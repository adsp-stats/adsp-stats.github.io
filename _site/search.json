[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Landing Page",
    "section": "",
    "text": "Welcome!\nHello! I’m Jonathan, and I want to teach you statistics. You’ll find these notes helpful if:\n\nYou are a student in one of my classes\nYou are someone else’s student and want to supplement their lessons with a different perspective\nYou work with data and want to improve your statistical knowledge base and toolkit\n\nYou can navigate these notes using the sidebar and search function. How you use this document is up to you, though I have some suggestions.\nIf you wish to learn or relearn the very basics of probability theory, I would start with REFERENCE. I teach graduate coursework and these topics are not my main focus since they are often taught in college, but we all benefit from a refresher and it may help to see the basics explained using the same notation and style used for more advanced concepts.\nIf you feel comfortable with basic probability and descriptive statistics, please proceed to REFERENCE where we introduce the idea of statistical inference and likelihood theory, providing a through-line which unites the rest of these notes.\nIn addition, the appendices describe common distributions, provide proofs for certain handwavy bits in the text, and catalog all the Greek and mathematical symbols used throughout. I also discuss the visual styling of this document and its notation below.",
    "crumbs": [
      "Home",
      "Placeholder",
      "Lecture"
    ]
  },
  {
    "objectID": "dist_normal.html",
    "href": "dist_normal.html",
    "title": "The Normal Distribution",
    "section": "",
    "text": "Although a few generating processes are provably normal, we mostly use the normal distribution in contexts where it is “close enough”, and do not require any particular assumptions.\nHowever, keep in mind that the normal distribution, at least in theory, is:\n\nUnbounded\nContinuous\nSymmetrical\n\nIf the process you are modeling is bounded, discrete, or asymmetrical, then the normal distribution may be a poor fit. Two common exceptions would be:\n\nWhen the distribution is naturally bounded, but most values are observed very far from the bounds (such as the weights of passenger jets, bounded below by 0, or the returns on a stock index, bounded below at -100%)\nWhen the distribution is discrete, but most values are very large or very finely subdivided (such as stadium attendance, or the current value of your bank account)"
  },
  {
    "objectID": "dist_normal.html#assumptions",
    "href": "dist_normal.html#assumptions",
    "title": "The Normal Distribution",
    "section": "",
    "text": "Although a few generating processes are provably normal, we mostly use the normal distribution in contexts where it is “close enough”, and do not require any particular assumptions.\nHowever, keep in mind that the normal distribution, at least in theory, is:\n\nUnbounded\nContinuous\nSymmetrical\n\nIf the process you are modeling is bounded, discrete, or asymmetrical, then the normal distribution may be a poor fit. Two common exceptions would be:\n\nWhen the distribution is naturally bounded, but most values are observed very far from the bounds (such as the weights of passenger jets, bounded below by 0, or the returns on a stock index, bounded below at -100%)\nWhen the distribution is discrete, but most values are very large or very finely subdivided (such as stadium attendance, or the current value of your bank account)"
  },
  {
    "objectID": "dist_normal.html#definition",
    "href": "dist_normal.html#definition",
    "title": "The Normal Distribution",
    "section": "Definition",
    "text": "Definition\n\\[\\begin{array}{ll}\n  \\text{Support:} & \\mathbb{R} \\\\\n  \\text{Parameter(s):} & \\mu,\\text{ the mean }(\\mu \\in \\mathbb{R}) \\\\\n  & \\sigma,\\text{ the standard deviation }(\\sigma \\gt 0) \\\\\n  \\text{PDF:} & f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2} \\\\\n  \\text{CDF:} & F_X(x) = \\Phi(\\frac{x-\\mu}{\\sigma})\\quad (\\text{No closed form expression}) \\\\\n  \\text{Mean:} & \\mathbb{E}[X]=\\mu \\\\\n  \\text{Variance:} & \\mathbb{V}[X]=\\sigma^2 \\\\\n\\end{array}\\]"
  },
  {
    "objectID": "dist_normal.html#visualizer",
    "href": "dist_normal.html#visualizer",
    "title": "The Normal Distribution",
    "section": "Visualizer",
    "text": "Visualizer\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 650\n\nlibrary(shiny)\nlibrary(bslib)\n\nui &lt;- page_sidebar(title = \"Normal distribution PDF\",\n  sidebar = sidebar(list(sliderInput(\"mu\", \"Mean (mu)\", min=-10, max=10, value=0),\n                         sliderInput(\"sigma\", \"Std Dev (sigma)\", min=0.01, max=10, value=1))),\n  plotOutput(\"distPlot\"))\n\nserver &lt;- function(input, output) {\n  output$distPlot &lt;- renderPlot({\n    x &lt;- seq(input$mu-3*input$sigma,input$mu+3*input$sigma,input$sigma/100)\n    y &lt;- dnorm(x,input$mu,input$sigma)\n    xlims &lt;- c(mean(c(-3,x[1])),mean(c(3,x[601])))\n    ylims &lt;- c(0,mean(c(dnorm(0),y[301])))\n    plot(x=x,y=y,main=NULL,xlab='x',ylab='Density',type='l',lwd=2,\n         xlim=xlims,ylim=ylims)\n  })\n}\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "dist_normal.html#properties",
    "href": "dist_normal.html#properties",
    "title": "The Normal Distribution",
    "section": "Properties",
    "text": "Properties\n\nThe normal distribution with mean \\(\\mu=0\\) and variance \\(\\sigma^2=1\\) is said to be the standard normal distribution and often written as \\(Z \\sim \\mathrm{Norm}(0,1)\\). The CDF of the standard normal distribution and its inverse are often abbreviated as \\(F_X(x)=\\Phi(x)\\) and \\(F_X^{-1}(x)=\\Phi^{-1}(x)\\), respectively.\nIf \\(X\\) is a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then for any constants \\(a,b \\in \\mathbb{R}\\) the transformation \\(aX + b\\) is also a normal random variable with mean \\(a\\mu + b\\) and variance \\(a^2\\sigma^2\\).\nIf \\(X\\) and \\(Y\\) are two independent normal random variables with means \\(\\mu_X, \\mu_Y\\) and variances \\(\\sigma^2_X, \\sigma^2_Y\\), then their sum \\(X+Y\\) is also a normal random variable with mean \\(\\mu_X+\\mu_Y\\) and variance \\(\\sigma^2_X+\\sigma^2_Y\\).\nMore generally, any linear combination of any number of independent normal random variables is itself a normal random variable!"
  },
  {
    "objectID": "dist_normal.html#relations-to-other-distributions",
    "href": "dist_normal.html#relations-to-other-distributions",
    "title": "The Normal Distribution",
    "section": "Relations to other distributions",
    "text": "Relations to other distributions\n\nThe sum of the squares of \\(n\\) independent standard normal variates is chi-squared distributed with \\(df=n\\): \\[\\sum_{i=1}^n Z_i^2 \\sim \\chi_{(n)}^2\\]\nThe ratio of two standard normal variates has the standard Cauchy distribution, i.e. \\[\\mathrm{For\\ }Z_1,Z_2 \\sim \\mathrm{Norm}(0,1),\\quad \\frac{Z_1}{Z_2} \\sim \\mathrm{Cauchy}(0,1)\\]\nThe standard normal distribution is the limit case for the Student’s t-distribution (as \\(df \\rightarrow \\infty\\)). The standard normal can be used in place of the t-distribution with little loss of accuracy for large \\(df\\).\nThe normal distribution with mean \\(df\\) and standard deviation \\(\\sqrt{2df}\\) closely approximates the chi-squared distribution for large \\(df\\).\nThe Poisson distribution and binomial distribution both form discrete approximations to the normal distribution when either \\(\\lambda\\) is very large (Poisson) or \\(np\\) is very large and \\(p\\) is not near 0 or 1.\n\ngfds"
  },
  {
    "objectID": "sets.html",
    "href": "sets.html",
    "title": "Set Theory",
    "section": "",
    "text": "These notes largely focus on parametric inference. Parameteric inference relies on distribution theory. Distribution theory relies on probability theory. Probability theory relies on set theory.\nBut we cannot cover all of set theory, probability theory, distributional theory, and inference in a single document or course. So in these first few chapters I am presenting small corners of each field to you for reference, no more than you need to build a solid understanding of the predictive models in the later chapters.\n\n\nSets are collections of objects, and set theory helps us talk about these collections of objects: how many there are, which objects can be found in two different sets, etc. Set theory seems quite basic, but it’s very relevant to probability because one way to think about probability is to divide “the number of desired outcomes” of an experiment by “the number of total outcomes” of that experiment, which requires us to know how to arrange and count outcomes.\nLet \\(\\mathcal{S}\\) be a set, that is, a collection of objects. The objects could be numbers, or words, or cars, or anything at all. We call each object that belongs to a set an element, and if an element named \\(x\\) belongs to the set \\(\\mathcal{S}\\), we write:\n\\[x \\in \\mathcal{S}\\]\nWhile if another element called \\(y\\) does not belong to the set \\(\\mathcal{S}\\), we write:\n\\[y \\notin \\mathcal{S}\\]\nIf a set \\(\\mathcal{A}\\) contains all of the elements that belong to another set \\(\\mathcal{B}\\), we say that \\(\\mathcal{B}\\) is a subset of \\(\\mathcal{A}\\), which can be written:\n\\[\\mathcal{B} \\subseteq \\mathcal{A}\\]\nNotice that this leaves the possibility that \\(\\mathcal{A}\\) and \\(\\mathcal{B}\\) are in fact equal, the same set. If we know that \\(\\mathcal{B}\\) is actually smaller than \\(\\mathcal{A}\\), that is, \\(\\mathcal{A}\\) contains all the elements in \\(\\mathcal{B}\\) and also other elements not in \\(\\mathcal{B}\\), then we say that \\(\\mathcal{B}\\) is a proper subset of \\(\\mathcal{A}\\) and we write:\n\\[\\mathcal{B} \\subset \\mathcal{A}\\]\nSometimes two sets share certain elements, and we want to identify only those elements which appear in both sets. We call this new set the intersection, and we could write:\n\\[\\mathcal{A} \\cap \\mathcal{B} = \\{x: x \\in \\mathcal{A} \\textrm{ and } x \\in \\mathcal{B}\\}\\] Other times we want to identify all of those elements which appear in either set. We call this new set the union, and we could write:\n\\[\\mathcal{A} \\cup \\mathcal{B} = \\{x: x \\in \\mathcal{A} \\textrm{ or } x \\in \\mathcal{B}\\}\\]\npar(mar=(rep(0.1,4)))\nsymbols(x=1,y=1,circles=0.8,inches=FALSE,fg='white',bg='grey80',\n        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',\n        xlab=NA,ylab=NA,add=FALSE)\ntext(x=0.25,y=1.75,label='A',adj=c(0.5,0.5),cex=3.5)\ntext(x=c(1.4,2.2),y=c(1,1),labels=c('x','y'),adj=c(0.5,0.5),cex=2.5)\n\nsymbols(x=c(1,1.1),y=c(1,0.9),circles=c(0.8,0.75),inches=FALSE,\n        fg=c('white','black'),bg=c('grey80',NA),\n        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',\n        xlab=NA,ylab=NA,add=FALSE)\ntext(x=c(0.25,1.8),y=c(1.7,0.3),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)\ntext(x=c(0.8,1.1,1.4),y=c(0.7,1.1,0.9),labels=c('x','y','z'),adj=c(0.5,0.5),cex=2.5)\n\nsymbols(x=c(1,1.25),y=c(1,1.25),circles=c(0.8,0.5),inches=FALSE,\n        fg=c('white','black'),bg=c('grey80',NA),\n        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',\n        xlab=NA,ylab=NA,add=FALSE)\ntext(x=c(0.25,1.7),y=c(1.7,1.7),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)\ntext(x=c(0.8,1.1,1.4),y=c(0.7,1.1,0.9),labels=c('x','y','z'),adj=c(0.5,0.5),cex=2.5)\n\nsymbols(x=c(1,1.6),y=c(1,0.9),circles=c(0.8,0.7),inches=FALSE,\n        fg=c('white','black'),bg=c('grey80',NA),\n        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',\n        xlab=NA,ylab=NA,add=FALSE)\ntext(x=c(0.25,2.1),y=c(1.7,1.7),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)\ntext(x=c(0.8,1.1,1.4,1.9),y=c(0.7,1.1,0.9,1.0),labels=c('x','y','z','w'),adj=c(0.5,0.5),cex=2.5)\n\n\n\n\n\n\n\n\n\n\n\n(a) \\(x \\in \\mathcal{A}, y \\notin \\mathcal{A}\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(\\mathcal{B} \\subseteq \\mathcal{A}, \\mathcal{A} \\subseteq \\mathcal{B}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) \\(\\mathcal{B} \\subset \\mathcal{A}, \\mathcal{A} \\not\\subset \\mathcal{B}\\)\n\n\n\n\n\n\n\n\n\n\n\n(d) \\(\\mathcal{A} \\cap \\mathcal{B} = \\{x,z\\}, \\mathcal{A} \\cup \\mathcal{B} = \\{w,x,y,z\\}\\)\n\n\n\n\n\n\n\nFigure 1: Visualization of set theory basics\n\n\n\nWe occasionally find it useful, after defining a set, to also consider every known object not in the set. If an element \\(x\\) does not belong to a set \\(\\mathcal{S}\\) then it belongs to “\\(\\mathcal{S}\\)-complement”, often written \\(\\mathcal{S}^c\\).\nJust above, I wrote “every known object”, and that is also a set worth naming. Let us say that we have some way of knowing all the elements which could or could not belong to any given set. This universe of elements is given lots of names, including the universal set and also \\(\\Omega\\), Omega, the last letter of the Greek alphabet and therefore literally the ultimate set.\nWhat about a set with no elements at all? Such a thing exists and is often quite useful, just as the number 0 is useful to us despite not doing much. We call it \\(\\emptyset\\), the empty set (sometimes just called “null”).\nConsider some basic results which flow from these definitions:\n\n\n\n\n\n\nNote\n\n\n\nLet \\(\\emptyset\\) be the empty set, \\(\\mathcal{A}\\) be any set, and \\(\\Omega\\) be the universal set. Then,\n\\[\\begin{array}{lcllcl}\n  \\mathcal{A} \\cup \\mathcal{A}^c &=& \\Omega\\qquad & \\mathcal{A} \\cap \\mathcal{A}^c &=& \\emptyset \\\\\n  \\mathcal{A} \\cup \\emptyset &=& \\mathcal{A} & \\mathcal{A} \\cap \\emptyset &=& \\emptyset \\\\\n  \\mathcal{A} \\cup \\Omega &=& \\Omega & \\mathcal{A} \\cap \\Omega &=& \\mathcal{A}\n\\end{array}\\]\n\n\nIf, for any two sets \\(\\mathcal{A}\\) and \\(\\mathcal{B}\\), we know that \\(\\mathcal{A} \\cap \\mathcal{B} = \\emptyset\\) then they have no elements in common and we say that the sets are disjoint.\n\n\n\nAnother part of set theory studies how to arrange and count the elements in a set. We call this topic “combinatorics”.\nYou may remember a mathematical operation called factorial, written with an exclamation mark (!). Its definition for non-negative integers is:\n\\[x! = x \\cdot (x-1) \\cdot (x-2) \\cdot \\ldots \\cdot 2 \\cdot 1\\]\nSo, for example, \\(3! = 3 \\cdot 2 \\cdot 1 = 6\\), and \\(10! = 3\\,628\\,800\\).1 This operation will be very handy for counting arrangements of objects. Let’s now consider several different situations in which wish to count arrangements. In all of these examples, we will suppose that we have a set \\(\\mathcal{S}\\) containing \\(n\\) elements. Sometimes we will be studying arrangements of all \\(n\\) objects, but if we are arranging a different number of objects, I will generally call that other number \\(k\\).\n\n\nFirst, let us consider how many ways we can arrange the \\(n\\) elements of \\(\\mathcal{S}\\) in a particular order. For example, let’s say that I am on vacation for five days starting Monday, I have brought five different t-shirts, and I intend to wear a fresh shirt every day. I can select any of the five shirts Monday night. On Tuesday, I can choose from the four remaining shirts. On Wednesday, no matter what I picked Monday and Tuesday, I will have three choices left. On Thursday, two choices. On Friday, only one shirt is left, and I must wear it. Thus I count \\(5 \\cdot 4 \\cdot 3 \\cdot 2 \\cdot 1 = 5! = 120\\) shirt arrangements.\n\n\n\nSecond, let us consider how many ways we could arrange the elements of \\(\\mathcal{S}\\) in a particular order if we now allow repetition. Reconsidering the previous example, what if I were comfortable wearing the same shirt on multiple days, perhaps even every day (yikes)? On Monday, I would have five choices of what to wear. On Tuesday I would also have five choices: I could repeat Monday’s shirt, or choose any of the others — and so on throughout the week. Thus I count \\(5 \\cdot 5 \\cdot 5 \\cdot 5 \\cdot 5 = 5^5 = 3125\\) different shirt arrangements.\nFurthermore, we can generalize this method to cases where we arrange \\(k \\neq n\\) elements of \\(\\mathcal{S}\\): if I were only vacationing for three days but brought five shirts, there would be \\(5^3=125\\) arrangements, or for seven days, \\(5^7=78\\,125\\) arrangements.\n\n\n\nThird, let us consider how to order only a subset of elements, without repetition. Say that I brought five shirts, I wear a fresh shirt every day, but the vacation lasts only three days (perhaps I wanted backups for spills or rain). The calculations proceed as in the first case above: I have five choices on Monday, four choices on Tuesday, and three choices on Wednesday — and then I’m done, and thus I count \\(5 \\cdot 4 \\cdot 3 = 60\\) shirt arrangements.\nNote that \\(5 \\cdot 4 \\cdot 3 = (5 \\cdot 4 \\cdot 3 \\cdot 2 \\cdot 1)/(2 \\cdot 1) = 5!/2!\\) or equivalently \\(5!/(5-3)!\\). We will use this result to show a general form below.\n\n\n\nFourth, suppose we no longer care about the order of elements, and only care about which elements are picked or not picked. Perhaps I am packing five shirts for my vacation, and choosing them from my closet which has a total of nine shirts. How many different bags could I create? The bag doesn’t know or care which shirts will be worn on which days… a vacation where I wear the red shirt on Monday will create the same bag as a week where I wear the red shirt on Friday. Using the third case above, we know there are \\(9!⁄4! = 15\\,120\\) ways to create an ordered subset of five shirts from a set of nine. But using the first case above, we also know that for any five shirts, there are \\(5!=120\\) ways to order them. Combining this information, we see that each of the \\(15\\,120\\) ordered shirt arrangements belongs to a group of \\(120\\) duplicate bags which only differ by their order, so we need to shrink our total by a factor of \\(120\\), leaving \\(15\\,120⁄120 = (9!/4!)/5! = 9!/((9-5)!5!) = 126\\) possible ways to pack my bag.\n\n\n\nFifth and finally, let us consider how many possible subsets we could construct, without specifiying size or order. Let us repeat the bag packing question (how many possible bags can I create?), but allowing me to pack any number of the nine shirts (not just five). To answer this question, I will show that it is equivalent to another, simpler question. Consider that each of my nine shirts can either be in or out of the bag. So each possible bag can be thought of as choosing from a set of two elements (“in” and “out”) nine times (once for each shirt), with repetition allowed. Following the logic of our second case we know there will be \\(2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 = 2^9 = 512\\) possible bags Notice that these bags will include one with all nine shirts, as well as a bag with no shirts at all (double yikes, but mathematically valid).\nLet’s review:\n\n\n\n\n\n\nNote\n\n\n\nLet \\(\\mathcal{S}\\) be a set of \\(n\\) elements. Then,\n\nThere are \\(n!\\) ways to arrange the elements of \\(\\mathcal{S}\\) in order.\nThere are \\(n^k\\) ways to pick \\(k\\) elements of \\(\\mathcal{S}\\), if we allow repetition.\nThere are \\({}_{n}P_k = \\frac{n!}{(n-k)!} = n \\cdot (n-1) \\cdot \\ldots \\cdot (n-k+1)\\) ordered subsets of \\(\\mathcal{S}\\) having exactly \\(k\\) elements. These ordered subsets are called permutations.\nThere are \\({}_{n}C_k = \\frac{n!}{(n-k)!k!}\\) unordered subsets of \\(\\mathcal{S}\\) having exactly \\(k\\) elements. These unordered subsets are called combinations, and in this text we will use \\(\\left(\\begin{array}{c} n \\\\ k \\end{array} \\right)\\) synomously with \\({}_{n}C_k\\). Statisticians often read this aloud as “n choose k”.\nThere are \\(2^n\\) distinct (unordered) subsets of \\(\\mathcal{S}\\), including \\(\\mathcal{S}\\) itself and the empty set \\(\\emptyset\\). This set of all possible subsets is called the power set.\n\n\n\n\n\n\n\nWe will soon explore a more formal definition of probability, but learning the combinatorics shown above leads to an immediate payoff: we can use them to calculate probabilities for a specific (yet common) scenario.\nWe often face a situation in which a finite number of outcomes are all equally likely. For example,\n\nIf we roll two six-sided dice, we have an equal chance of each of 36 ordered results (e.g. Roll #1 is 2 and Roll #2 is 5)\nIf we draw five cards from a 52-card deck, we have an equal chance of each of \\(311\\,875\\,200\\) possible ordered hands, or an equal chance of each of \\(2\\,598\\,960\\) unordered hands.\nIf we split 24 students into six groups of four, there are roughly 4.5 trillion groupings which are each equally likely, if we order neither the groups themselves nor the students within the groups.\n\nIn each of these cases, we can evaluate the probability of certain outcomes by counting the number of cases with the desired attributes and dividing by the number of total cases.\n\n\n\n\n\n\nNote\n\n\n\nFor any finite set \\(\\mathcal{A}\\), let \\(n(\\mathcal{A})\\) be a function which counts the number of elements in \\(\\mathcal{A}\\).\nNow consider an experiment with a set of outcomes, \\(\\Omega\\). Exactly one outcome from \\(\\Omega\\) must happen, and all outcomes are equally likely to happen. For any subset \\(\\mathcal{A} \\subseteq \\Omega\\), the probability of an outcome belonging to \\(\\mathcal{A}\\) can be calculated as: \\[P(\\mathcal{A})=\\frac{n(\\mathcal{A})}{n(\\Omega)}\\]\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe above result is only true for situations with a finite number of equally likely outomes. At the moment, we haven’t learned enough to prove which situations meet that requirement, nor to prove the result is even true: we are proceeding on assumption.\n\n\nFrom here, we can start to calculate some actual probabilities. Suppose we are dealt five cards from a standard 52-card deck: what is the probability of being dealt exactly one pair (two matched cards and three unmatched cards)?\n\nThis question is complicated, because many pairs are actually part of a more valuable hand: three-of-a-kind, four-of-a-kind, a full house, or two pairs. We don’t wish to count those hands, even though they contain pairs.\nAlthough order doesn’t matter, suppose that the first and second cards are paired, while the third, fourth, and fifth cards are unmatched. The first card can be anything (52 choices). The second card must be one of the three remaining cards of the same rank (3 choices). The third card can be anything except the rank of the pair (48 choices). The fourth card can be anything except the rank of the pair or the rank of the third card, since that would form a second pair (44 choices). And likewise for the fifth (40 choices).\n\\(52 \\cdot 3 \\cdot 48 \\cdot 44 \\cdot 40 = 13\\,178\\,880\\) would describe the number of hands where the first two cards form a pair. But there are other hands with one pair, such as when the first and third cards are paired. In fact there are \\({}_5C_2 = 5!/(2!3!) = 10\\) different ways the pair could be arranged in our hand. So there are in fact \\(n(\\mathcal{A})=131\\,788\\,800\\) ordered hands with exactly one pair.\nThat would be among \\(n(\\Omega) = 52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48 = 52!/(52 - 5)! = 311\\,875\\,200\\) total ordered hands.\nIn which case the probability of exactly one pair is \\(n(\\mathcal{A})/n(\\Omega) = 134\\,534\\,400/311\\,875\\,200 \\approx 42.3\\%\\)\n\nLet’s try one more example, this time somewhat more relevant to a real-world data science issue. Consider an allegation of discriminatory hiring practices. 15 pilots interviewed for five open positions at an airline. 10 of the 15 candidates were men, but only 2 of the 5 selected pilots are men. One of the rejected male pilots claims that the hiring process was unfair. What do you think?\n\nThere are \\({}_{10}C_2 = 10!/(2!8!) = 45\\) unordered ways to choose 2 men from among 10 male applicants and \\({}_3C_5 = 5!/(3!2!) = 10\\) ways to choose 3 women2 from among the remaining 5 applicants, so we have \\(n(\\mathcal{A}) = 45 \\cdot 10 = 450\\).\nThere are \\(n(\\Omega) = {}_15C_5 = 15!/(10!5!) = 3003\\) unordered ways to choose 5 pilots from the 15 total applicants.\nIn which case, if we assume that the successful pilots were selected at random (or at any rate not on the basis of their sex), the probability of selecting exactly 2 men and 3 women from 10 men and 5 women would be \\(n(\\mathcal{A})/n(\\Omega) = 450/3003 \\approx 15.0\\%\\).\nIt might be useful to also contemplate the case of picking only one male candidate, or zero male candidates. Using similar calculations, the cumulative probability of picking “so few or fewer” male candidates under an assumption of equal probability would be \\(501/3003 \\approx 16.7\\%\\)\n\nAt the end of the day we cannot tell whether the hiring process was fair or unfair. But we can say that an impartial hiring process which was blind to pilot sex would reach a similar outcome (or a more extreme outcome!) roughly \\(16.7\\%\\) of the time.\n\nNotice how in the first example, I found it easier to count ordered cases, while in the second example I found it easier to count unordered cases. As long as both my numerator and denominator are consistent, the answer will come out the same.\n\n\n\n\nAt the end of each chapter I will provide some R code snippets to help put the concepts into practice, as well as sample problems (and their solutions!) to help you test your own comprehension of the material.\n\n\n\n\nSet theory is so basic that it’s all around us. For example, when we filter a dataset, or when we merge two different datasets, we are choosing intersections and unions from sets where each element is a row of data. The following functions are rarely used in R, but do directly implement the concepts learned above.\n\nletters[1:10]\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\"\n\nis.element('j',letters)\n\n[1] TRUE\n\nis.element(c('a','B','c'),letters)\n\n[1]  TRUE FALSE  TRUE\n\nunion(1:8,3:10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nintersect(1:8,3:10)\n\n[1] 3 4 5 6 7 8\n\nsetdiff(1:8,3:10)\n\n[1] 1 2\n\nsetequal(c(1,4,9),c(1,9,4))\n\n[1] TRUE\n\n\n\n\n\nSometimes our combinatorics problems cannot be solved with easy helper functions, because of special constraints to the problem. However, the following functions will often come in handy. Note the addition of a custom function for permutations.\n\nfactorial(4)\n\n[1] 24\n\nfactorial(1:5)\n\n[1]   1   2   6  24 120\n\nchoose(n=10,k=3)\n\n[1] 120\n\npermute &lt;- function(n,k) factorial(n)/factorial(n-k)\npermute(n=10,k=3)\n\n[1] 720\n\n\n\n\n\n\n\nEarlier, I calculated the probability that a five-card hand from a standard deck contains exactly one pair. I counted ordered hands to find the answer, though order doesn’t matter. Try to find an unordered solution, which should arrive at the same answer.\n\n\n\n\n\n\n\nSolution (theoretical)\n\n\n\n\n\nThere are 13 ways to choose the rank of the pair, \\({}_4{C}_2\\) ways to choose the two suits of that rank which will form the pair, \\({}_{12}{C}_3\\) ways to choose the three different ranks of the remaining cards, and four choices of suit for each of them. \\[\\frac{13 \\cdot {}_4{C}_2 \\cdot {}_{12}{C}_3 \\cdot 4^3}{{}_{52}{C}_5} \\approx 42.3\\%\\]\n\n\n\n\n13*choose(4,2)*choose(12,3)*4^3/choose(52,5)\n\n\nAssume that birthdays are evenly distributed across a 365-day (non-leap) year. In a classroom of 23 students, what is the probability that at least two of them share a birthday?\n\n\n\n\n\n\n\nSolution (theoretical)\n\n\n\n\n\nThere are so many ways in which two or more students could share birthdays that it will be easier for us to consider the complement: how many ways students could not share any birthdays. Clearly, the first student can have any birthday, but the second will only have 364 qualifying options, etc. \\[P(A) = 1 - P(A^c) = 1 - \\frac{{}_{365}P_{23}}{365^{23}} = 1 - \\frac{365 \\cdot 364 \\cdot \\ldots \\cdot 343}{365^{23}} \\approx 50.7\\%\\] This is sometimes known as the birthday “paradox”, as it may surprise you that such a small classroom would most likely contain a shared birthday.\n\n\n\n\n1-prod(365:343)/365^23\n\n\nIn 1919, the statistician Ronald Fisher heard his colleague, the phycologist Muriel Bristol, claim that she could tell whether milk was added to hot tea, or whether the tea was poured directly onto milk. Fisher tested her by pouring eight cups of tea, four one way and four the other, and serving them to her in a random order which she was able to identify with complete accuracy. If Bristol knew that there were four cups of each type, what would be the probability that she identified them all correctly by chance alone?\n\n\n\n\n\n\n\nSolution (theoretical)\n\n\n\n\n\nThis one’s quite simple! There are \\({}_8C_4 = 70\\) ways to arrange the four milk-first cups among the eight total cups, and if Dr. Bristol had been guessing at random she would have selected each arrangement with equal probability, and so would have chosen the right arrangement with only \\(1/70 \\approx 1.4\\%\\) probability.\n\n\n\n\n1/choose(8,4)\n\n\nHow would the problem above change if Muriel Bristol had not known there were four cups of each type?\n\n\n\n\n\n\n\nSolution (theoretical)\n\n\n\n\n\nWithout knowing in advance how many cups had milk poured first, Bristol would have been guessing blindly on each new cup, with her guesses for the first few cups providing no information on the latter cups. The experiment now allows \\(2^8=256\\) possible cup sequences, with only one being correct, so if she were guessing at random then a perfect score would only occur with probability \\(1/256 \\approx 0.4\\%\\).\n\n\n\n\n1/2^8"
  },
  {
    "objectID": "sets.html#sets-unions-and-intersections",
    "href": "sets.html#sets-unions-and-intersections",
    "title": "Set Theory",
    "section": "",
    "text": "Sets are collections of objects, and set theory helps us talk about these collections of objects: how many there are, which objects can be found in two different sets, etc. Set theory seems quite basic, but it’s very relevant to probability because one way to think about probability is to divide “the number of desired outcomes” of an experiment by “the number of total outcomes” of that experiment, which requires us to know how to arrange and count outcomes.\nLet \\(\\mathcal{S}\\) be a set, that is, a collection of objects. The objects could be numbers, or words, or cars, or anything at all. We call each object that belongs to a set an element, and if an element named \\(x\\) belongs to the set \\(\\mathcal{S}\\), we write:\n\\[x \\in \\mathcal{S}\\]\nWhile if another element called \\(y\\) does not belong to the set \\(\\mathcal{S}\\), we write:\n\\[y \\notin \\mathcal{S}\\]\nIf a set \\(\\mathcal{A}\\) contains all of the elements that belong to another set \\(\\mathcal{B}\\), we say that \\(\\mathcal{B}\\) is a subset of \\(\\mathcal{A}\\), which can be written:\n\\[\\mathcal{B} \\subseteq \\mathcal{A}\\]\nNotice that this leaves the possibility that \\(\\mathcal{A}\\) and \\(\\mathcal{B}\\) are in fact equal, the same set. If we know that \\(\\mathcal{B}\\) is actually smaller than \\(\\mathcal{A}\\), that is, \\(\\mathcal{A}\\) contains all the elements in \\(\\mathcal{B}\\) and also other elements not in \\(\\mathcal{B}\\), then we say that \\(\\mathcal{B}\\) is a proper subset of \\(\\mathcal{A}\\) and we write:\n\\[\\mathcal{B} \\subset \\mathcal{A}\\]\nSometimes two sets share certain elements, and we want to identify only those elements which appear in both sets. We call this new set the intersection, and we could write:\n\\[\\mathcal{A} \\cap \\mathcal{B} = \\{x: x \\in \\mathcal{A} \\textrm{ and } x \\in \\mathcal{B}\\}\\] Other times we want to identify all of those elements which appear in either set. We call this new set the union, and we could write:\n\\[\\mathcal{A} \\cup \\mathcal{B} = \\{x: x \\in \\mathcal{A} \\textrm{ or } x \\in \\mathcal{B}\\}\\]\npar(mar=(rep(0.1,4)))\nsymbols(x=1,y=1,circles=0.8,inches=FALSE,fg='white',bg='grey80',\n        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',\n        xlab=NA,ylab=NA,add=FALSE)\ntext(x=0.25,y=1.75,label='A',adj=c(0.5,0.5),cex=3.5)\ntext(x=c(1.4,2.2),y=c(1,1),labels=c('x','y'),adj=c(0.5,0.5),cex=2.5)\n\nsymbols(x=c(1,1.1),y=c(1,0.9),circles=c(0.8,0.75),inches=FALSE,\n        fg=c('white','black'),bg=c('grey80',NA),\n        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',\n        xlab=NA,ylab=NA,add=FALSE)\ntext(x=c(0.25,1.8),y=c(1.7,0.3),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)\ntext(x=c(0.8,1.1,1.4),y=c(0.7,1.1,0.9),labels=c('x','y','z'),adj=c(0.5,0.5),cex=2.5)\n\nsymbols(x=c(1,1.25),y=c(1,1.25),circles=c(0.8,0.5),inches=FALSE,\n        fg=c('white','black'),bg=c('grey80',NA),\n        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',\n        xlab=NA,ylab=NA,add=FALSE)\ntext(x=c(0.25,1.7),y=c(1.7,1.7),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)\ntext(x=c(0.8,1.1,1.4),y=c(0.7,1.1,0.9),labels=c('x','y','z'),adj=c(0.5,0.5),cex=2.5)\n\nsymbols(x=c(1,1.6),y=c(1,0.9),circles=c(0.8,0.7),inches=FALSE,\n        fg=c('white','black'),bg=c('grey80',NA),\n        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',\n        xlab=NA,ylab=NA,add=FALSE)\ntext(x=c(0.25,2.1),y=c(1.7,1.7),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)\ntext(x=c(0.8,1.1,1.4,1.9),y=c(0.7,1.1,0.9,1.0),labels=c('x','y','z','w'),adj=c(0.5,0.5),cex=2.5)\n\n\n\n\n\n\n\n\n\n\n\n(a) \\(x \\in \\mathcal{A}, y \\notin \\mathcal{A}\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(\\mathcal{B} \\subseteq \\mathcal{A}, \\mathcal{A} \\subseteq \\mathcal{B}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) \\(\\mathcal{B} \\subset \\mathcal{A}, \\mathcal{A} \\not\\subset \\mathcal{B}\\)\n\n\n\n\n\n\n\n\n\n\n\n(d) \\(\\mathcal{A} \\cap \\mathcal{B} = \\{x,z\\}, \\mathcal{A} \\cup \\mathcal{B} = \\{w,x,y,z\\}\\)\n\n\n\n\n\n\n\nFigure 1: Visualization of set theory basics\n\n\n\nWe occasionally find it useful, after defining a set, to also consider every known object not in the set. If an element \\(x\\) does not belong to a set \\(\\mathcal{S}\\) then it belongs to “\\(\\mathcal{S}\\)-complement”, often written \\(\\mathcal{S}^c\\).\nJust above, I wrote “every known object”, and that is also a set worth naming. Let us say that we have some way of knowing all the elements which could or could not belong to any given set. This universe of elements is given lots of names, including the universal set and also \\(\\Omega\\), Omega, the last letter of the Greek alphabet and therefore literally the ultimate set.\nWhat about a set with no elements at all? Such a thing exists and is often quite useful, just as the number 0 is useful to us despite not doing much. We call it \\(\\emptyset\\), the empty set (sometimes just called “null”).\nConsider some basic results which flow from these definitions:\n\n\n\n\n\n\nNote\n\n\n\nLet \\(\\emptyset\\) be the empty set, \\(\\mathcal{A}\\) be any set, and \\(\\Omega\\) be the universal set. Then,\n\\[\\begin{array}{lcllcl}\n  \\mathcal{A} \\cup \\mathcal{A}^c &=& \\Omega\\qquad & \\mathcal{A} \\cap \\mathcal{A}^c &=& \\emptyset \\\\\n  \\mathcal{A} \\cup \\emptyset &=& \\mathcal{A} & \\mathcal{A} \\cap \\emptyset &=& \\emptyset \\\\\n  \\mathcal{A} \\cup \\Omega &=& \\Omega & \\mathcal{A} \\cap \\Omega &=& \\mathcal{A}\n\\end{array}\\]\n\n\nIf, for any two sets \\(\\mathcal{A}\\) and \\(\\mathcal{B}\\), we know that \\(\\mathcal{A} \\cap \\mathcal{B} = \\emptyset\\) then they have no elements in common and we say that the sets are disjoint."
  },
  {
    "objectID": "sets.html#combinatorics",
    "href": "sets.html#combinatorics",
    "title": "Set Theory",
    "section": "",
    "text": "Another part of set theory studies how to arrange and count the elements in a set. We call this topic “combinatorics”.\nYou may remember a mathematical operation called factorial, written with an exclamation mark (!). Its definition for non-negative integers is:\n\\[x! = x \\cdot (x-1) \\cdot (x-2) \\cdot \\ldots \\cdot 2 \\cdot 1\\]\nSo, for example, \\(3! = 3 \\cdot 2 \\cdot 1 = 6\\), and \\(10! = 3\\,628\\,800\\).1 This operation will be very handy for counting arrangements of objects. Let’s now consider several different situations in which wish to count arrangements. In all of these examples, we will suppose that we have a set \\(\\mathcal{S}\\) containing \\(n\\) elements. Sometimes we will be studying arrangements of all \\(n\\) objects, but if we are arranging a different number of objects, I will generally call that other number \\(k\\).\n\n\nFirst, let us consider how many ways we can arrange the \\(n\\) elements of \\(\\mathcal{S}\\) in a particular order. For example, let’s say that I am on vacation for five days starting Monday, I have brought five different t-shirts, and I intend to wear a fresh shirt every day. I can select any of the five shirts Monday night. On Tuesday, I can choose from the four remaining shirts. On Wednesday, no matter what I picked Monday and Tuesday, I will have three choices left. On Thursday, two choices. On Friday, only one shirt is left, and I must wear it. Thus I count \\(5 \\cdot 4 \\cdot 3 \\cdot 2 \\cdot 1 = 5! = 120\\) shirt arrangements.\n\n\n\nSecond, let us consider how many ways we could arrange the elements of \\(\\mathcal{S}\\) in a particular order if we now allow repetition. Reconsidering the previous example, what if I were comfortable wearing the same shirt on multiple days, perhaps even every day (yikes)? On Monday, I would have five choices of what to wear. On Tuesday I would also have five choices: I could repeat Monday’s shirt, or choose any of the others — and so on throughout the week. Thus I count \\(5 \\cdot 5 \\cdot 5 \\cdot 5 \\cdot 5 = 5^5 = 3125\\) different shirt arrangements.\nFurthermore, we can generalize this method to cases where we arrange \\(k \\neq n\\) elements of \\(\\mathcal{S}\\): if I were only vacationing for three days but brought five shirts, there would be \\(5^3=125\\) arrangements, or for seven days, \\(5^7=78\\,125\\) arrangements.\n\n\n\nThird, let us consider how to order only a subset of elements, without repetition. Say that I brought five shirts, I wear a fresh shirt every day, but the vacation lasts only three days (perhaps I wanted backups for spills or rain). The calculations proceed as in the first case above: I have five choices on Monday, four choices on Tuesday, and three choices on Wednesday — and then I’m done, and thus I count \\(5 \\cdot 4 \\cdot 3 = 60\\) shirt arrangements.\nNote that \\(5 \\cdot 4 \\cdot 3 = (5 \\cdot 4 \\cdot 3 \\cdot 2 \\cdot 1)/(2 \\cdot 1) = 5!/2!\\) or equivalently \\(5!/(5-3)!\\). We will use this result to show a general form below.\n\n\n\nFourth, suppose we no longer care about the order of elements, and only care about which elements are picked or not picked. Perhaps I am packing five shirts for my vacation, and choosing them from my closet which has a total of nine shirts. How many different bags could I create? The bag doesn’t know or care which shirts will be worn on which days… a vacation where I wear the red shirt on Monday will create the same bag as a week where I wear the red shirt on Friday. Using the third case above, we know there are \\(9!⁄4! = 15\\,120\\) ways to create an ordered subset of five shirts from a set of nine. But using the first case above, we also know that for any five shirts, there are \\(5!=120\\) ways to order them. Combining this information, we see that each of the \\(15\\,120\\) ordered shirt arrangements belongs to a group of \\(120\\) duplicate bags which only differ by their order, so we need to shrink our total by a factor of \\(120\\), leaving \\(15\\,120⁄120 = (9!/4!)/5! = 9!/((9-5)!5!) = 126\\) possible ways to pack my bag.\n\n\n\nFifth and finally, let us consider how many possible subsets we could construct, without specifiying size or order. Let us repeat the bag packing question (how many possible bags can I create?), but allowing me to pack any number of the nine shirts (not just five). To answer this question, I will show that it is equivalent to another, simpler question. Consider that each of my nine shirts can either be in or out of the bag. So each possible bag can be thought of as choosing from a set of two elements (“in” and “out”) nine times (once for each shirt), with repetition allowed. Following the logic of our second case we know there will be \\(2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 \\cdot 2 = 2^9 = 512\\) possible bags Notice that these bags will include one with all nine shirts, as well as a bag with no shirts at all (double yikes, but mathematically valid).\nLet’s review:\n\n\n\n\n\n\nNote\n\n\n\nLet \\(\\mathcal{S}\\) be a set of \\(n\\) elements. Then,\n\nThere are \\(n!\\) ways to arrange the elements of \\(\\mathcal{S}\\) in order.\nThere are \\(n^k\\) ways to pick \\(k\\) elements of \\(\\mathcal{S}\\), if we allow repetition.\nThere are \\({}_{n}P_k = \\frac{n!}{(n-k)!} = n \\cdot (n-1) \\cdot \\ldots \\cdot (n-k+1)\\) ordered subsets of \\(\\mathcal{S}\\) having exactly \\(k\\) elements. These ordered subsets are called permutations.\nThere are \\({}_{n}C_k = \\frac{n!}{(n-k)!k!}\\) unordered subsets of \\(\\mathcal{S}\\) having exactly \\(k\\) elements. These unordered subsets are called combinations, and in this text we will use \\(\\left(\\begin{array}{c} n \\\\ k \\end{array} \\right)\\) synomously with \\({}_{n}C_k\\). Statisticians often read this aloud as “n choose k”.\nThere are \\(2^n\\) distinct (unordered) subsets of \\(\\mathcal{S}\\), including \\(\\mathcal{S}\\) itself and the empty set \\(\\emptyset\\). This set of all possible subsets is called the power set."
  },
  {
    "objectID": "sets.html#probability-as-counting-cases",
    "href": "sets.html#probability-as-counting-cases",
    "title": "Set Theory",
    "section": "",
    "text": "We will soon explore a more formal definition of probability, but learning the combinatorics shown above leads to an immediate payoff: we can use them to calculate probabilities for a specific (yet common) scenario.\nWe often face a situation in which a finite number of outcomes are all equally likely. For example,\n\nIf we roll two six-sided dice, we have an equal chance of each of 36 ordered results (e.g. Roll #1 is 2 and Roll #2 is 5)\nIf we draw five cards from a 52-card deck, we have an equal chance of each of \\(311\\,875\\,200\\) possible ordered hands, or an equal chance of each of \\(2\\,598\\,960\\) unordered hands.\nIf we split 24 students into six groups of four, there are roughly 4.5 trillion groupings which are each equally likely, if we order neither the groups themselves nor the students within the groups.\n\nIn each of these cases, we can evaluate the probability of certain outcomes by counting the number of cases with the desired attributes and dividing by the number of total cases.\n\n\n\n\n\n\nNote\n\n\n\nFor any finite set \\(\\mathcal{A}\\), let \\(n(\\mathcal{A})\\) be a function which counts the number of elements in \\(\\mathcal{A}\\).\nNow consider an experiment with a set of outcomes, \\(\\Omega\\). Exactly one outcome from \\(\\Omega\\) must happen, and all outcomes are equally likely to happen. For any subset \\(\\mathcal{A} \\subseteq \\Omega\\), the probability of an outcome belonging to \\(\\mathcal{A}\\) can be calculated as: \\[P(\\mathcal{A})=\\frac{n(\\mathcal{A})}{n(\\Omega)}\\]\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe above result is only true for situations with a finite number of equally likely outomes. At the moment, we haven’t learned enough to prove which situations meet that requirement, nor to prove the result is even true: we are proceeding on assumption.\n\n\nFrom here, we can start to calculate some actual probabilities. Suppose we are dealt five cards from a standard 52-card deck: what is the probability of being dealt exactly one pair (two matched cards and three unmatched cards)?\n\nThis question is complicated, because many pairs are actually part of a more valuable hand: three-of-a-kind, four-of-a-kind, a full house, or two pairs. We don’t wish to count those hands, even though they contain pairs.\nAlthough order doesn’t matter, suppose that the first and second cards are paired, while the third, fourth, and fifth cards are unmatched. The first card can be anything (52 choices). The second card must be one of the three remaining cards of the same rank (3 choices). The third card can be anything except the rank of the pair (48 choices). The fourth card can be anything except the rank of the pair or the rank of the third card, since that would form a second pair (44 choices). And likewise for the fifth (40 choices).\n\\(52 \\cdot 3 \\cdot 48 \\cdot 44 \\cdot 40 = 13\\,178\\,880\\) would describe the number of hands where the first two cards form a pair. But there are other hands with one pair, such as when the first and third cards are paired. In fact there are \\({}_5C_2 = 5!/(2!3!) = 10\\) different ways the pair could be arranged in our hand. So there are in fact \\(n(\\mathcal{A})=131\\,788\\,800\\) ordered hands with exactly one pair.\nThat would be among \\(n(\\Omega) = 52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48 = 52!/(52 - 5)! = 311\\,875\\,200\\) total ordered hands.\nIn which case the probability of exactly one pair is \\(n(\\mathcal{A})/n(\\Omega) = 134\\,534\\,400/311\\,875\\,200 \\approx 42.3\\%\\)\n\nLet’s try one more example, this time somewhat more relevant to a real-world data science issue. Consider an allegation of discriminatory hiring practices. 15 pilots interviewed for five open positions at an airline. 10 of the 15 candidates were men, but only 2 of the 5 selected pilots are men. One of the rejected male pilots claims that the hiring process was unfair. What do you think?\n\nThere are \\({}_{10}C_2 = 10!/(2!8!) = 45\\) unordered ways to choose 2 men from among 10 male applicants and \\({}_3C_5 = 5!/(3!2!) = 10\\) ways to choose 3 women2 from among the remaining 5 applicants, so we have \\(n(\\mathcal{A}) = 45 \\cdot 10 = 450\\).\nThere are \\(n(\\Omega) = {}_15C_5 = 15!/(10!5!) = 3003\\) unordered ways to choose 5 pilots from the 15 total applicants.\nIn which case, if we assume that the successful pilots were selected at random (or at any rate not on the basis of their sex), the probability of selecting exactly 2 men and 3 women from 10 men and 5 women would be \\(n(\\mathcal{A})/n(\\Omega) = 450/3003 \\approx 15.0\\%\\).\nIt might be useful to also contemplate the case of picking only one male candidate, or zero male candidates. Using similar calculations, the cumulative probability of picking “so few or fewer” male candidates under an assumption of equal probability would be \\(501/3003 \\approx 16.7\\%\\)\n\nAt the end of the day we cannot tell whether the hiring process was fair or unfair. But we can say that an impartial hiring process which was blind to pilot sex would reach a similar outcome (or a more extreme outcome!) roughly \\(16.7\\%\\) of the time.\n\nNotice how in the first example, I found it easier to count ordered cases, while in the second example I found it easier to count unordered cases. As long as both my numerator and denominator are consistent, the answer will come out the same."
  },
  {
    "objectID": "sets.html#putting-it-into-practice",
    "href": "sets.html#putting-it-into-practice",
    "title": "Set Theory",
    "section": "",
    "text": "At the end of each chapter I will provide some R code snippets to help put the concepts into practice, as well as sample problems (and their solutions!) to help you test your own comprehension of the material.\n\n\n\n\nSet theory is so basic that it’s all around us. For example, when we filter a dataset, or when we merge two different datasets, we are choosing intersections and unions from sets where each element is a row of data. The following functions are rarely used in R, but do directly implement the concepts learned above.\n\nletters[1:10]\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\"\n\nis.element('j',letters)\n\n[1] TRUE\n\nis.element(c('a','B','c'),letters)\n\n[1]  TRUE FALSE  TRUE\n\nunion(1:8,3:10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nintersect(1:8,3:10)\n\n[1] 3 4 5 6 7 8\n\nsetdiff(1:8,3:10)\n\n[1] 1 2\n\nsetequal(c(1,4,9),c(1,9,4))\n\n[1] TRUE\n\n\n\n\n\nSometimes our combinatorics problems cannot be solved with easy helper functions, because of special constraints to the problem. However, the following functions will often come in handy. Note the addition of a custom function for permutations.\n\nfactorial(4)\n\n[1] 24\n\nfactorial(1:5)\n\n[1]   1   2   6  24 120\n\nchoose(n=10,k=3)\n\n[1] 120\n\npermute &lt;- function(n,k) factorial(n)/factorial(n-k)\npermute(n=10,k=3)\n\n[1] 720\n\n\n\n\n\n\n\nEarlier, I calculated the probability that a five-card hand from a standard deck contains exactly one pair. I counted ordered hands to find the answer, though order doesn’t matter. Try to find an unordered solution, which should arrive at the same answer.\n\n\n\n\n\n\n\nSolution (theoretical)\n\n\n\n\n\nThere are 13 ways to choose the rank of the pair, \\({}_4{C}_2\\) ways to choose the two suits of that rank which will form the pair, \\({}_{12}{C}_3\\) ways to choose the three different ranks of the remaining cards, and four choices of suit for each of them. \\[\\frac{13 \\cdot {}_4{C}_2 \\cdot {}_{12}{C}_3 \\cdot 4^3}{{}_{52}{C}_5} \\approx 42.3\\%\\]\n\n\n\n\n13*choose(4,2)*choose(12,3)*4^3/choose(52,5)\n\n\nAssume that birthdays are evenly distributed across a 365-day (non-leap) year. In a classroom of 23 students, what is the probability that at least two of them share a birthday?\n\n\n\n\n\n\n\nSolution (theoretical)\n\n\n\n\n\nThere are so many ways in which two or more students could share birthdays that it will be easier for us to consider the complement: how many ways students could not share any birthdays. Clearly, the first student can have any birthday, but the second will only have 364 qualifying options, etc. \\[P(A) = 1 - P(A^c) = 1 - \\frac{{}_{365}P_{23}}{365^{23}} = 1 - \\frac{365 \\cdot 364 \\cdot \\ldots \\cdot 343}{365^{23}} \\approx 50.7\\%\\] This is sometimes known as the birthday “paradox”, as it may surprise you that such a small classroom would most likely contain a shared birthday.\n\n\n\n\n1-prod(365:343)/365^23\n\n\nIn 1919, the statistician Ronald Fisher heard his colleague, the phycologist Muriel Bristol, claim that she could tell whether milk was added to hot tea, or whether the tea was poured directly onto milk. Fisher tested her by pouring eight cups of tea, four one way and four the other, and serving them to her in a random order which she was able to identify with complete accuracy. If Bristol knew that there were four cups of each type, what would be the probability that she identified them all correctly by chance alone?\n\n\n\n\n\n\n\nSolution (theoretical)\n\n\n\n\n\nThis one’s quite simple! There are \\({}_8C_4 = 70\\) ways to arrange the four milk-first cups among the eight total cups, and if Dr. Bristol had been guessing at random she would have selected each arrangement with equal probability, and so would have chosen the right arrangement with only \\(1/70 \\approx 1.4\\%\\) probability.\n\n\n\n\n1/choose(8,4)\n\n\nHow would the problem above change if Muriel Bristol had not known there were four cups of each type?\n\n\n\n\n\n\n\nSolution (theoretical)\n\n\n\n\n\nWithout knowing in advance how many cups had milk poured first, Bristol would have been guessing blindly on each new cup, with her guesses for the first few cups providing no information on the latter cups. The experiment now allows \\(2^8=256\\) possible cup sequences, with only one being correct, so if she were guessing at random then a perfect score would only occur with probability \\(1/256 \\approx 0.4\\%\\).\n\n\n\n\n1/2^8"
  },
  {
    "objectID": "sets.html#footnotes",
    "href": "sets.html#footnotes",
    "title": "Set Theory",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNotice how quickly these grow: even modern distributed computing has a hard time with large factorials.↩︎\nOr non-binary pilots!↩︎"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "I could use these notes to teach probability and statistics “for statisticians”. Probability theory is elegant and contemplative. Graduate-level work can be completed using only pencil and paper, almost entirely with symbolic notation. The tools we will study here were built from such theoretical work. However, the students I teach are not (generally) headed into pure research, but rather into industry. They may never be asked to author a proof, but they will be asked to draw conclusions about the world from noisy, biased, incomplete, or insufficient data.\nInstead, I want to teach probability and statistics “for data scientists”. Data science is a tradecraft, not a body of theory, and it allows people and organizations to answer questions, solve problems, and achieve goals. Data science which does not help us to confront real problems or understand real datasets is not truly data science after all. So I will try to stay focused on that mission in these notes.\nWe will learn statistics as we go, and I will try to present the statistical theory in a way that is easily understood by non-statisticians, and to complement rather than duplicate the materials you might find elsewhere. Therefore, this document blends aspects of a textbook, a set of lecture slides, and a set of hands-on workshops. It would pair very well with a true textbook, and I have several recommendations:\n\nPractical Statistics for Data Scientists 2nd edition, by Peter Bruce, Andrew Bruce, and Peter Gedeck\nFoundations and Applications of Statistics: An Introduction using R 2nd edition, by Randall Pruim\nFoundations of Statistics for Data Scientists, with R and Python, by Alan Agresti and Maria Kateri\nIntroduction to Probability 2nd edition, by Joseph Blitzstein and Jessica Hwang\n\n\n\n\nI assembled these notes using Quarto, a publishing system built around the Pandoc markdown language. I wrote all the code backing these notes in R, and alongside every figure or table you can find the corresponding R code.\nNeither the text nor the R code in these notes were generated by AI tools. AI assistance was used to brainstorm case studies and examples, and to help with the layout and tech stack of the document itself.\nThese notes began as a (clunky) Word document shared with my students across several academic quarters. Their questions, requests for clarification, and occasional corrections have all vastly improved my content, and I thank them for their help.\n\n\n\nUnfortunately, no two statistical sources use exactly the same notation. Any choice I make will inevitably differ from other sources you consult. I will follow the common conventions when I can, and beg your understanding when I cannot. I will occasionally use two different options to represent the same concept, not because I wish to confuse you, but because sometimes complete consistency creates impossible formatting challenges or even greater ambiguity.\n\nObservations from a sample and realizations of a random variable will use lowercase Latin letters, with subscripts as needed:\n\n\\[x_1,x_2,...,x_n\\]\n\nRandom variables themselves will use uppercase Latin letters.1 Subscripts on random variables suggest relations between them, such as two predictors for the same response:\n\n\\[Y,Z,X_1,X_2\\]\n\nTrue parameters of a model will often use Greek lowercase letters:2\n\n\\[\\mu,\\sigma^2,\\beta_0,\\beta_1\\]\n\nEstimates of random variables will use a ‘hat’ accent above the original symbol or use the matching lowercase Latin alphabet letter:3\n\n\\[\\hat{\\mu},s^2,\\hat{\\beta}_0,b_1\\]\n\nVectors (including univariate samples) will use an arrow accent or boldface lowercase letters. Matrices will use bold uppercase letters (not italic):\n\n\\[\\vec{u},\\boldsymbol{y},\\mathbf{X}\\]\n\nElements of a matrix or data with multiple indices will use a double subscript:\n\n\\[\\mathbf{X} = \\begin{bmatrix} x_{1,1} & x_{1,2} \\\\ x_{2,1} & x_{2,2} \\end{bmatrix}, y_{i \\bullet} = \\frac{1}{n_i}\\sum_j y_{i,j}\\]\n\nBy convention some terms are stylized using blackboard bold, including the set of reals and the set of integers, expectation and variance.\n\n\\[\\mathbb{R},\\mathbb{Z},\\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\\]\n\nSets which do not use blackboard bold may instead use a script typeface, such as when the letter F denotes an event space rather than a function:\n\n\\[\\mathcal{A},\\mathcal{F}\\]",
    "crumbs": [
      "Home",
      "Placeholder",
      "Lab"
    ]
  },
  {
    "objectID": "intro.html#my-intended-scope",
    "href": "intro.html#my-intended-scope",
    "title": "Introduction",
    "section": "",
    "text": "I could use these notes to teach probability and statistics “for statisticians”. Probability theory is elegant and contemplative. Graduate-level work can be completed using only pencil and paper, almost entirely with symbolic notation. The tools we will study here were built from such theoretical work. However, the students I teach are not (generally) headed into pure research, but rather into industry. They may never be asked to author a proof, but they will be asked to draw conclusions about the world from noisy, biased, incomplete, or insufficient data.\nInstead, I want to teach probability and statistics “for data scientists”. Data science is a tradecraft, not a body of theory, and it allows people and organizations to answer questions, solve problems, and achieve goals. Data science which does not help us to confront real problems or understand real datasets is not truly data science after all. So I will try to stay focused on that mission in these notes.\nWe will learn statistics as we go, and I will try to present the statistical theory in a way that is easily understood by non-statisticians, and to complement rather than duplicate the materials you might find elsewhere. Therefore, this document blends aspects of a textbook, a set of lecture slides, and a set of hands-on workshops. It would pair very well with a true textbook, and I have several recommendations:\n\nPractical Statistics for Data Scientists 2nd edition, by Peter Bruce, Andrew Bruce, and Peter Gedeck\nFoundations and Applications of Statistics: An Introduction using R 2nd edition, by Randall Pruim\nFoundations of Statistics for Data Scientists, with R and Python, by Alan Agresti and Maria Kateri\nIntroduction to Probability 2nd edition, by Joseph Blitzstein and Jessica Hwang",
    "crumbs": [
      "Home",
      "Placeholder",
      "Lab"
    ]
  },
  {
    "objectID": "intro.html#how-these-notes-were-made",
    "href": "intro.html#how-these-notes-were-made",
    "title": "Introduction",
    "section": "",
    "text": "I assembled these notes using Quarto, a publishing system built around the Pandoc markdown language. I wrote all the code backing these notes in R, and alongside every figure or table you can find the corresponding R code.\nNeither the text nor the R code in these notes were generated by AI tools. AI assistance was used to brainstorm case studies and examples, and to help with the layout and tech stack of the document itself.\nThese notes began as a (clunky) Word document shared with my students across several academic quarters. Their questions, requests for clarification, and occasional corrections have all vastly improved my content, and I thank them for their help.",
    "crumbs": [
      "Home",
      "Placeholder",
      "Lab"
    ]
  },
  {
    "objectID": "intro.html#a-note-on-notation",
    "href": "intro.html#a-note-on-notation",
    "title": "Introduction",
    "section": "",
    "text": "Unfortunately, no two statistical sources use exactly the same notation. Any choice I make will inevitably differ from other sources you consult. I will follow the common conventions when I can, and beg your understanding when I cannot. I will occasionally use two different options to represent the same concept, not because I wish to confuse you, but because sometimes complete consistency creates impossible formatting challenges or even greater ambiguity.\n\nObservations from a sample and realizations of a random variable will use lowercase Latin letters, with subscripts as needed:\n\n\\[x_1,x_2,...,x_n\\]\n\nRandom variables themselves will use uppercase Latin letters.1 Subscripts on random variables suggest relations between them, such as two predictors for the same response:\n\n\\[Y,Z,X_1,X_2\\]\n\nTrue parameters of a model will often use Greek lowercase letters:2\n\n\\[\\mu,\\sigma^2,\\beta_0,\\beta_1\\]\n\nEstimates of random variables will use a ‘hat’ accent above the original symbol or use the matching lowercase Latin alphabet letter:3\n\n\\[\\hat{\\mu},s^2,\\hat{\\beta}_0,b_1\\]\n\nVectors (including univariate samples) will use an arrow accent or boldface lowercase letters. Matrices will use bold uppercase letters (not italic):\n\n\\[\\vec{u},\\boldsymbol{y},\\mathbf{X}\\]\n\nElements of a matrix or data with multiple indices will use a double subscript:\n\n\\[\\mathbf{X} = \\begin{bmatrix} x_{1,1} & x_{1,2} \\\\ x_{2,1} & x_{2,2} \\end{bmatrix}, y_{i \\bullet} = \\frac{1}{n_i}\\sum_j y_{i,j}\\]\n\nBy convention some terms are stylized using blackboard bold, including the set of reals and the set of integers, expectation and variance.\n\n\\[\\mathbb{R},\\mathbb{Z},\\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\\]\n\nSets which do not use blackboard bold may instead use a script typeface, such as when the letter F denotes an event space rather than a function:\n\n\\[\\mathcal{A},\\mathcal{F}\\]",
    "crumbs": [
      "Home",
      "Placeholder",
      "Lab"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe most common exception will be my use of the Greek lowercase epsilon \\((\\varepsilon)\\) for an error term, per tradition.↩︎\nWith many exceptions when parameters are traditionally named otherwise, such as using ‘a’ and ‘b’ for the parameters of a Uniform distribution or ‘df’ for degrees of freedom in a t-distribution.↩︎\nThe hat accent is properly called a circumflex, but statisticians say ‘hat’, e.g. the estimate for ‘mu’ is ‘mu-hat’.↩︎",
    "crumbs": [
      "Home",
      "Placeholder",
      "Lab"
    ]
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "SAURON",
    "section": "",
    "text": "Blah blah\n\n\nNo?"
  },
  {
    "objectID": "chapter4.html#see-if-this-helps",
    "href": "chapter4.html#see-if-this-helps",
    "title": "SAURON",
    "section": "",
    "text": "No?"
  },
  {
    "objectID": "chapter5.html",
    "href": "chapter5.html",
    "title": "SAURON",
    "section": "",
    "text": "Simple linear regression\nblah blah"
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "SAURON",
    "section": "",
    "text": "Properties of random variables\nBlah blah"
  },
  {
    "objectID": "chapter6.html",
    "href": "chapter6.html",
    "title": "SAURON",
    "section": "",
    "text": "Logistic regression\nblah blah"
  },
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "It might surprise you to learn that mathematicians did not complete a formal system for defining probability until Andrey Kolmogorov’s work in the 1930s. Many important insights and results had been noticed by earlier mathematicians, but our “classical” understanding of probability is still less than 100 years old. More recently, mathematicians have explored other systems of probability by relaxing or modifying Kolmogorov’s axioms. The most famous alternative system of probability is the “Bayesian” school, which I will not discuss here.\n\n\nKolmogorov’s definition of probability relies on the idea of an experiment. The “experiment” can be very broad or abstract, including actual experiments performed by scientists in laboratories but also natural phenomenon such as tomorrow’s weather and human activities such as a hedge fund’s annual performance.\nImagine an experiment made up of many different trials of the same experimental process. Each trial ends in a single outcome, and there are multiple possible outcomes (possibly an infinite number of outcomes). For example, let us consider an experiment where each trial involves flipping two coins, each marked H for heads and T for tails. Then the four ordered outcomes would be:\n\n\n\n\\[\\qquad \\, \\Large{\\{\\mathrm{HH},\\mathrm{TH},\\mathrm{TH},\\mathrm{TT}\\}}\\] \\[{}_\\mathrm{First\\ flip}{}^\\nearrow \\quad {}^\\nwarrow{}_\\mathrm{Second\\ flip}\\]\n\n\nFigure 1: Outcomes of an experiment which flips two coins\n\n\n\nEach trial ends in one outcome, but we will want to consider combinations of outcomes, which will be called events. For example, the event {HH, HT, TH} includes three outcomes, and we could think of this event as “a trial resulting in at least one head”. One special event is the empty set (seen earlier in ?@sec-sets), sometimes written \\(\\emptyset\\), which is an event containing no outcomes. This event never happens(!) but we still find it mathematically useful, just like we find zero helpful even if we don’t “see” zeroes around us. Set theory teaches us that for \\(n\\) different elements, there are \\(2^n\\) ways to choose combinations of those elements, which means that with four outcomes there are sixteen events:\n\n\n\n\\[\\begin{array}{ll} \\scriptsize{\\textit{1 event with no outcomes}} & \\emptyset \\\\\n\\scriptsize{\\textit{4 events with one outcome}} & \\{\\mathrm{HH}\\},\\{\\mathrm{HT}\\},\\{\\mathrm{TH}\\},\\{\\mathrm{TT}\\} \\\\\n\\scriptsize{\\textit{6 events with two outcomes}} & \\{\\mathrm{HH},\\mathrm{HT}\\},\\{\\mathrm{HH},\\mathrm{TH}\\},\\{\\mathrm{HH},\\mathrm{TT}\\},\\{\\mathrm{HT},\\mathrm{TH}\\},\\{\\mathrm{HT},\\mathrm{TT}\\},\\{\\mathrm{TH},\\mathrm{TT}\\} \\\\\n\\scriptsize{\\textit{4 events with three outcomes}} & \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH}\\},\\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TT}\\},\\{\\mathrm{HH},\\mathrm{TH},\\mathrm{TT}\\},\\{\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\} \\\\\n\\scriptsize{\\textit{1 event with four outcomes}} & \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\} \\end{array}\\]\n\n\nFigure 2: Events of an experiment which flips two coins\n\n\n\nNotice that these combinations are unordered subsets of the outcomes. For example, I did not separately list both {HT, TT} and {TT, HT} as two different events, since they both contain the same two outcomes. On the other hand, the nature of our experiment requires that the order of the flips does matter: the event {HT, TT} is meaningfully different from the event {TH, TT}.\nLet’s review:\n\n\n\n\n\n\nNote\n\n\n\nThe outcomes of an experiment are the set of all possible results from a single trial.\nThe event space of an experiment is the set of all unordered combinations of the outcomes including the empty set (\\(\\emptyset\\)), each individual outcome, and all pairs, triplets, etc. of the outcomes.\n\n\n\n\n\nHaving set up this idea of an experiment, we now define probability as a way of assigning a numeric score to each event in an experiment.\nThere are of course many ways we could make numeric scores for each event, and most of them are unhelpful. So we will need rules to help separate “probability” from all the other, unhelpful ways we could assign scores to events. Andrey Kolmogorov proposed the following three rules, often called the axioms of probability. If we assume these rules, all of probability and (classical) parametric statistics will follow:\n\n\n\n\n\n\nNote\n\n\n\nLet the triplet \\(\\Omega,\\mathcal{F},P\\) define an experiment, where:\n\n\\(\\Omega\\) is the set of outcomes of the experiment (possible results of a single trial)\n\\(\\mathcal{F}\\) is the set of events of the experiment (combinations of outcomes)\n\\(P(E)\\) is a function which assigns a real number to each event \\(E\\) in \\(\\mathcal{F}\\)\n\nIf we choose \\(P\\) using the following three conditions,\n\n\\(P(E) \\geq 0 \\quad \\forall E \\in F\\) (All events have non-negative probability)\n\\(P(\\Omega)=1\\) (The probability of observing any of the outcomes is 1)\nIf a group of events \\(E_1,E_1,\\ldots,E_n\\) are disjoint then \\(P(\\bigcup_{i=1}^n E_i)=\\sum_{i=1}^n P(E_i)\\) (The combined probability of a union of mutually exclusive events is equal to the sum of the probabilities of each individual event)\n\nThen we say that \\(P\\) measures probability.\n\n\nNow that we have defined probability, let’s review some basic properties of how probability works. You have probably seen these before, or at least they should make a certain amount of sense. I will not prove them here, but they can all be proven from the axioms and other simple mathematical theorems.\n\n\n\n\n\n\nNote\n\n\n\nLet the triplet \\(\\Omega,\\mathcal{F},P\\) define an experiment, and let \\(A\\) and \\(B\\) be events within \\(\\mathcal{F}\\):\n\n\\(P(A^c ) = 1 - P(A)\\)\n\\(P(A \\cup B) = P(A) + P(B) - (A \\cap B)\\)\nIf A and B are disjoint (mutually exclusive), then \\(P(A \\cap B) = P(A) + P(B)\\)\n\n\n\nThe first result above simply confirms that the probability of an event happening is equivalent to one minus the probability of the event not happening. The second result helps us to find the probability that \\(A\\) or \\(B\\) will happen (you can think of union as ‘or’ operator and intersection as ‘and’). If we simply add all the probability of \\(A\\) to all the probability of \\(B\\), we will double-count their intersection, which is in both sets. So we must subtract one intersection… unless the two sets are disjoint, in which case there is no problem!\n\n\nOften we wish to study the relationships between two or more experiments. For example, consider someone who takes a diagnostic test for a particular disease:\n\nOne experiment is whether the person actually has the disease\nA different experiment is whether the person tests positive for the disease, regardless of whether they actually have it\n\nMost people who test for a disease have some valid concern, and so among the test-takers let us assume that \\(P(\\mathrm{Disease})=0.60\\). Let us further assume that the test is imperfect, with few fase positives but lots of false negatives, and so \\(P(\\mathrm{Positive})=0.45\\).\nThese two pieces of information are not enough for us to understand the full implications of a positive test. A clearer sense of how these two experiments relate to each other could be expressed in a table as follows:\n\n\n\n\\[ \\begin{array}{rrccc} & & & \\textbf{Test Result} & \\\\ & & \\mathrm{Positive} & \\mathrm{Negative} & \\textit{Total} \\\\ & \\mathrm{Has\\ Disease} & 0.44 & 0.16 & \\textit{0.60} \\\\ \\textbf{Health} & \\mathrm{Does\\ Not} & 0.01 & 0.39 & \\textit{0.40} \\\\ & \\textit{Total} & \\textit{0.45} & \\textit{0.55} & \\end{array}\\]\n\n\nFigure 3: Contingency table of joint and marginal probabilities\n\n\n\nThe four cells at the top right are joint probabilities, which tell you the chance of simultaneously observing two pieces of information. For example, among people who test for this disease, 39% do not have the disease and yet test negative.\nThe four italicized cells along the bottom and right sides are marginal probabilities, which tell you the overall chance of one experiment’s outcome averaged over all possible results from the second experiment. Notice that we can compute these marginal probabilities by totaling the rows and columns of the joint probabilities in the literal margins of the table.\nFrom the combination of the joint and marginal probabilities, we can compute the conditional probabilities, which show us how the outcomes of one experiment become more or less likely once we know the result of the other. When we learn about the other experiment, we change the event space of the first experiment, since some joint outcomes are no longer possible. Events containing those outcomes are removed from \\(\\mathcal{F}\\). Probabilities shift such that the total of all remaining events sum to 1.\nIf we test positive, what is the probability we have the disease? We can disregard the second column above: we now “live” in the first column, totaling 45% (those who test positive). For every 45 people who test positive, 44 test positive and have the disease, while 1 tests positive and does not have the disease. Therefore, the probability of having the disease given a positive test is \\(0.44/0.45 \\approx 0.978.\\) We can formalize this result:\n\n\n\n\n\n\nNote\n\n\n\nLet the triplet \\(\\Omega,\\mathcal{F},P\\) define an experiment, and let \\(A\\) and \\(B\\) be events within \\(\\mathcal{F}\\). The conditional probability of \\(A\\) given \\(B\\) is written \\(P(A|B)\\) and defined, \\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\n\nWe can derive three useful rules from this definition of conditional probability. The first flows simply from the above formula if we multiply both sides by \\(P(B)\\):\n\n\n\n\n\n\nNote\n\n\n\nLet the triplet \\(\\Omega,\\mathcal{F},P\\) define an experiment, and let \\(A\\) and \\(B\\) be events within \\(\\mathcal{F}\\). Then, \\[P(A \\cap B) = P(A|B) \\cdot P(B)\\]\n\n\nThis result allows us to compute the probability of a series of events by multiplying the branching probabilities of each conditional link. Consider an unfair coin which lands heads (“H”) 40% of the time and tails (“T”) 60% of the time. What is the probability of the sequence THH?\n\n\n\n\n\n\n\n\n---\nconfig:\n  look: handDrawn\n  theme: neutral\n---\nflowchart LR\n  A((Begin)) -- 0.4 --&gt; B[H _ _]\n  A -- 0.6 --&gt; C[T _ _]\n  C -- 0.4 --&gt; D[T H _]\n  C -- 0.6 --&gt; E[T T _]\n  D -- 0.4 --&gt; F[T H H]\n  D -- 0.6 --&gt; G[T H T]\n  classDef stop stroke:red,color:red\n  class B,E,G stop\n\n\n\n\n\n\n\n\nFigure 4: Chain of coin flip probabilities\n\n\n\nUsing the rule above, we can see that the probability of the full sequence could be expressed as P(THH)=P(T)∙P(TH|T)∙P(THT|TH)=0.6∙0.4∙0.6=0.144. The second useful result is known as The Law of Complete Probability, and allows us to compute the probability of an event by aggregating its conditional probability among a group of exhaustive and mutually exclusive conditions, meaning that exactly one of the conditions is always true. Let the triplet Ω,F,P define an experiment, and let A be an event within F. Let B_1,B_2,…,B_n also be events within F such that all events B_i are mutually exclusive and ∑_i▒P(B_i ) =1 Then, P(A)=∑_i▒〖P(A|B_i )∙P(B_i ) 〗 As an example, consider the proportion of time that my heart rate is elevated above 80 beats per minute. Elevated heart rates are rare in my sleep, perhaps occurring only during stressful dreams (perhaps 2% of my sleep?). When I’m awake, 80bpm is near my resting heart rate, and so I might spend 25% of my waking hours at rates above that. If I sleep on average 7 hours a day, then we can calculate P(elevated)=P(elevated|asleep)∙P(asleep)+P(elevated|awake)∙P(awake) =0.02∙(7/24)+0.25∙(17/24) ≈18.3% The last useful result I will mention here is a way to calculate P(B|A) from P(A|B). This formula is known as Bayes Theorem, after the English clergyman Reverend Thomas Bayes. Bayes was not a trained mathematician, but his natural curiosity and diligent amateur study led him to this significant result, published posthumously: Let the triplet Ω,F,P define an experiment, and let A and B be events within F. Then, P(B|A)=(P(A|B)∙P(B))/P(A) If we further assume that instead of one event B we have many events B_1,B_2,…,B_n such that all events B_i are mutually exclusive and ∑_i▒P(B_i ) =1, then further, P(B_j |A)=(P(A|B_j )∙P(B_j ))/(∑_i▒〖P(A|B_i )∙P(B_i ) 〗) The second equation above flows from the first equation when we apply our prior result of the Law of Complete Probability. For an example of the first equation at work, consider the heart rate hypothetical above: P(awake|elevated)=(P(elevated|awake)∙P(awake))/P(elevated) =(0.25∙(17/24))/(0.1829…)≈0.968 Notice the distinction: The probability that my heart rate is elevated given that I’m awake is pretty low: only 25% (I don’t exercise as often as I should). But the probability that I’m awake given that my heart rate is elevated is very high: almost 97%. This is both because my heart rarely races in my sleep, and because I’m more often awake than asleep. Bayes Theorem has lent its name to an alternative system of probability known as Bayesian probability, because they both allow the user to update their prior beliefs as more and more data are observed. This broader Bayesian system relaxes some of Kolmogorov’s axioms and creates entirely new models and computations which some “classical” or “frequentist” statisticians find controversial. However, using Bayes Theorem itself is uncontroversial and perfectly valid under Kolmogorov’s axioms."
  },
  {
    "objectID": "probability.html#experiments",
    "href": "probability.html#experiments",
    "title": "Probability Theory",
    "section": "",
    "text": "Kolmogorov’s definition of probability relies on the idea of an experiment. The “experiment” can be very broad or abstract, including actual experiments performed by scientists in laboratories but also natural phenomenon such as tomorrow’s weather and human activities such as a hedge fund’s annual performance.\nImagine an experiment made up of many different trials of the same experimental process. Each trial ends in a single outcome, and there are multiple possible outcomes (possibly an infinite number of outcomes). For example, let us consider an experiment where each trial involves flipping two coins, each marked H for heads and T for tails. Then the four ordered outcomes would be:\n\n\n\n\\[\\qquad \\, \\Large{\\{\\mathrm{HH},\\mathrm{TH},\\mathrm{TH},\\mathrm{TT}\\}}\\] \\[{}_\\mathrm{First\\ flip}{}^\\nearrow \\quad {}^\\nwarrow{}_\\mathrm{Second\\ flip}\\]\n\n\nFigure 1: Outcomes of an experiment which flips two coins\n\n\n\nEach trial ends in one outcome, but we will want to consider combinations of outcomes, which will be called events. For example, the event {HH, HT, TH} includes three outcomes, and we could think of this event as “a trial resulting in at least one head”. One special event is the empty set (seen earlier in ?@sec-sets), sometimes written \\(\\emptyset\\), which is an event containing no outcomes. This event never happens(!) but we still find it mathematically useful, just like we find zero helpful even if we don’t “see” zeroes around us. Set theory teaches us that for \\(n\\) different elements, there are \\(2^n\\) ways to choose combinations of those elements, which means that with four outcomes there are sixteen events:\n\n\n\n\\[\\begin{array}{ll} \\scriptsize{\\textit{1 event with no outcomes}} & \\emptyset \\\\\n\\scriptsize{\\textit{4 events with one outcome}} & \\{\\mathrm{HH}\\},\\{\\mathrm{HT}\\},\\{\\mathrm{TH}\\},\\{\\mathrm{TT}\\} \\\\\n\\scriptsize{\\textit{6 events with two outcomes}} & \\{\\mathrm{HH},\\mathrm{HT}\\},\\{\\mathrm{HH},\\mathrm{TH}\\},\\{\\mathrm{HH},\\mathrm{TT}\\},\\{\\mathrm{HT},\\mathrm{TH}\\},\\{\\mathrm{HT},\\mathrm{TT}\\},\\{\\mathrm{TH},\\mathrm{TT}\\} \\\\\n\\scriptsize{\\textit{4 events with three outcomes}} & \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH}\\},\\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TT}\\},\\{\\mathrm{HH},\\mathrm{TH},\\mathrm{TT}\\},\\{\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\} \\\\\n\\scriptsize{\\textit{1 event with four outcomes}} & \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\} \\end{array}\\]\n\n\nFigure 2: Events of an experiment which flips two coins\n\n\n\nNotice that these combinations are unordered subsets of the outcomes. For example, I did not separately list both {HT, TT} and {TT, HT} as two different events, since they both contain the same two outcomes. On the other hand, the nature of our experiment requires that the order of the flips does matter: the event {HT, TT} is meaningfully different from the event {TH, TT}.\nLet’s review:\n\n\n\n\n\n\nNote\n\n\n\nThe outcomes of an experiment are the set of all possible results from a single trial.\nThe event space of an experiment is the set of all unordered combinations of the outcomes including the empty set (\\(\\emptyset\\)), each individual outcome, and all pairs, triplets, etc. of the outcomes."
  },
  {
    "objectID": "probability.html#the-axioms-of-probability",
    "href": "probability.html#the-axioms-of-probability",
    "title": "Probability Theory",
    "section": "",
    "text": "Having set up this idea of an experiment, we now define probability as a way of assigning a numeric score to each event in an experiment.\nThere are of course many ways we could make numeric scores for each event, and most of them are unhelpful. So we will need rules to help separate “probability” from all the other, unhelpful ways we could assign scores to events. Andrey Kolmogorov proposed the following three rules, often called the axioms of probability. If we assume these rules, all of probability and (classical) parametric statistics will follow:\n\n\n\n\n\n\nNote\n\n\n\nLet the triplet \\(\\Omega,\\mathcal{F},P\\) define an experiment, where:\n\n\\(\\Omega\\) is the set of outcomes of the experiment (possible results of a single trial)\n\\(\\mathcal{F}\\) is the set of events of the experiment (combinations of outcomes)\n\\(P(E)\\) is a function which assigns a real number to each event \\(E\\) in \\(\\mathcal{F}\\)\n\nIf we choose \\(P\\) using the following three conditions,\n\n\\(P(E) \\geq 0 \\quad \\forall E \\in F\\) (All events have non-negative probability)\n\\(P(\\Omega)=1\\) (The probability of observing any of the outcomes is 1)\nIf a group of events \\(E_1,E_1,\\ldots,E_n\\) are disjoint then \\(P(\\bigcup_{i=1}^n E_i)=\\sum_{i=1}^n P(E_i)\\) (The combined probability of a union of mutually exclusive events is equal to the sum of the probabilities of each individual event)\n\nThen we say that \\(P\\) measures probability.\n\n\nNow that we have defined probability, let’s review some basic properties of how probability works. You have probably seen these before, or at least they should make a certain amount of sense. I will not prove them here, but they can all be proven from the axioms and other simple mathematical theorems.\n\n\n\n\n\n\nNote\n\n\n\nLet the triplet \\(\\Omega,\\mathcal{F},P\\) define an experiment, and let \\(A\\) and \\(B\\) be events within \\(\\mathcal{F}\\):\n\n\\(P(A^c ) = 1 - P(A)\\)\n\\(P(A \\cup B) = P(A) + P(B) - (A \\cap B)\\)\nIf A and B are disjoint (mutually exclusive), then \\(P(A \\cap B) = P(A) + P(B)\\)\n\n\n\nThe first result above simply confirms that the probability of an event happening is equivalent to one minus the probability of the event not happening. The second result helps us to find the probability that \\(A\\) or \\(B\\) will happen (you can think of union as ‘or’ operator and intersection as ‘and’). If we simply add all the probability of \\(A\\) to all the probability of \\(B\\), we will double-count their intersection, which is in both sets. So we must subtract one intersection… unless the two sets are disjoint, in which case there is no problem!\n\n\nOften we wish to study the relationships between two or more experiments. For example, consider someone who takes a diagnostic test for a particular disease:\n\nOne experiment is whether the person actually has the disease\nA different experiment is whether the person tests positive for the disease, regardless of whether they actually have it\n\nMost people who test for a disease have some valid concern, and so among the test-takers let us assume that \\(P(\\mathrm{Disease})=0.60\\). Let us further assume that the test is imperfect, with few fase positives but lots of false negatives, and so \\(P(\\mathrm{Positive})=0.45\\).\nThese two pieces of information are not enough for us to understand the full implications of a positive test. A clearer sense of how these two experiments relate to each other could be expressed in a table as follows:\n\n\n\n\\[ \\begin{array}{rrccc} & & & \\textbf{Test Result} & \\\\ & & \\mathrm{Positive} & \\mathrm{Negative} & \\textit{Total} \\\\ & \\mathrm{Has\\ Disease} & 0.44 & 0.16 & \\textit{0.60} \\\\ \\textbf{Health} & \\mathrm{Does\\ Not} & 0.01 & 0.39 & \\textit{0.40} \\\\ & \\textit{Total} & \\textit{0.45} & \\textit{0.55} & \\end{array}\\]\n\n\nFigure 3: Contingency table of joint and marginal probabilities\n\n\n\nThe four cells at the top right are joint probabilities, which tell you the chance of simultaneously observing two pieces of information. For example, among people who test for this disease, 39% do not have the disease and yet test negative.\nThe four italicized cells along the bottom and right sides are marginal probabilities, which tell you the overall chance of one experiment’s outcome averaged over all possible results from the second experiment. Notice that we can compute these marginal probabilities by totaling the rows and columns of the joint probabilities in the literal margins of the table.\nFrom the combination of the joint and marginal probabilities, we can compute the conditional probabilities, which show us how the outcomes of one experiment become more or less likely once we know the result of the other. When we learn about the other experiment, we change the event space of the first experiment, since some joint outcomes are no longer possible. Events containing those outcomes are removed from \\(\\mathcal{F}\\). Probabilities shift such that the total of all remaining events sum to 1.\nIf we test positive, what is the probability we have the disease? We can disregard the second column above: we now “live” in the first column, totaling 45% (those who test positive). For every 45 people who test positive, 44 test positive and have the disease, while 1 tests positive and does not have the disease. Therefore, the probability of having the disease given a positive test is \\(0.44/0.45 \\approx 0.978.\\) We can formalize this result:\n\n\n\n\n\n\nNote\n\n\n\nLet the triplet \\(\\Omega,\\mathcal{F},P\\) define an experiment, and let \\(A\\) and \\(B\\) be events within \\(\\mathcal{F}\\). The conditional probability of \\(A\\) given \\(B\\) is written \\(P(A|B)\\) and defined, \\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\n\nWe can derive three useful rules from this definition of conditional probability. The first flows simply from the above formula if we multiply both sides by \\(P(B)\\):\n\n\n\n\n\n\nNote\n\n\n\nLet the triplet \\(\\Omega,\\mathcal{F},P\\) define an experiment, and let \\(A\\) and \\(B\\) be events within \\(\\mathcal{F}\\). Then, \\[P(A \\cap B) = P(A|B) \\cdot P(B)\\]\n\n\nThis result allows us to compute the probability of a series of events by multiplying the branching probabilities of each conditional link. Consider an unfair coin which lands heads (“H”) 40% of the time and tails (“T”) 60% of the time. What is the probability of the sequence THH?\n\n\n\n\n\n\n\n\n---\nconfig:\n  look: handDrawn\n  theme: neutral\n---\nflowchart LR\n  A((Begin)) -- 0.4 --&gt; B[H _ _]\n  A -- 0.6 --&gt; C[T _ _]\n  C -- 0.4 --&gt; D[T H _]\n  C -- 0.6 --&gt; E[T T _]\n  D -- 0.4 --&gt; F[T H H]\n  D -- 0.6 --&gt; G[T H T]\n  classDef stop stroke:red,color:red\n  class B,E,G stop\n\n\n\n\n\n\n\n\nFigure 4: Chain of coin flip probabilities\n\n\n\nUsing the rule above, we can see that the probability of the full sequence could be expressed as P(THH)=P(T)∙P(TH|T)∙P(THT|TH)=0.6∙0.4∙0.6=0.144. The second useful result is known as The Law of Complete Probability, and allows us to compute the probability of an event by aggregating its conditional probability among a group of exhaustive and mutually exclusive conditions, meaning that exactly one of the conditions is always true. Let the triplet Ω,F,P define an experiment, and let A be an event within F. Let B_1,B_2,…,B_n also be events within F such that all events B_i are mutually exclusive and ∑_i▒P(B_i ) =1 Then, P(A)=∑_i▒〖P(A|B_i )∙P(B_i ) 〗 As an example, consider the proportion of time that my heart rate is elevated above 80 beats per minute. Elevated heart rates are rare in my sleep, perhaps occurring only during stressful dreams (perhaps 2% of my sleep?). When I’m awake, 80bpm is near my resting heart rate, and so I might spend 25% of my waking hours at rates above that. If I sleep on average 7 hours a day, then we can calculate P(elevated)=P(elevated|asleep)∙P(asleep)+P(elevated|awake)∙P(awake) =0.02∙(7/24)+0.25∙(17/24) ≈18.3% The last useful result I will mention here is a way to calculate P(B|A) from P(A|B). This formula is known as Bayes Theorem, after the English clergyman Reverend Thomas Bayes. Bayes was not a trained mathematician, but his natural curiosity and diligent amateur study led him to this significant result, published posthumously: Let the triplet Ω,F,P define an experiment, and let A and B be events within F. Then, P(B|A)=(P(A|B)∙P(B))/P(A) If we further assume that instead of one event B we have many events B_1,B_2,…,B_n such that all events B_i are mutually exclusive and ∑_i▒P(B_i ) =1, then further, P(B_j |A)=(P(A|B_j )∙P(B_j ))/(∑_i▒〖P(A|B_i )∙P(B_i ) 〗) The second equation above flows from the first equation when we apply our prior result of the Law of Complete Probability. For an example of the first equation at work, consider the heart rate hypothetical above: P(awake|elevated)=(P(elevated|awake)∙P(awake))/P(elevated) =(0.25∙(17/24))/(0.1829…)≈0.968 Notice the distinction: The probability that my heart rate is elevated given that I’m awake is pretty low: only 25% (I don’t exercise as often as I should). But the probability that I’m awake given that my heart rate is elevated is very high: almost 97%. This is both because my heart rarely races in my sleep, and because I’m more often awake than asleep. Bayes Theorem has lent its name to an alternative system of probability known as Bayesian probability, because they both allow the user to update their prior beliefs as more and more data are observed. This broader Bayesian system relaxes some of Kolmogorov’s axioms and creates entirely new models and computations which some “classical” or “frequentist” statisticians find controversial. However, using Bayes Theorem itself is uncontroversial and perfectly valid under Kolmogorov’s axioms."
  }
]