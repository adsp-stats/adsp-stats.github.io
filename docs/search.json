[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Analysis Using R: Online Notes",
    "section": "",
    "text": "Introduction\nHello! I’m Jonathan, and I want to teach you statistics. I have designed this website to accompany the University of Chicago course ADSP 31014 “Statistical Models for Data Science”, since I was unable to find a single textbook which covered all of the requisite material, and and did not want my students to buy three expensive textbooks for a ten-week class.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-howtouse",
    "href": "index.html#sec-howtouse",
    "title": "Statistical Analysis Using R: Online Notes",
    "section": "How to use this website",
    "text": "How to use this website\nThe left-side chapter headings and search bar will help you to select different pages. The right-side table of contents will help you to navigate within each page.\nThe appendices contain notes on common probability distributions, a few proofs (which might be of interest but are not necessary to progress through the material), and a table of commonly used symbols and their meanings. For more on how to read these chapters, please see the last section below, A note on notation.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#purpose-and-scope",
    "href": "index.html#purpose-and-scope",
    "title": "Statistical Analysis Using R: Online Notes",
    "section": "Purpose and scope",
    "text": "Purpose and scope\nEleventy years ago, I studied probability and statistics “for statisticians”. Probability theory is elegant and contemplative. Graduate-level work can be completed with just pencil and paper, through proofs and symbolic notation.\nThe tools and methods discussed in these notes were built from such theoretical work. However, the students I teach are headed (generally) to industry, not to research positions or Ph.D programs. They may never need to author a proof, but they will need to draw conclusions about the world from noisy, biased, incomplete, or insufficient data, to perform their analyses within a modern day tech stack, and to communciate their findings to decisionmakers.\nSo I want to teach probability and statistics “for data scientists”. Data science is a tradecraft, not a body of theory, and it allows people and organizations to answer questions, solve problems, and achieve goals. Data science which does not help us to confront real problems or understand real datasets is not truly data science after all.\nI will try to stay focused on that mission in these notes, which should not be confused for a true textbook: they more closely resemble a detailed set of lecture slides, paired with ready-to-use code and interactive workshops. The layout of these notes echoes the syllabus for my class: a fast-paced survey of inferential statistics and parametric modeling methods, using likelihood estimation theory as a throughline for three main sections:\n\nFirst, we’ll review some topics in univariate analysis which may already be familiar to many readers.\nSecond, we’ll examine ordinary least squares (OLS) regression in more detail than readers may have seen at the college level.\nThird, we’ll abstract from OLS regression to the family of models called generalized linear models, which describe non-linear trends among non-normally distributed datasets.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-referencetexts",
    "href": "index.html#sec-referencetexts",
    "title": "Statistical Analysis Using R: Online Notes",
    "section": "Recommended textbooks",
    "text": "Recommended textbooks\nDespite the sentiments above, I retain both fondness and respect for true textbooks, and I highly suggest that readers of these notes pair them with one or more proper reference tomes. A few recommendations follow:\n\nIntroduction to Probability 2nd edition, by Joseph Blitzstein and Jessica Hwang\nThis book is freely available and would help you prepare if you need to spend more time with the foundational topics which precede this course. The authors cover probability and random variables in depth, but they do not cover inference/estimation or regression topics.\nPractical Statistics for Data Scientists 2nd edition, by Peter Bruce, Andrew Bruce, and Peter Gedeck\nThis might be the most comprehensive of the books in this list. It covers many of our topics, and contains extra sections on experimental design, classification models, and machine learning models which might be useful to readers of these notes.\nFoundations and Applications of Statistics: An Introduction using R 2nd edition, by Randall Pruim\nThis book covers most of our material, but skimps a little on generalized linear models. It focuses mostly on univariate analysis and linear regression, with some basic probability as well as a brief section on logistic regression. It also contains a lot of R code.\nFoundations of Linear and Generalized Linear Models, by Alan Agresti\nThis book aligns well with the second and third sections of these notes (linear regression and GLMs), but does not cover basic probability or univariate inference.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#how-these-notes-were-made",
    "href": "index.html#how-these-notes-were-made",
    "title": "Statistical Analysis Using R: Online Notes",
    "section": "How these notes were made",
    "text": "How these notes were made\nI assembled these notes using Quarto, a publishing system built around the Pandoc markdown language. I wrote all the code backing these notes in R, and alongside every figure or table you can find the corresponding R code.\nNeither the text nor the R code in these notes were generated by AI tools: for better and worse the opinions expressed here are my own, and the I’ve described these concepts in my own voice.1 Complaints can be submitted here.\nThese notes began as a (clunky) Word document shared with my students across several academic quarters. Their questions, requests for clarification, and occasional corrections have all vastly improved my content, and I thank them for their help.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#sec-notation",
    "href": "index.html#sec-notation",
    "title": "Statistical Analysis Using R: Online Notes",
    "section": "A note on notation",
    "text": "A note on notation\nUnfortunately, no two statistical sources use exactly the same notation. Any choice I make will inevitably differ from other sources you consult. I will follow the common conventions when I can, and beg your understanding when I cannot. I will occasionally use two different options to represent the same concept, not because I wish to confuse you, but because sometimes complete consistency creates impossible formatting challenges or even greater ambiguity.\n\nObservations from a sample and realizations of a random variable will use lowercase Latin letters, with subscripts as needed:\n\n\\[x_1,x_2,...,x_n\\]\n\nRandom variables themselves will use uppercase Latin letters.2 Subscripts on random variables suggest relations between them, such as two predictors for the same response:\n\n\\[Y,Z;\\quad X_1,X_2\\]\n\nTrue parameters of a model will often use Greek lowercase letters:3\n\n\\[\\mu,\\sigma^2,\\beta_0,\\beta_1\\]\n\nEstimates of random variables will use a ‘hat’ accent above the original symbol or use the matching lowercase Latin alphabet letter:4\n\n\\[\\hat{\\mu},\\hat{\\beta}_0;\\quad s^2,b_1\\]\n\nVectors (including univariate samples) will use an arrow accent or boldface lowercase letters. Matrices will use bold uppercase letters (not italic):\n\n\\[\\vec{u},\\boldsymbol{y};\\quad \\mathbf{X}\\]\n\nElements of a matrix or data with multiple indices will use a double subscript:\n\n\\[\\mathbf{X} = \\begin{bmatrix} x_{1,1} & x_{1,2} \\\\ x_{2,1} & x_{2,2} \\end{bmatrix};\\qquad y_{i \\bullet} = \\frac{1}{n_i}\\sum_j y_{i,j}\\]\n\nBy convention some terms are stylized using blackboard letters, including the set of reals and the set of integers, as well as expectation and variance.\n\n\\[\\mathbb{R},\\mathbb{Z}; \\quad \\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\\]\n\nScript typefaces may be used for other sets, or to “re-use” a letter with more established meanings:\n\n\\[\\mathcal{S},\\mathcal{L},\\ell \\qquad (\\textrm{compare with}\\ S, L, l)\\]",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Statistical Analysis Using R: Online Notes",
    "section": "",
    "text": "AI assistance was used to brainstorm case studies and examples, and to help with the layout and coding of the website itself.↩︎\nThe most common exception will be my use of the Greek lowercase epsilon \\((\\varepsilon)\\) for an error term, per tradition.↩︎\nWith many exceptions when parameters are traditionally named otherwise, such as using ‘a’ and ‘b’ for the parameters of a Uniform distribution or ‘df’ for degrees of freedom in a t-distribution.↩︎\nThe hat accent is properly called a circumflex, but statisticians say ‘hat’, e.g. the estimate for ‘mu’ is ‘mu-hat’.↩︎",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface: Inference",
    "section": "",
    "text": "Inferential statistics\nAll of the methods and theory presented in these notes are examples of parametric inference. If you aren’t already familiar with that term, it’s worth exploring now.\nWhen I was young, I first heard the term “statistics” used to summarize or highlight the values of a dataset:\nThese figures are correctly called statistics, but statisticians label them as descriptive statistics. They are incontrovertible facts. They are properties of a fixed sample which we can all agree upon. They do not require theory, just a calculation. Once I explain to you how to compute a median, you know that the median of the numbers \\(\\{1,1,2,3,5,8,13\\}\\) is 3, without having to argue over assumptions.\nBy contrast, the field of inferential statistics concerns itself with a shadowy world we cannot see and which might not exist. Inferential statistics starts from the assumption that the numbers in our world come to us from generating processes which are unknown — but systematic and guessable. The data we observe are realizations of random variables, and the random variables are defined by formulae, and the formulae are controlled by parameters. Once we know those parameters, we can usually answer more detailed questions about the generating process, even questions for which we have no direct observational evidence.\nFor example, our study of the Earth and the broader solar system suggests that meteors with a diameter of more than 1 km strike the Earth roughly every 500,000 years. We believe that such meteor strikes are closely approximated by a Poisson process, and that therefore the time between large meteor strikes could be represented by an exponential distribution with the parameter \\(\\lambda=0.000002\\) (here \\(\\lambda\\), or lambda, represents the long-term rate of meteor strikes per year).\nIf all this is true, then I can use the exponential distribution to calculate that the probability of a large meteor strike in my lifetime (or equivalently, in the next 50 years) is only about 0.01%:1\n\\[P(X \\le 50) = 1 - e^{-\\lambda \\cdot 50} = 1 - e^{-0.0001} \\approx 0.00009995\\]\nOf course, I cannot prove my calculation is right or wrong. If the next large meteor struck tomorrow, or just as I died, or two thousand years from now, none of these would validate or invalidate my estimate. But the estimate might still be flawed for several reasons. Further research might change our estimate of how often such meteors strike the Earth — perhaps it’s roughly once every 400,000 years, or every 600,000 years. We may even be wrong about meteor strikes being Poisson processes, and if they are not, then I would need a completely new set of assumptions.\nYet consider my approach:\nThese are the central concepts of inferential statistics. We make assumptions about how the world works, and then use data to estimate various unknown parameters. We are always wrong in our guesses –– and we don’t even know how wrong we are. We are sometimes even wrong about our distributional assumptions. I wouldn’t say we are taking guesses in the dark, but the room can be very dim indeed. However, our reward is to be able to describe things we have not seen, to predict the future, and to better understand the past.",
    "crumbs": [
      "Preface: Inference"
    ]
  },
  {
    "objectID": "preface.html#sec-inferentialstatistics",
    "href": "preface.html#sec-inferentialstatistics",
    "title": "Preface: Inference",
    "section": "",
    "text": "Among Major League Baseball pitchers, Nolan Ryan holds the career strikeout record with a total of 5714.\nJapan has a greater proportion of centenarians (people who are over 100 years of age) than any other country, at 43 per 100,000 residents.\nRoughly 24% of the bullet chess players on &lt;www.chess.com&gt; have an Elo score better than my own.\n\n\n\n\n\n\n\n\n\nI started from a dataset (the geologic record of how many large meteors have struck the Earth during the Cenozoic period)\nI assumed that the data came from a specific probability distribution\nI used the data to make a guess as to which parameters controlled that distribution\nWith my guess for the parameters, I was able to answer questions that the data by itself could not answer",
    "crumbs": [
      "Preface: Inference"
    ]
  },
  {
    "objectID": "preface.html#sec-parameters",
    "href": "preface.html#sec-parameters",
    "title": "Preface: Inference",
    "section": "How all parametric estimation is performed",
    "text": "How all parametric estimation is performed\nI described the steps above in generalities. We have not yet discussed how to make a guess about the parameters of a distribution. Nor have we discussed what makes one guessing method better or worse than other guessing methods. Before I can talk about these subjects, we need to introduce a few definitions.\nWe will start with some data. Perhaps we have a univariate vector of \\(n\\) observations: \\(\\boldsymbol{x} = \\{x_1,x_2,\\ldots,x_n\\}\\).2 I will frequently describe \\(\\boldsymbol{x}\\) as our sample, even if it was collected by non-sampling methods.\nNext, let’s introduce a distributional assumption. The data \\(\\boldsymbol{x}\\) are realizations of a random variable \\(X\\) with a cumulative distribution function \\(F_X\\) controlled by one or more parameters \\(\\theta\\) (theta). The probability or density of each observation \\(x_i\\) depends not only on its value but also on the parameters \\(\\theta\\). We could write,\n\\[P(X \\le x_i) = F_X(x_i;\\theta) \\qquad \\forall i \\in \\mathbb{N}:\\ 1 \\le i \\le n\\]\nStatistics textbooks sometimes refer to \\(\\theta\\) as the estimand. In my experience, very few real-world professionals use this term. From now on, we will simply refer to \\(\\theta\\) as the parameters or often the unknown parameters, which emphasizes the fact that we rarely know their true value.\nNow, let’s make a guess as the value(s) of \\(\\theta\\). There are several methods we could use to make this guess, general systems for guessing that work well for many distributions and many datasets. Right now, the specific method we use is unimportant. What is important is that our guess should be some function of the data in front of us. That is, our data \\(\\boldsymbol{x}\\) should inform our guess for the parameters \\(\\theta\\). The calculation which transforms our data into a guess of the parameter is called the estimator and written \\(\\hat{\\theta}\\) (theta-hat):\n\\[\\hat{\\theta} = g(\\boldsymbol{x})\\]\nWritten this way, \\(\\hat{\\theta}\\) is a calculation, a function \\(g\\) that we apply to each new sample \\(\\boldsymbol{x}\\), producing a different result for different samples. Anytime we use our estimator \\(\\hat{\\theta}\\) on a specific sample, the result of this calculation is called the estimate of \\(\\theta\\). The estimator is the function, and the estimate is its value for a specific sample.\nAllow me a metaphor to sum this all up. Inferential statistics is like baking chocolate chip cookies. We each have an idea of what chocolate chip cookies should taste like (please take a moment to imagine your own perfect cookie). This theoretical goal is the unknown parameter. We want to make the best real-world version of this unattainable perfection. We can choose from many recipes, or even make a new recipe of our own. Some recipes lean toward one texture or another, or accentuate some flavors more than others. Each different recipe is a different estimator. We may think one recipe is better than another, but that doesn’t mean that it always produces a perfect batch of cookies. Depending on the materials at hand — the freshness of the ingredients, the specific brand of chocolate, the shape and reliability of the oven, our altitude — even our favorite recipe might produce a bad batch of cookies, or an unloved recipe might produce a surprisingly good batch of cookies. Each individual batch is a different estimate, and those conditions which vary batch-to-batch are the data.",
    "crumbs": [
      "Preface: Inference"
    ]
  },
  {
    "objectID": "preface.html#sec-statsvsml",
    "href": "preface.html#sec-statsvsml",
    "title": "Preface: Inference",
    "section": "Statistical models and machine learning models",
    "text": "Statistical models and machine learning models\nNow that we’ve reviewed the aims of parametric inference, you might wonder how it differs from any other type of data analysis. After all, don’t all quantitative methods use the information in a dataset to answer questions about the world around us?\nA statistical model makes a strong assumption that the data has a functional form, i.e. that the data are realizations of a random variable with a known distribution type. The only unknowns are the specific values of the parameters which created the data. Finding estimates for these parameters is typically the “finish line” for the analysis: most of the useful findings flow directly from the estimated theoretical distribution.\nStatistical models are high-risk and high-reward. Very few datasets are perfectly distributed according to known probability distributions. Even if the generating process is well understood, the parameters which govern the data might change over time, and the dataset we use may give us outdated information. The extremes of the distribution will typically be the least observed, and we may produce catastrophically bad predictions when we naively fit the wrong distributions to these unobserved regions.3\nAt first, we accepted these risks because we had no other choice. There were few alternative methods, and practitioners were limited by the data and technology of their day: dozens or hundreds of observations, studied without electronic help or with relatively primitive computing resources.\nAll these drawbacks are also the strengths of statistical modeling. Statistical models can give a wide range of answers about how a generating process will behave in conditions never seen in the data. Statistical models are often very resource-light, and some can even be computed by hand. Statistical models will work with almost any amount of data and can give useful results with very small sample sizes. The parameters that we estimate from statistical models often give us powerful insight into how and why the world works.\nA machine learning (ML) model, by contrast, does not believe or require that the data were generated by a probability distribution. ML models are generally uninterested in the idea of a single generating process which created all the data. They explore clusters and breakpoints within the data, seeking to find useful rulesets or “views” of the data which preserve as much of the original information as possible.\nAn ML model might use parametric components which are iteratively tuned in order to minimize an error function. For example, the bins created by a decision tree or the hyperplane classifiers of support vector machines are both defined by parameters. But these parameters are generally not associated with probability distributions.\nML models typically offer less interpretability than statistical models. They are less eager to find hidden “truths” in the world around us, less able to explain how changes in the inputs result in changes to the outputs. They can also be very resource-intensive, requiring both large amounts of data as well as large amounts of computing power.\nIn return, ML models offer flexibility and robustness in situations which would defy statistical modeling. ML models usually perform better than statistical models on very large datasets, which are more likely the result of many different generating processes rather than a single generating process. ML models thrive on heterogeneity and local differences in behavior, which often confound or mislead statistical models. You will learn about them in other courses. For now, we will focus on statistical models.",
    "crumbs": [
      "Preface: Inference"
    ]
  },
  {
    "objectID": "preface.html#footnotes",
    "href": "preface.html#footnotes",
    "title": "Preface: Inference",
    "section": "",
    "text": "Somehow this proved less comforting than I had hoped.↩︎\nLater on in these notes, we will extend our methods to data which form a matrix of values, where each component \\(x_i\\) is a vector of its own: \\(\\mathbf{X}={\\boldsymbol{x_1},\\boldsymbol{x_2},\\ldots,\\boldsymbol{x_k}}\\).↩︎\nThis was a major driver of the 2007–08 financial crisis, for example.↩︎",
    "crumbs": [
      "Preface: Inference"
    ]
  },
  {
    "objectID": "likelihood.html",
    "href": "likelihood.html",
    "title": "Univariate likelihood",
    "section": "",
    "text": "Motivation and definition\nLet’s begin studying statistical inference with the simplest of cases: trying to determine the distribution which generated a single column of numbers. I assume your familiarity with some of the most common probability distributions: the discrete Bernoulli, binomial, geometric, and Poisson distributions, along with the continuous uniform, exponential, and normal distributions. If you need a refresher, the appendices contain more detail about each of these distributions and others we will study in later sections.\nWhen we ask our computers today to model our data with set of parameters (such as the slope and intercept of a simple regression), the computer usually solves for the unknown parameters using maximum likelihood estimation, a method developed by Ronald Fisher over 100 years ago. The basic premise of maximum likelihood is to assume that the data aren’t… weird. Of course, the data could be weird: they could be unrepresentative or contain wild outliers. But usually, and by definition, our data aren’t unusual. So we will suppose that the best guess for the unknown parameters will be the values which make the data seem the most ordinary. There are other estimation methods worth learning, but in this course we will focus heavily on maximum likelihood estimation.\nWhen we conduct statistical inference, we begin with data, and then we proceed to ask what distribution (and which parameters) could have created the data. Notice that this situation reverses the problems you might find in a high school or college class on probability. In those earlier classes, you would often be asked “if the parameters for this distribution are \\(\\theta\\), then what is the probability of observing \\(\\boldsymbol{x}\\)?” For example:\nInstead, the shoe is now on the other foot:\nTo answer these questions, we will invent a way to “score” each set of possible parameters for a specific dataset. The parameters which seem well fit to the data will receive a higher score. We will consider all parameter choices which score highly as reasonable guesses for the unknown truth, but if we need to make just one guess, then we will choose the parameter or set of parameters with the highest score. We will call this scoring function likelihood.\nImagine a univariate sample \\(\\boldsymbol{x} = x_1,x_2,\\ldots,x_n\\) which we believe came from a discrete probability distribution \\(X\\) with parameters \\(\\theta\\), and assume for the moment that the observations are independent of each other. Then we could compute the probability of observing the entire sample simply by multiplying together the probabilities of each individual observation:\n\\[P(\\boldsymbol{x}|\\theta) = \\prod_{i=1}^n P(X=x_i|\\theta)\\]\nThe equation above treats \\(\\theta\\) as a fixed assumption and \\(\\boldsymbol{x}\\) as the input variable. Now we will repurpose this same function but treat \\(\\boldsymbol{x}\\) as the assumption and \\(\\theta\\) as the variable. We will also take the opportunity to extend this idea to a continuous case, using densities rather than probability mass functions:\nNotice that likelihood functions are usually products of the individual probabilities/densities of each observation in the sample. It can be difficult to directly maximize a complicated product of many terms. Happily, we can use one or two tricks which greatly simplify maximum likelihood estimation. The first trick is to notice that the log of a function reaches its maximum or minimum at the same input values as the original function (that is, logarithms are a monotonic transformation). Below I plot the likelihood function for the coin data mentioned above: 27 heads and 23 tails. I also will plot the log of the likelihood function:\nCode\n#generate coin data\ncoins &lt;- c(rep(1,27),rep(0,23))\n\n#compute likelihood and log-likelihood functions\ncoin.lik &lt;- function(p) p^sum(coins)*(1-p)^sum(1-coins)\ncoin.ll &lt;- function(p) sum(coins)*log(p)+sum(1-coins)*log(1-p)\n\n#plot coin likelihood and log-likelihood\npar(mfrow=c(1,2),bty='n',cex=0.8)\nplot((1:99)/100, coin.lik((1:99)/100),type='l',lwd=2,\n     main=\"Likelihood of Coin Parameter 'p'\",\n     xlab='p (Prob. of Heads)',ylab='Likelihood')\nabline(v=mean(coins),lwd=2,lty=2,col='grey50')\ntext(x=mean(coins),y=0,pos=4,col='grey50',\n     labels=paste0('x=',round(mean(coins),2)))\n\nplot((1:99)/100, coin.ll((1:99)/100),type='l',lwd=2,\n     main=\"Log-likelihood of Coin Parameter 'p'\",\n     xlab='p (Prob. of Heads)',ylab='Log-likelihood')\nabline(v=mean(coins),lwd=2,lty=2,col='grey50')\ntext(x=mean(coins),y=-120,pos=4,col='grey50',\n     labels=paste0('x=',round(mean(coins),2)))\n\n\n\n\n\n\n\n\nFigure 1.1: Likelihood and log-likelihood of coin flip data\nSince the log of a product is simply the sum of logs of each term in the product, we often find log-likelihood proves easier to maximize than the original likelihood function.\nThe second trick which we use to more easily maximize likelihood is calculus. When a likelihood function is continuously differentiable and has a local maximum (as the two graphs do above), then the same parameter value which maximizes the likelihood and log-likelihood will be a root of the first derivative of the log-likelihood:\nCode\n# create first derivative of coin log-likelihood function\ncoin.dll &lt;- function(p) sum(coins)/p-sum(1-coins)/(1-p)\n\n# graph first derivative of coin log-likelihood function\npar(mfrow=c(1,1),bty='n',cex=0.8)\nplot((1:99)/100, coin.dll((1:99)/100),type='l',lwd=2,\n     main=\"Derivative of LL of Coin Parameter 'p'\",\n     xlab='p (Prob. of Heads)',ylab='dLL/dp')\nabline(h=0)\nabline(v=sum(coins)/length(coins),lwd=2,lty=2,col='grey50')\ntext(x=sum(coins)/length(coins),y=-2000,pos=4,col='grey50',\n     labels=paste0('x=',round(sum(coins)/length(coins),2)))\n\n\n\n\n\n\n\n\nFigure 1.2: First derivative of the log-likelihood of coin flip data",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate likelihood</span>"
    ]
  },
  {
    "objectID": "likelihood.html#motivation-and-definition",
    "href": "likelihood.html#motivation-and-definition",
    "title": "Univariate likelihood",
    "section": "",
    "text": "If a fair coin is flipped 50 times, what is the probability of observing exactly 27 heads and 23 tails?\nIf the heights of adult women in the United States are normally distributed with a mean of 162 cm and a standard deviation of 7 cm, what is the probability of drawing a sample of ten women who are all shorter than 152 cm?\n\n\n\nWe flip a coin 50 times and observe 27 heads and 23 tails. Is it reasonable to believe that the coin is fair, despite these lopsided results?\nWe observe the heights of ten women, and we assume they represent a sample from a population which is normally distributed. Based on our sample, what are realistic ranges for the unknown mean \\(\\mu\\) and variance \\(\\sigma^2\\)?\n\n\n\n\n\n\nLet \\(X\\) be a random variable dependent on one or more parameters \\(\\theta\\) and \\(\\boldsymbol{x} = x_1,x_2,\\ldots,x_n\\) be independent sample observations where \\(x_i \\sim X \\quad \\forall i \\in \\mathbb{N}: \\ 1 \\le i \\le n.\\) Then we write the likelihood of \\(\\theta\\) given \\(\\boldsymbol{x}\\) as \\(\\mathcal{L}(\\theta|\\boldsymbol{x})\\). If \\(X\\) is discrete, we define:\n\\[\\mathcal{L}(\\theta|\\boldsymbol{x})=\\prod_{i=1}^n P(X=x_i|\\theta)\\]\nAnd if \\(X\\) is continuous with probability distribution function (PDF) \\(f_X\\), we define:\n\\[\\mathcal{L}(\\theta|\\boldsymbol{x})=\\prod_{i=1}^n f_X(x_i|\\theta)\\]\nIf \\(\\theta\\) has \\(k\\) parameters, let \\(\\mathcal{S} \\in \\mathbb{R}^k\\) be the set of values \\(\\theta\\) can take which are permitted by the distribution of \\(X\\) and the observed values of \\(\\boldsymbol{x}\\). Then the choice for \\(\\theta\\) which maximizes \\(\\mathcal{L}(\\theta|\\boldsymbol{x})\\) is referred to as the maximum likelihood estimator (MLE) for \\(\\theta\\):\n\\[\\hat{\\theta}_\\textit{MLE} = \\mathop{\\mathrm{argmax}}_{\\theta \\in \\mathcal{S}} \\,\\mathcal{L}(\\theta|\\boldsymbol{x})\\]\n\n\n\n\n\nLet \\(\\mathcal{L}(\\theta|\\boldsymbol{x})\\) be the likelihood of a parameter \\(\\theta\\) given a sample \\(\\boldsymbol{x}\\) and a distributional assumption about the random variable \\(X\\) from which the sample was drawn. Then we denote the log-likelihood of \\(\\theta\\) given \\(\\boldsymbol{x}\\) as \\(\\ell(\\theta|\\boldsymbol{x})\\) and define it as\n\\[\\ell(\\theta│\\boldsymbol{x})=\\log{\\mathcal{L}(\\theta│\\boldsymbol{x})}\\]\n\n\n\n\nExample 1: Coin flips\nSuppose that we were given a coin and told it was fixed to land on one side more than the other. We flip the coin 50 times and record each ‘heads’ as 1 and each ‘tails’ as 0. The results below show that the coin landed ‘heads’ 27 times and ‘tails’ 23 times.\n\\[\\boldsymbol{x}=\\left\\{ \\begin{aligned} 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, \\\\ 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0 \\; \\end{aligned} \\right\\}\\]\nLet us make a distributional assumption: the coin data can be modeled by a Bernoulli distribution. We cannot know whether this is correct or not, but it seems reasonable: Bernoulli trials require exactly two outcomes, a fixed probability of success, and independence between trials. While it’s possible that the coin could land on its edge, or that it deforms over time, or that it shows serial correlation, modeling the coin flips as Bernoulli trials seems true enough to be useful.1\nWhat is the probability of observing the data if the coin truly lands heads 60% of the time? You should be able to answer this from your past lessons in probability and statistics. Since we assume trials to be independent, we can write:\n\\[\\begin{align}P(\\boldsymbol{x} | p = 0.6) &= \\prod_{i = 1}^{50} P(x_i | p = 0.6) = 0.4 \\cdot 0.4 \\cdot 0.6 \\cdot \\ldots \\cdot 0.4 \\\\ &= 0.6^{27} \\cdot 0.4^{23} \\approx 7.2×10^{-16}\\end{align}\\]\nA very small number… although these results are actually quite unextraordinary, there are simply so many ways that 50 coin flips can occur (1.13 quadrillion ways) that even the most common sequences each have a very, very low probability.\nWhat is the likelihood for any given parameter \\(p\\), given our dataset of 27 heads in 50 flips?\n\\[\\mathcal{L}(p|\\boldsymbol{x}) = \\prod_{i=1}^{50} P(x_i|p) = p^{27} (1-p)^{23}\\]\nWhat is the value of \\(p\\) which maximizes this likelihood? It’s not immediately evident from the equation above, but perhaps the log-likelihood will help us to solve for \\(p\\):\n\\[\\ell(p|\\boldsymbol{x}) = \\log{\\mathcal{L}(p|\\boldsymbol{x})} = 27\\log{⁡p}+23\\log⁡(1-p)\\]\nThis is still difficult to solve by hand, so let’s bring in the final trick, and instead try to find the root of the first derivative of the log-likelihood:\n\\[\\frac{d}{dp} \\ell(p│\\boldsymbol{x}) = \\frac{27}{p}-\\frac{23}{1-p}\\]\nSetting the above equal to zero and solving for p,\n\\[\\begin{align} \\frac{27}{p}-\\frac{23}{1-p} = 0 & \\Longrightarrow \\frac{27}{p} = \\frac{23}{1-p} \\Longrightarrow 27-27p = 23p \\\\ & \\Longrightarrow 50p=27 \\Longrightarrow \\hat{p}_\\textit{MLE} = \\frac{27}{50}=0.54 \\end{align}\\]\nIn fact, we could abstract a little further here to find the MLE for any Bernoulli-distributed sample. Let \\(k\\) be the number of successes and \\(n\\) be the total number of trials. Using the same math as above, you will find that:\n\\[\\hat{p}_\\mathit{MLE} = k/n = \\frac{\\sum_i x_i}{n} = \\bar{x}\\] This is a tidy little result. When our data are Bernoulli distributed, then the maximum likelihood estimator for the parameter \\(p\\) is simply the sample average, i.e. the proportion of observations that were successes. I like findings such as these which conform with our intuition: when we have data on a Bernoulli process, our best guess as to how often successes truly happen will simply be how often successes occurred in our data.\n\n\nExample 2: Heights\nThe above example used a very simple discrete distribution with a single parameter. Let’s try again with a more complicated continuous distribution, which uses two parameters. Across the entire world population, heights are not exactly distributed according to any known distribution. However, among otherwise homogeneous populations, we do observe that heights are roughly normally distributed. Let’s pretend that we sampled 10 adult women in the United States and measured their heights. Rounded to the nearest tenth of a centimeter, their heights are listed below:2\n\\[\\boldsymbol{x}=\\{170.1,161.6,175.2,166.3,165.6,165.8,152.0,155.8,168.6,154.3\\}\\] Let us assume that these heights are drawn from a normal distribution. What then would be the best guess for the parameters \\(\\mu\\) and \\(\\sigma^2\\), which are the mean and variance of the distribution? We will start by finding the likelihood function. Recall that if \\(X\\) is normal,\n\\[f_X(x|\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\\] From this, we can compute the likelihood of any pair of normal parameters for any dataset:\n\\[\\mathcal{L}(\\mu,\\sigma^2|\\boldsymbol{x}) = (2\\pi\\sigma^2)^{-n/2}\\cdot e^{-\\frac{1}{2\\sigma^2}\\sum_{i}(x_i-\\mu)^2}\\] Then, we can find the log-likelihood:\n\\[\\ell(\\mu,\\sigma^2|\\boldsymbol{x}) = \\log{\\mathcal{L}(\\mu,\\sigma^2|\\boldsymbol{x})} = -\\frac{n}{2}\\log{2\\pi\\sigma^2} - \\frac{1}{2\\sigma^2} \\sum_{i}(x_i-\\mu)^2\\]\nNext, we will take the derivative with respect to \\(\\mu\\):\n\\[\\frac{\\partial\\ell}{\\partial\\mu} = \\frac{1}{\\sigma^2} \\sum_{i}(x_i-μ) \\] From here we will solve for the root of the derivative, which will be the value of \\(\\mu\\) that maximizes the original likelihood function:\n\\[\\begin{align} \\frac{\\partial\\ell}{\\partial\\mu} = 0 & \\Longrightarrow \\sum_i (x_i-\\mu) = 0 \\Longrightarrow \\sum_i x_i - n\\mu = 0 \\Longrightarrow n\\mu=\\sum_i x_i \\\\ & \\Longrightarrow \\hat{\\mu}_\\textit{MLE} = \\bar{x} \\end{align}\\]\nWhat a fantastic bit of luck. The best guess for the true mean of a normal distribution is the sample mean of our data! Let’s finish up by repeating for variance: first we take the partial derivative of the log-likelihood with respect to \\(\\sigma^2\\):\n\\[\\frac{\\partial\\ell}{\\partial\\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4}\\sum_i (x_i-\\mu)^2\\] Then we will solve for the root of the derivative, which will be the value of \\(\\sigma^2\\) which maximizes the original likelihood function:\n\\[\\begin{align} \\frac{\\partial\\ell}{\\partial\\sigma^2} =0 & \\Longrightarrow \\frac{1}{2\\sigma^4} \\sum_i (x_i-\\mu)^2 = \\frac{n}{2\\sigma^2} \\Longrightarrow \\frac{1}{\\sigma^2} \\sum_i (x_i-\\mu)^2 = n \\\\ & \\Longrightarrow \\hat{\\sigma}^2_\\textit{MLE} = \\frac{1}{n} \\sum_i (x_i-\\mu)^2 \\end{align}\\]\nYou may recognize this quantity as the biased (uncorrected) sample variance. Although this calculation seems very sensible, we will later show that it systematically underestimates the true variance \\(\\sigma^2\\), which provides our first hint that maximum likelihood estimation is not the final answer for every problem we will encounter.\nWith these results in hand, we can produce the MLEs for our normal parameters given our height data. We would say that the best guess for the true mean height of adult women in the United States is 163.5 cm and the best guess for their variance would be 50.4 cm\\({}^2\\) (implying a standard deviation of 7.1 cm).3\n\n\nCode\n#generate height data\nheights &lt;- c(170.1,161.6,175.2,166.3,165.6,165.8,152.0,155.8,168.6,154.3)\n\n#generate height parameter ll contour plot\nheight.ll &lt;- function(parms) {-1*length(heights)*log(2*pi*parms[2])/2-sum((heights-parms[1])^2)/(2*parms[2])}\nxgrid &lt;- seq(140,180,0.1)\nygrid &lt;- seq(25,80,0.1)\nzgrid &lt;- matrix(apply(cbind(rep(xgrid,times=length(ygrid)),rep(ygrid,each=length(xgrid))),\n                      1,height.ll),ncol=length(ygrid))\nfilled.contour(xgrid,ygrid,zgrid,levels=c(-120,-100,-80,-70,-60,-50,-40,-35,-34,-33.8,-33.7),\n               col=paste0('#000000',c('00','20','40','60','80','9f','af','cf','ef','ff')),\n               main='Log-Lik of Parameters for Height Data',\n               xlab='Mu (mean height, in cm)',ylab='Sigma^2 (variance)')\n\n\n\n\n\n\n\n\nFigure 1.3: Contour plot of height data log-likelihoods\n\n\n\n\n\nWe can confirm that these solutions are reasonable by plotting the log-likelihood of various combinations of mean and variance, seen above. Notice that a broad range of possible means and variances have log-likelihoods close to the maximum value of -33.8. Any of these combinations could easily have generated our data. But if we have to make one guess, then the MLE values of (163.5, 50.4) would be our best choice.",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate likelihood</span>"
    ]
  },
  {
    "objectID": "likelihood.html#visualizer",
    "href": "likelihood.html#visualizer",
    "title": "Univariate likelihood",
    "section": "Visualizer",
    "text": "Visualizer\nThis visualizer shows an exponential distribution, which is often used to model the waiting times between events. You can create a sample by adjusting the rate parameter \\(\\lambda\\) (e.g. \\(\\lambda=5\\) might mean an average of five events per hour), and the total sample size. Then the visualizer will plot the raw data (each waiting time) as well as the likelihood, log-likelihood, and derivative of the log-likelihood function for the parameter \\(\\lambda\\).\nNotice how the parameter value made most likely by your data will never quite “right” (i.e. equal to the true parameter.) But as sample size increases, the estimates usually get closer to the true value, and the likelihood function develops a very narrow “peak” around our estimate, meaning that the other values are not made very likely by our data.\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 900\n\nlibrary(shiny)\nlibrary(bslib)\n\nll &lt;- function(lambda,x) length(x)*log(lambda) - lambda*sum(x)\nl &lt;- function(lambda,x) exp(ll(lambda,x))\ndll &lt;-function(lambda,x) length(x)/lambda - sum(x)\nx.axis &lt;- seq(0.05,6.0,0.05)\n\nui &lt;- page_fluid(\n  tags$head(tags$style(HTML(\"body {overflow-x: hidden;}\"))),\n  title = \"Likelihood for an Exponential sample\",\n  fluidRow(column(width=6,sliderInput(\"lambda\", \"Lambda (rate)\", min=1, max=5, value=3)),\n           column(width=6,sliderInput(\"nsamp\", \"N (sample size)\", min=10, max=1000, value=100))),\n  fluidRow(column(width=6,plotOutput(\"distPlot1\")),\n           column(width=6,plotOutput(\"distPlot2\"))),\n  fluidRow(column(width=6,plotOutput(\"distPlot3\")),\n           column(width=6,plotOutput(\"distPlot4\"))))\n\nserver &lt;- function(input, output) {\n  x &lt;- reactive({rexp(n=input$nsamp,rate=input$lambda)})\n  output$distPlot1 &lt;- renderPlot(hist(x(),main='Histogram of Data',xlab='Waiting time',ylab='Frequency'))\n  output$distPlot2 &lt;- renderPlot(plot(x.axis,l(x.axis,x()),main='Likelihoods for Lambda',xlab='Lambda',ylab='Likelihood',type='l',xlim=c(0,6)))\n  output$distPlot3 &lt;- renderPlot(plot(x.axis,ll(x.axis,x()),main='Log-likelihoods for Lambda',xlab='Lambda',ylab='Log-likelihood',type='l',xlim=c(0,6)))\n  output$distPlot4 &lt;- renderPlot({plot(x.axis,dll(x.axis,x()),main='First Derivative of LL for Lambda',xlab='Lambda',ylab='dLL/dLambda',type='l',xlim=c(0,6)); abline(v=0,lty=2)})\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate likelihood</span>"
    ]
  },
  {
    "objectID": "likelihood.html#footnotes",
    "href": "likelihood.html#footnotes",
    "title": "Univariate likelihood",
    "section": "",
    "text": "You may recall the statistician George Box’s maxim: all models are wrong, some are useful.↩︎\nFor the stubborn imperial-unit diehards among us, these heights range from five feet (60”) to five feet nine inches (69”).↩︎\nOr for provincial bumpkins like myself: 64 in, 20 in\\({}^2\\), and 3 in.↩︎",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate likelihood</span>"
    ]
  },
  {
    "objectID": "hypothesistest.html",
    "href": "hypothesistest.html",
    "title": "Hypothesis tests",
    "section": "",
    "text": "Two-tailed hypothesis tests\nMaximum likelihood estimation computes the best guess for the true location of an unknown parameter, but unfortunately these guesses are almost never correct, and guesses for the same parameter usually fluctuate by small amounts from sample to sample. Put another way, each sample usually misleads us by a little bit — even carefully gathered samples which meet all our assumptions. Therefore, we should not only learn methods of identifying the best estimate for a parameter, but methods for identifying whether a specific estimate is reasonable, or indeed, methods which help us to identify all reasonable estimates for the parameter.\nWe will first consider the case of asking whether one specific estimate could be a reasonable guess for the true parameter(s).\nConsider again the coin data from before: 27 heads and 23 tails from 50 trials. Maximum likelihood estimation would say that the best guess for the true probability of heads would be the sample average, 54%. But I believe that if you had a real coin in your hands, and you flipped it 50 times and observed 27 heads, you would not say to yourself, “Surely, this coin must slightly favor heads.” You probably assumed it was a fair 50-50 coin before you flipped it, and you probably didn’t change your mind after you flipped it. Intuitively, we know that even fair coins produce unfair sample averages.1 Yes, it’s true that an unfair 55-45 coin might often produce 27 heads from 50 trials. But so would a fair 50-50 coin, and so our data do not rule out the possibility of a fair coin.\nWe can even compute the exact probability that a fair 50-50 coin would create results like our data. When I say “like our data”, I will include all results that are as far-from-fair as our data, or even farther-from-fair. I want to show you that fair coins can not only produce our exact data, but can sometimes produce even stranger results.2 These extreme results would include 27 heads (like our data), but also 28, 29, …, up to 50 heads. They also include 23 heads, since 23 heads (and 27 tails) from 50 flips of a fair coin would be just as unusual as 23 tails (and 27 heads). Likewise, 22 heads, 21, …, down to 0 heads. If we assume that the number of heads is binomially distributed, we can write:\n\\[\\begin{align} P(X \\le 23 \\textit{ or } X \\ge 27) & = 2 \\cdot P(X \\le 23) = 2 \\cdot \\sum_{i=0}^{23} \\left( \\begin{array}{c} 50 \\\\ i \\end{array} \\right) 0.5^{50} \\\\ & \\approx 0.672 \\end{align}\\]\nSo you can see that perfectly fair coins will behave at least as “unfairly” as our data more than two times out of three!3\nCode\n#coin hypothesis test\nplot(0:50,dbinom(0:50,50,0.5),type='h',lwd=4,xlim=c(10,40),\n     main='PMF of Fair Coin Flipped 50 Times',col='blue',\n     xlab='Number of heads',ylab='Probability')\npoints(24:26,dbinom(24:26,50,0.5),type='h',lwd=4)\ntext(27,dbinom(27,50,0.5),'x',pos=3)\nlegend(x='topright',legend=expression('Total Mass'%~~%0.672),\n       fill='blue')\n\n\n\n\n\n\n\n\nFigure 2.1: Two-tailed hypothesis test on the coin data, assuming a fair coin\nThe chain of reasoning we just followed is known as a hypothesis test. Above, you can see a figure which illustrates the same logic through a graph: the probability mass function (PMF) of a binomial variable where \\(N=50\\) and \\(p=0.5\\). This corresponds to our calculation of how the heads and tails will be distributed, under our assumption that the coin is fair. The maroon-colored lines are the probabilities for every outcome as extreme as our data (27 heads, marked ‘x’), or more extreme than our data. They sum to 0.672.\nIn truth, I did not strictly follow the steps of a formal hypothesis test, which I present below:\nEach of these steps involve many nuanced considerations, more than can be easily expressed in this short document. For the moment, I might simply say that hypothesis testing is incredibly misunderstood and misused throughout not just the broader scientific community (including data science), but even within the statistical community, which you might presume to know better. What I have presented here is a woefully incomplete tale, but we all must start somewhere. With those caveats, allow me a few further remarks:",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesis tests</span>"
    ]
  },
  {
    "objectID": "hypothesistest.html#two-tailed-hypothesis-tests",
    "href": "hypothesistest.html#two-tailed-hypothesis-tests",
    "title": "Hypothesis tests",
    "section": "",
    "text": "Let \\(X\\) be a random variable from a distribution but with one or more unknown parameters \\(\\theta\\), and let \\(\\boldsymbol{x}\\) be data sampled from \\(X\\). To perform a two-tailed hypothesis test, perform the following steps:\n\nDefine the null hypothesis, \\(H_0: \\theta = \\theta_0\\)\nDefine the alternative hypothesis, \\(H_1: \\theta \\ne \\theta_0\\)\nDetermine a significance threshold \\(\\alpha\\) which represents the maximum acceptable risk of falsely rejecting the null hypothesis in cases where it was actually true\nDerive a test statistic \\(T=f(\\cdot | \\theta_0)\\), a function of the sample which has a known probability distribution when the null hypothesis is true, and calculate \\(t_\\boldsymbol{x}=f(\\boldsymbol{x}|\\theta_0)\\)\nCompute the p-value of the test, which is the probability of observing a test statistic at least as extreme as observed in \\(\\boldsymbol{x}\\) — typically, \\(P(T \\gt t_\\boldsymbol{x})\\) or \\(P(T \\lt t_\\boldsymbol{x})\\)\nIf the p-value is less than or equal to \\(\\alpha\\) then reject \\(H_0\\), since the data make it too unlikely; otherwise, we do not have enough evidence to reject \\(H_0\\)\n\n\n\n\nSometimes we choose a null hypothesis \\(H_0\\) which we genuinely wish to evaluate as a possible truth about the world. Other times we choose a “straw man” null hypothesis which we do not seriously believe, in order to establish a more realistic alternative. These two cases are both legitimate avenues for scientific inquiry.\nNotice that the alternative hypothesis will frequently be a composite hypothesis, containing an infinitude of possibilities. Therefore, we only say that we “reject the null hypothesis”, never that we “accept the alternative hypothesis” — there are many alternative hypotheses, and some of them are even less likely to be true than our null hypothesis. We have done nothing to identify the ‘right’ alternative hypothesis, we have only ruled out the null hypothesis.\nThe significance threshold should be chosen before calculating your p-value, or else all this scientific rigor evaporates, leaving us with nothing more than a gut check. The most common significance threshold is \\(\\alpha = 0.05\\), but it’s best practice to choose a threshold that is actually appropriate to the context of your problem. I have often used thresholds as low as \\(\\alpha = 0.001\\) and as high as \\(\\alpha = 0.2\\) in my career.\nConsider the costs of wrongly rejecting the null hypothesis very carefully, and weigh them against the costs of wrongly failing to reject the null hypothesis. For example, a diagnostic test for cancer creates very different problems from a false positive versus a false negative.",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesis tests</span>"
    ]
  },
  {
    "objectID": "hypothesistest.html#one-tailed-hypothesis-tests",
    "href": "hypothesistest.html#one-tailed-hypothesis-tests",
    "title": "Hypothesis tests",
    "section": "One-tailed hypothesis tests",
    "text": "One-tailed hypothesis tests\nThe steps listed above document a two-sided hypothesis test, but sometimes we have an asymmetric problem to consider which suggests a one-tailed hypothesis test. As an example, let’s re-use the same coin data (27 heads, 23 tails), but invent a different story: Pretend that you have bought a “trick” coin from a magician, who promises that it lands tails much more often than heads. The magician isn’t sure of the precise probabilities, but guarantees that the coin lands heads no more than 40% of the time. Skeptical of the magician’s claims, you flip the coin 50 times and observe 27 heads. Could the magician be telling the truth? Let’s test this hypothesis through the following steps:\n\nWe define the null hypothesis, \\(H_0:p \\le 0.4\\). Notice that unlike the two-sided test, our null hypothesis is now composite, including many different possible truths.\nWe define the alternative hypothesis, \\(H_a:p \\gt 0.4\\). Just like the two-sided test, our null and alternative hypotheses are exhaustive and mutually exclusive: exactly one of them will always be true.\nWe set a significance threshold; here I will use the classic \\(\\alpha=0.05\\) since this example is made up and there are no real consequences to being wrong.\nWe derive a test statistic under the null hypothesis — here, simply the number of heads, which follows the binomial distribution. Our null contains multiple candidates for \\(p\\), but as the data suggest \\(p \\gt 0.4\\), we will assume \\(p=0.4\\), since every other parameter choice within the null hypothesis will result in even lower \\(p\\)-values.\nWe compute a \\(p\\)-value, that is, the probability of observing a test statistic at least as extreme as our data:\n\n\\[P(x \\ge 27 | p=0.4) = \\sum_{i=27}^{50} \\left(\\begin{array}{c} 50 \\\\ i \\end{array} \\right) 0.4^i\\ 0.6^{50-i} \\approx 0.031\\]\n\nSince our p-value of 0.031 is less than our significance threshold of 0.05, we reject the null hypothesis and conclude that we were swindled by the magician. We cannot be certain, but we know that “trick” coins like the one described create datasets like our own only 3% of the time.\n\nThe figure below illustrates this test, and shows why the two variants are called “two-tailed” and “one-tailed”. Two-tailed test evaluates all possible data samples which are at least as extreme as our actual data — these samples might support parameters less than or greater than \\(\\theta_0\\), and they fall in both the left and right “tails” of the test distribution. One-tailed tests evaluate only one side of those extreme samples:\n\n\nCode\n#coin hypothesis test\nplot(0:50,dbinom(0:50,50,0.4),type='h',lwd=4,xlim=c(10,40),\n     main='PMF of True p=0.4 Coin Flipped 50 Times',col='blue',\n     xlab='Number of heads',ylab='Probability')\npoints(0:26,dbinom(0:26,50,0.4),type='h',lwd=4)\ntext(27,dbinom(27,50,0.4),'x',pos=3)\nlegend(x='topright',legend=expression('Total Mass'%~~%0.031),\n       fill='blue')\n\n\n\n\n\n\n\n\nFigure 2.2: One-tailed hypothesis test of the coin data, assuming a trick coin",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesis tests</span>"
    ]
  },
  {
    "objectID": "hypothesistest.html#footnotes",
    "href": "hypothesistest.html#footnotes",
    "title": "Hypothesis tests",
    "section": "",
    "text": "If you disagree, I wonder what you think would happen if we flipped a fair coin five times…↩︎\nThis reasoning is very important for continuous distributions, where we may never observe the same data twice. But it also applies to discrete distributions: when we have many observations, the probability of any specific sequence of data can be very, very small.↩︎\nThe formula above makes use of the ‘combination’ operator, familiar to some readers but perhaps not others. In short, \\(({\\scriptstyle \\begin{array}{cc} N \\\\ k \\end{array}}) = N!/(N-k)!k!\\), with “!” representing the factorial symbol, whereby \\(k! = k \\cdot (k-1) \\cdot \\ldots \\cdot 2 \\cdot 1\\). The classic use case of combinations is to count the ways of selecting unordered sets of \\(k\\) objects from \\(N\\) total possibilities.↩︎",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesis tests</span>"
    ]
  },
  {
    "objectID": "biasvariance.html",
    "href": "biasvariance.html",
    "title": "Estimator bias and variance",
    "section": "",
    "text": "Visualizer: Normal estimation\nNot all estimators are created equal. Some estimators are worse than others, and they can be better or worse in different ways. Let’s pretend we have a normally distributed population (such as people’s heights, or stock returns), and we would like to estimate the true mean of the population \\(\\mu\\) from a sample of 100 observations, \\(\\boldsymbol{x}\\). We have already learned that the maximum likelihood estimator for the true mean is \\(\\bar{x}\\), the sample mean. What if I forced you to pick one of two alternative estimators:\n\\[\\begin{array}{ll} \\hat{\\mu}_1 = & \\frac{\\min(\\boldsymbol{x}) + \\max(\\boldsymbol{x})}{2} \\\\ \\hat{\\mu}_2 = & x_{(52)},\\, \\textrm{the }52^{nd}\\text{ observation (from smallest to largest)}\\end{array}\\]\nYou may not yet be an expert statistician, but you can probably guess something about the second estimator: \\(\\hat{\\mu}_2\\) will generally overestimate the true mean. The 50th or 51st observation out of 100 would generally be more central.\nIn the figure above, I simulated 100,000 different samples of 100 observations each, and plotted a histogram of how far from the true mean these two estimators were each time. You can see that while the 52nd ordered observation tends to slightly overestimate the true mean, it usually produces a much closer estimate than the other estimator (the straight average of the sample min and max). In fact, in almost three-quarters of the simulations, \\(\\hat{\\mu}_2\\) produced a closer estimate of the true mean than \\(\\hat{\\mu}_1\\). We call these concepts the bias and the variance of an estimator. Bias measures how much the estimator systematically overestimates or underestimates the true parameter. Variance measures how much its estimates change sample to sample.\nThe sport of archery provides a useful analogy for illustrating bias and variance. Imagine different archers (estimators) firing at the target. They are all aiming for the same goal (the true value of the parameter), but they can be off in different ways. One might have a tight grouping of shots that are all off-target in the same way (bias). Another might be hitting every corner of the target but, on average, is neither too high nor too low (variance).\nThere are other properties, such as consistency or efficiency, which can make an estimator desirable or undesirable, but the variance and bias of an estimator are generally the two most-discussed properties.1 They relate to a third metric which may be familiar from a machine learning perspective: mean squared error (MSE).\n\\[\\begin{array}{rl} \\mathrm{MSE}(\\hat{\\theta}) = & \\mathbb{E}[(\\hat{\\theta} - \\theta)^2] \\\\ = & \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}] + \\mathbb{E}[\\hat{\\theta}] - \\theta)^2] \\\\ = & \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}])^2 + 2 (\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}]) (\\mathbb{E}[\\hat{\\theta}] - \\theta) + (\\mathbb{E}[\\hat{\\theta}] - \\theta)^2] \\\\ = & \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}])]^2 + 2\\, \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}]) (\\mathbb{E}[\\hat{\\theta}] - \\theta)] + \\mathbb{E}[(\\mathbb{E}[\\hat{\\theta}] - \\theta)^2] \\\\ = & \\mathbb{V}[\\hat{\\theta}] + 2\\, \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}]) (\\mathbb{E}[\\hat{\\theta}] - \\theta)] + \\mathrm{Bias}(\\hat{\\theta})^2 \\\\ = & \\mathbb{V}[\\hat{\\theta}] + 2\\,(\\mathbb{E}[\\hat{\\theta}] - \\theta)\\, \\mathbb{E}[\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}]] + \\mathrm{Bias}(\\hat{\\theta})^2 \\\\ = & \\mathbb{V}[\\hat{\\theta}] + \\mathrm{Bias}(\\hat{\\theta})^2 \\end{array}\\]\nEssentially, the mean squared error of an estimator can always be decomposed into a systematic bias component and an idiosyncratic variance component. Between two models with the same MSE, a lower variance implies a higher bias and vice versa. This property is called the bias-variance tradeoff and will affect our modeling work in later sections.\nThere are times we prefer maximum likelihood estimators (MLEs) and times we do not. Consider estimating the mean \\((\\mu)\\) and standard deviation \\((\\sigma^2)\\) of a normal distribution from a sample. I will set true values of \\(\\mu = 100\\) and \\(\\sigma = 20\\). You can choose a sample size, and I will show you how various estimators perform among 10,000 simulated samples of that size.\nWe have many choices for an estimator of the mean, \\(\\mu\\). The MLE is the sample average, \\(\\bar{x}\\), but we could also choose the median of \\(\\boldsymbol{x}\\). Note that both estimators are unbiased, but that the sample average has lower variance, and that the effect grows for large sample sizes.\nWe have fewer sensible estimators for the standard deviation, \\(\\sigma\\). The MLE is the ‘uncorrected’ sample standard deviation, \\(\\sqrt{\\sum_i (x_i - \\bar{x})^2 / n}\\). However, you can see that when sample sizes are small, this estimator is biased; it underestimates the true standard deviation. A slight bias remains even at large sample sizes, but would be hard for the eye to detect. The ‘corrected’ sample standard deviation, \\(\\sqrt{\\sum_i (x_i - \\bar{x})^2 / (n - 1)}\\), remains unbiased and we usually choose this estimator even though it is not the MLE solution.",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimator bias and variance</span>"
    ]
  },
  {
    "objectID": "biasvariance.html#footnotes",
    "href": "biasvariance.html#footnotes",
    "title": "Estimator bias and variance",
    "section": "",
    "text": "Briefly, a consistent estimator produces better and better estimates as your sample size increases, while an efficient estimator makes the best possible use of the sample’s information.↩︎",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimator bias and variance</span>"
    ]
  },
  {
    "objectID": "confidenceintervals.html",
    "href": "confidenceintervals.html",
    "title": "Exact confidence intervals",
    "section": "",
    "text": "We have learned how to identify the best guess for an unknown parameter from the data. We have also learned how to check if a specific alternative is a reasonable guess, or if the data make it too unlikely to be true. Now we shall learn how to find the range of all reasonable guesses for an unknown parameter. This range is called a confidence interval, because the size of the range depends on how confident we are that it will contain the true parameter:\nYou are the one who decides how confident to be. Combining your own risk tolerance with the precise nature of the problem at hand, you choose a confidence level, usually a number close to 100%. Then you find the upper and lower bounds for your interval.\nI wish I could now show you how to construct a confidence interval. Many other textbooks do, at this point. But the truth is, confidence intervals are very poorly defined and statisticians do not agree on how best to build them. For the moment, I will leave you with an unsatisfying half-answer: what a confidence interval should do.\nI will show you one example of an exact confidence interval below, and in the next chapter I will show you a method for constructing approximate confidence intervals which are much easier to calculate and which are very accurate for large sample sizes.\nLet’s return to the coin data: 27 heads from 50 trials. We’ve already shown that a fair 50-50 coin could reasonably have produced this sample. We’ve also shown that an unfair 40-60 coin would not likely have produced this sample. Using a computer’s help and the CDF of the binomial distribution, I can find the exact lower and upper bounds \\(p^*_{l,0.05}\\) and \\(p^*_{u,0.05}\\) such that:\nWhen I use this method to build a confidence interval, I know that 10% of the time my data is going to “trick” me into constructing an interval which does not include the true parameter. This will happen when — by freak chance — the data contain so many heads (or so many tails) that the true parameter seems like a bad fit to the data. But 90% of the time the interval I create will contain the true parameter. Even when the data have a few more heads or a few more tails than expected, the true parameter will be among the values that could plausibly create such data. Therefore we say that this method produces an “exact” 90% confidence interval for \\(p\\).1\nWe will learn more about confidence intervals soon. But while we are discussing theory, I want to emphasize a few common misunderstandings about their concept and purpose. For the sake of argument, let’s say that you have a calculated a 95% confidence interval.",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Exact confidence intervals</span>"
    ]
  },
  {
    "objectID": "confidenceintervals.html#footnotes",
    "href": "confidenceintervals.html#footnotes",
    "title": "Exact confidence intervals",
    "section": "",
    "text": "This particular method is known as the Clopper-Pearson interval. But as if to illustrate the confusion on this topic, it is neither the only “exact” calculation nor the one with the best performance!↩︎",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Exact confidence intervals</span>"
    ]
  },
  {
    "objectID": "identification.html",
    "href": "identification.html",
    "title": "Identifying distributions",
    "section": "",
    "text": "Using what you and others know about the data\nThe prior sections have all assumed that our data comes to us from a known distribution, such as the normal or the binomial, and that all we need to do is find the specific parameters of the distribution. But in the real world, data are rarely labeled with their distribution name. Often, the data don’t even come from a named distribution at all. How can we be sure that we have chosen the right distribution with which to model our data?\nThe first step is to narrow down your list of candidate distributions. Ideally you will be in one of two scenarios:\nHowever the world is not an ideal place, and so sometimes we will choose a distribution not because it is “correct” but because it is “good enough” for our data. Remember also that your data may not be distributed neatly. Your data may include different subsamples, each with their own distribution. Your data might also be distributed a certain way only after accounting for other variables, which we will consider in future chapters. Do ask yourself the following, if you are unsure of where to start:",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Identifying distributions</span>"
    ]
  },
  {
    "objectID": "identification.html#using-what-you-and-others-know-about-the-data",
    "href": "identification.html#using-what-you-and-others-know-about-the-data",
    "title": "Identifying distributions",
    "section": "",
    "text": "The data you’re examining has been studied before, and other researchers have described it as being distributed a certain way. For example, daily stock returns are often modeled as being normal or lognormal. Lightbulb lifetimes are often modeled as exponentially distributed. (Stay cautious: there may be important differences between the earlier research and the data in front of you.)\nThe data you’re examining comes from a generating process with known physical properties suggesting certain distributions. For example, even if we are not familiar with astronomical literature, we can reason for ourselves that large meteors (\\(\\gt 1\\,\\)km diameter) might strike the Earth according to a Poisson process.\n\n\n\nDoes your data only take integer values (or is it easily transformed to take only integer values)? If so, consider a discrete distribution.\n\nBut what if the integers are all very large, like stadium attendance figures? Depending on your task, continuous distributions might work just as well.\nWhat if the general scale for the integers is different in each observation, such as smoking deaths by state? Perhaps it would be better to model the rate (e.g. deaths per 100,000 residents) as a continuous distribution, rather than modeling the count as discrete.\nCan the integers be negative? If so, you might need to transform the data, since most discrete distributions don’t permit negative values.\n\nAre the data naturally bounded above and/or below? Some distributions like the uniform or exponential might have matching bounds, others like the normal distribution do not have theoretical bounds, just practical limits where it would be rare to see any data.\nAre your data spread out over many degrees of magnitude? If so, a logarithmic transformation or the lognormal distribution might be useful, or again finding a way to express these figures relative to some baseline which varies by observation.",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Identifying distributions</span>"
    ]
  },
  {
    "objectID": "identification.html#empirical-distribution-functions-and-the-kolmogorov-smirnov-test",
    "href": "identification.html#empirical-distribution-functions-and-the-kolmogorov-smirnov-test",
    "title": "Identifying distributions",
    "section": "Empirical distribution functions and the Kolmogorov-Smirnov test",
    "text": "Empirical distribution functions and the Kolmogorov-Smirnov test\nProbability distributions are often plotted with very precise and elegant curves, brimming with mathematical truths and delicate nuances. And then there is your data: shaped like a mess, coarsely finite, and probably full of unhelpful outliers and misleading observations. But we can still plot the data as though it were a probability distribution, and learn from it:\n\nLet \\(\\boldsymbol{x}\\) be a sample of \\(n\\) observations. Define the indicator function \\(1\\!\\!1\\{x_i \\le t\\}\\) as 1 when an observation from \\(\\boldsymbol{x}\\) is less than or equal to some threshold value \\(t\\), and 0 otherwise. Then the empirical cumulative distribution function of \\(\\boldsymbol{x}\\) on a support of all \\(t \\in \\mathbb{R}\\) is:\n\\[\\hat{F}(t)=\\frac{1}{n} \\sum_{i} 1\\!\\!1\\{x_i \\le t\\}\\]\n\nThis definition provides us with a sample-based analog to the theoretical CDF of a probability distribution — which is why I use the notation \\(\\hat{F}(t)\\), to emphasize that it estimates some unknown cumulative distribution \\(F(t)\\). In essence, the empirical distribution function simply plots the ranks of data, or the quantiles of the data if you prefer that term. Below, I plot the empirical distribution function for 50 simulated heights next to a theoretical normal distribution which may or may not have generated the sample:\n\n\nCode\n#empirical cdf\npar(mfrow=c(1,2))\nset.seed(1977)\nhgt50 &lt;- round(rnorm(50,165,7),1)\nplot(ecdf(hgt50),do.points=FALSE,main=expression('Empirical CDF of 50 Heights'),\n     xlab='Height (cm)',ylab='ECDF',xlim=c(146,184))\nplot(seq(146,184,0.1),pnorm(seq(146,184,0.1),162,7),type='l',\n     col='#0000ff',main=expression(paste('Theoretical CDF of Norm(162,',7^2,')')),\n     ylab='Cumul. Prob.',xlab='Height (cm)',xlim=c(146,184))\n\n\n\n\n\n\n\n\nFigure 5.1: Empirical and Theoretical CDFs\n\n\n\n\n\nYou can see these two graphs resemble each other. We may be tempted to say that the sample came from the normal distribution, or at least that it could be normal. But we need not settle for visual approximations: we can use a hypothesis test specifically developed for this situation, which will more precisely compare these two graphs. The Kolmogorov-Smirnov test, or K-S test, was developed to help statisticians answer two similar questions:\n\nCould a sample \\(\\boldsymbol{x}\\) have been generated according to a theoretical distribution \\(X\\)?\nCould two samples, \\(\\boldsymbol{x}\\) and \\(\\boldsymbol{y}\\), be generated by the same unknown distribution?\n\nIt works by comparing the ECDF of one sample against either the theoretical CDF of a known distribution or against the ECDF of the second sample, and finding the maximum vertical difference between the two functions. Andrey Kolmogorov showed that under the null hypothesis that the two distributions are equal, this maximum discrepancy follows a novel probability distribution.\n\n\nCode\n#k-s test\nkst &lt;- suppressWarnings(ks.test(hgt50,pnorm,mean=162,sd=7))\nFhgt &lt;- sapply(seq(146,184,0.1),function(z){mean(hgt50&lt;=z)})\nFnorm &lt;- pnorm(seq(146,184,0.1),162,7)\nplot(ecdf(hgt50),do.points=FALSE,main=\n       expression(paste('K-S test of heights against Norm(162,',7^2,')')),\n     xlab='Height (cm)',ylab='Cumul. Prob.',xlim=c(146,184))\nlines(seq(146,184,0.1),Fnorm,col='#0000ff')\nk_max &lt;- order(abs(Fnorm-Fhgt),decreasing=TRUE)[1]\nx_max &lt;- seq(146,184,0.1)[152]\nsegments(x0=x_max,x1=x_max,y0=Fhgt[k_max],y1=Fnorm[k_max],lwd=3)\nlegend(x='topleft',bty='n',lwd=1,col=c('#000000','#0000ff'),\n       legend=c('ECDF of heights','Norm CDF'))\ntext(x=x_max,y=Fhgt[k_max],label='Max diff = 0.115, p-value=0.529',pos=4)\n\n\n\n\n\n\n\n\nFigure 5.2: Graphical illustration of a Kolmogorov-Smirnov test\n\n\n\n\n\nIn the figure above, we see that while the empirical CDF of our 50 heights does not always perfectly match the theoretical CDF of the normal distribution with mean 162 and variance 49, that same theoretical distribution would generate samples of 50 observations that look even stranger over 52% of the time, more than half of all samples. So we cannot rule out that the height data were generated from that theoretical distribution.1\nIn practice, we can use maximum likelihood estimation and the Kolmogorov-Smirnov test as an effective “toggle” to help rapidly propose and confirm possible distributions for our data. Consider using this set of steps whenever you are faced with new univariate data:\n\nIdentify a candidate distribution type, such as normal or binomial\nUse maximum likelihood to find the best possible parameters for the data, given your guess of the distribution type\nUse a K-S test to determine whether that distribution and those parameters are actually a good fit to the data (the best fit is not necessarily a good fit)\nIf so, proceed under the assumption that your data could be distributed that way. If not, go back to step 1, identify a new distribution type, and repeat.",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Identifying distributions</span>"
    ]
  },
  {
    "objectID": "identification.html#footnotes",
    "href": "identification.html#footnotes",
    "title": "Identifying distributions",
    "section": "",
    "text": "Since I generated the data, I will tell you: they are not from that distribution! They are from another!↩︎",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Identifying distributions</span>"
    ]
  },
  {
    "objectID": "dist_normal.html",
    "href": "dist_normal.html",
    "title": "Normal distribution",
    "section": "",
    "text": "Assumptions\nAlthough a few generating processes are provably normal, we mostly use the normal distribution in contexts where it is “close enough”, and do not require any particular assumptions.\nHowever, keep in mind that the normal distribution, at least in theory, is:\nIf the process you are modeling is bounded, discrete, or asymmetrical, then the normal distribution may be a poor fit. Two common exceptions would be:",
    "crumbs": [
      "Appendices",
      "Distributions",
      "Normal distribution"
    ]
  },
  {
    "objectID": "dist_normal.html#assumptions",
    "href": "dist_normal.html#assumptions",
    "title": "Normal distribution",
    "section": "",
    "text": "Unbounded\nContinuous\nSymmetrical\n\n\n\nWhen the distribution is naturally bounded, but most values are observed very far from the bounds (such as the weights of passenger jets, bounded below by 0, or the returns on a stock index, bounded below at -100%)\nWhen the distribution is discrete, but most values are very large or very finely subdivided (such as stadium attendance, or the current value of your bank account)",
    "crumbs": [
      "Appendices",
      "Distributions",
      "Normal distribution"
    ]
  },
  {
    "objectID": "dist_normal.html#definition",
    "href": "dist_normal.html#definition",
    "title": "Normal distribution",
    "section": "Definition",
    "text": "Definition\n\\[\\begin{array}{ll}\n  \\text{Support:} & \\mathbb{R} \\\\\n  \\text{Parameter(s):} & \\mu,\\text{ the mean }(\\mu \\in \\mathbb{R}) \\\\\n  & \\sigma,\\text{ the standard deviation }(\\sigma \\gt 0) \\\\\n  \\text{PDF:} & f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2} \\\\\n  \\text{CDF:} & F_X(x) = \\Phi(\\frac{x-\\mu}{\\sigma})\\quad (\\text{No closed form expression}) \\\\\n  \\text{Mean:} & \\mathbb{E}[X]=\\mu \\\\\n  \\text{Variance:} & \\mathbb{V}[X]=\\sigma^2 \\\\\n\\end{array}\\]",
    "crumbs": [
      "Appendices",
      "Distributions",
      "Normal distribution"
    ]
  },
  {
    "objectID": "dist_normal.html#visualizer",
    "href": "dist_normal.html#visualizer",
    "title": "Normal distribution",
    "section": "Visualizer",
    "text": "Visualizer\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 650\n\nlibrary(shiny)\nlibrary(bslib)\n\nui &lt;- page_fluid(\n      tags$head(tags$style(HTML(\"body {overflow-x: hidden;}\"))),\n  title = \"Normal distribution PDF\",\n  fluidRow(plotOutput(\"distPlot\")),\n  fluidRow(column(width=6,sliderInput(\"mu\", \"Mean (mu)\", min=-10, max=10, value=0)),\n           column(width=6,sliderInput(\"sigma\", \"Std Dev (sigma)\", min=0.01, max=10, value=1))))\n\nserver &lt;- function(input, output) {\n  output$distPlot &lt;- renderPlot({\n    x &lt;- seq(input$mu-3*input$sigma,input$mu+3*input$sigma,input$sigma/100)\n    y &lt;- dnorm(x,input$mu,input$sigma)\n    xlims &lt;- c(mean(c(-3,x[1])),mean(c(3,x[601])))\n    ylims &lt;- c(0,mean(c(dnorm(0),y[301])))\n    plot(x=x,y=y,main=NULL,xlab='x',ylab='Density',type='l',lwd=2,\n         xlim=xlims,ylim=ylims)\n  })\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "Appendices",
      "Distributions",
      "Normal distribution"
    ]
  },
  {
    "objectID": "dist_normal.html#properties",
    "href": "dist_normal.html#properties",
    "title": "Normal distribution",
    "section": "Properties",
    "text": "Properties\n\nThe normal distribution with mean \\(\\mu=0\\) and variance \\(\\sigma^2=1\\) is said to be the standard normal distribution and often written as \\(Z \\sim \\mathrm{Norm}(0,1)\\). The CDF of the standard normal distribution and its inverse are often abbreviated as \\(F_X(x)=\\Phi(x)\\) and \\(F_X^{-1}(x)=\\Phi^{-1}(x)\\), respectively.\nIf \\(X\\) is a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then for any constants \\(a,b \\in \\mathbb{R}\\) the transformation \\(aX + b\\) is also a normal random variable with mean \\(a\\mu + b\\) and variance \\(a^2\\sigma^2\\).\nIf \\(X\\) and \\(Y\\) are two independent normal random variables with means \\(\\mu_X, \\mu_Y\\) and variances \\(\\sigma^2_X, \\sigma^2_Y\\), then their sum \\(X+Y\\) is also a normal random variable with mean \\(\\mu_X+\\mu_Y\\) and variance \\(\\sigma^2_X+\\sigma^2_Y\\).\nMore generally, any linear combination of any number of independent normal random variables is itself a normal random variable!",
    "crumbs": [
      "Appendices",
      "Distributions",
      "Normal distribution"
    ]
  },
  {
    "objectID": "dist_normal.html#relations-to-other-distributions",
    "href": "dist_normal.html#relations-to-other-distributions",
    "title": "Normal distribution",
    "section": "Relations to other distributions",
    "text": "Relations to other distributions\n\nThe sum of the squares of \\(n\\) independent standard normal variates is chi-squared distributed with \\(df=n\\): \\[\\sum_{i=1}^n Z_i^2 \\sim \\chi_{(n)}^2\\]\nThe ratio of two standard normal variates has the standard Cauchy distribution, i.e. \\[\\mathrm{For\\ }Z_1,Z_2 \\sim \\mathrm{Norm}(0,1),\\quad \\frac{Z_1}{Z_2} \\sim \\mathrm{Cauchy}(0,1)\\]\nThe standard normal distribution is the limit case for the Student’s t-distribution (as \\(df \\rightarrow \\infty\\)). The standard normal can be used in place of the t-distribution with little loss of accuracy for large \\(df\\).\nThe normal distribution with mean \\(df\\) and standard deviation \\(\\sqrt{2df}\\) closely approximates the chi-squared distribution for large \\(df\\).\nThe Poisson distribution and binomial distribution both form discrete approximations to the normal distribution when either \\(\\lambda\\) is very large (Poisson) or \\(np\\) is very large and \\(p\\) is not near 0 or 1.\n\ngfds",
    "crumbs": [
      "Appendices",
      "Distributions",
      "Normal distribution"
    ]
  },
  {
    "objectID": "likelihood.html#example-1-coin-flips",
    "href": "likelihood.html#example-1-coin-flips",
    "title": "Univariate likelihood",
    "section": "Example 1: Coin flips",
    "text": "Example 1: Coin flips\nSuppose that we were given a coin and told it was fixed to land on one side more than the other. We flip the coin 50 times and record each ‘heads’ as 1 and each ‘tails’ as 0. The results below show that the coin landed ‘heads’ 27 times and ‘tails’ 23 times.\n\\[\\boldsymbol{x}=\\left\\{ \\begin{aligned} 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, \\\\ 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0 \\; \\end{aligned} \\right\\}\\]\nLet us make a distributional assumption: the coin data can be modeled by a Bernoulli distribution. We cannot know whether this is correct or not, but it seems reasonable: Bernoulli trials require exactly two outcomes, a fixed probability of success, and independence between trials. While it’s possible that the coin could land on its edge, or that it deforms over time, or that it shows serial correlation, modeling the coin flips as Bernoulli trials seems true enough to be useful.1\nWhat is the probability of observing the data if the coin truly lands heads 60% of the time? You should be able to answer this from your past lessons in probability and statistics. Since we assume trials to be independent, we can write:\n\\[\\begin{align}P(\\boldsymbol{x} | p = 0.6) &= \\prod_{i = 1}^{50} P(x_i | p = 0.6) = 0.4 \\cdot 0.4 \\cdot 0.6 \\cdot \\ldots \\cdot 0.4 \\\\ &= 0.6^{27} \\cdot 0.4^{23} \\approx 7.2×10^{-16}\\end{align}\\]\nA very small number… although these results are actually quite unextraordinary, there are simply so many ways that 50 coin flips can occur (1.13 quadrillion ways) that even the most common sequences each have a very, very low probability.\nWhat is the likelihood for any given parameter \\(p\\), given our dataset of 27 heads in 50 flips?\n\\[\\mathcal{L}(p|\\boldsymbol{x}) = \\prod_{i=1}^{50} P(x_i|p) = p^{27} (1-p)^{23}\\]\nWhat is the value of \\(p\\) which maximizes this likelihood? It’s not immediately evident from the equation above, but perhaps the log-likelihood will help us to solve for \\(p\\):\n\\[\\ell(p|\\boldsymbol{x}) = \\log{\\mathcal{L}(p|\\boldsymbol{x})} = 27\\log{⁡p}+23\\log⁡(1-p)\\]\nThis is still difficult to solve by hand, so let’s bring in the final trick, and instead try to find the root of the first derivative of the log-likelihood:\n\\[\\frac{d}{dp} \\ell(p│\\boldsymbol{x}) = \\frac{27}{p}-\\frac{23}{1-p}\\]\nSetting the above equal to zero and solving for p,\n\\[\\begin{align} \\frac{27}{p}-\\frac{23}{1-p} = 0 & \\Longrightarrow \\frac{27}{p} = \\frac{23}{1-p} \\Longrightarrow 27-27p = 23p \\\\ & \\Longrightarrow 50p=27 \\Longrightarrow \\hat{p}_\\textit{MLE} = \\frac{27}{50}=0.54 \\end{align}\\]\nIn fact, we could abstract a little further here to find the MLE for any Bernoulli-distributed sample. Let \\(k\\) be the number of successes and \\(n\\) be the total number of trials. Using the same math as above, you will find that:\n\\[\\hat{p}_\\mathit{MLE} = k/n = \\frac{\\sum_i x_i}{n} = \\bar{x}\\] This is a tidy little result. When our data are Bernoulli distributed, then the maximum likelihood estimator for the parameter \\(p\\) is simply the sample average, i.e. the proportion of observations that were successes. I like findings such as these which conform with our intuition: when we have data on a Bernoulli process, our best guess as to how often successes truly happen will simply be how often successes occurred in our data.",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate likelihood</span>"
    ]
  },
  {
    "objectID": "likelihood.html#example-2-heights",
    "href": "likelihood.html#example-2-heights",
    "title": "Univariate likelihood",
    "section": "Example 2: Heights",
    "text": "Example 2: Heights\nThe above example used a very simple discrete distribution with a single parameter. Let’s try again with a more complicated continuous distribution, which uses two parameters. Across the entire world population, heights are not exactly distributed according to any known distribution. However, among otherwise homogeneous populations, we do observe that heights are roughly normally distributed. Let’s pretend that we sampled 10 adult women in the United States and measured their heights. Rounded to the nearest tenth of a centimeter, their heights are listed below:2\n\\[\\boldsymbol{x}=\\{170.1,161.6,175.2,166.3,165.6,165.8,152.0,155.8,168.6,154.3\\}\\] Let us assume that these heights are drawn from a normal distribution. What then would be the best guess for the parameters \\(\\mu\\) and \\(\\sigma^2\\), which are the mean and variance of the distribution? We will start by finding the likelihood function. Recall that if \\(X\\) is normal,\n\\[f_X(x|\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\\] From this, we can compute the likelihood of any pair of normal parameters for any dataset:\n\\[\\mathcal{L}(\\mu,\\sigma^2|\\boldsymbol{x}) = (2\\pi\\sigma^2)^{-n/2}\\cdot e^{-\\frac{1}{2\\sigma^2}\\sum_{i}(x_i-\\mu)^2}\\] Then, we can find the log-likelihood:\n\\[\\ell(\\mu,\\sigma^2|\\boldsymbol{x}) = \\log{\\mathcal{L}(\\mu,\\sigma^2|\\boldsymbol{x})} = -\\frac{n}{2}\\log{2\\pi\\sigma^2} - \\frac{1}{2\\sigma^2} \\sum_{i}(x_i-\\mu)^2\\]\nNext, we will take the derivative with respect to \\(\\mu\\):\n\\[\\frac{\\partial\\ell}{\\partial\\mu} = \\frac{1}{\\sigma^2} \\sum_{i}(x_i-μ) \\] From here we will solve for the root of the derivative, which will be the value of \\(\\mu\\) that maximizes the original likelihood function:\n\\[\\begin{align} \\frac{\\partial\\ell}{\\partial\\mu} = 0 & \\Longrightarrow \\sum_i (x_i-\\mu) = 0 \\Longrightarrow \\sum_i x_i - n\\mu = 0 \\Longrightarrow n\\mu=\\sum_i x_i \\\\ & \\Longrightarrow \\hat{\\mu}_\\textit{MLE} = \\bar{x} \\end{align}\\]\nWhat a fantastic bit of luck. The best guess for the true mean of a normal distribution is the sample mean of our data! Let’s finish up by repeating for variance: first we take the partial derivative of the log-likelihood with respect to \\(\\sigma^2\\):\n\\[\\frac{\\partial\\ell}{\\partial\\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4}\\sum_i (x_i-\\mu)^2\\] Then we will solve for the root of the derivative, which will be the value of \\(\\sigma^2\\) which maximizes the original likelihood function:\n\\[\\begin{align} \\frac{\\partial\\ell}{\\partial\\sigma^2} =0 & \\Longrightarrow \\frac{1}{2\\sigma^4} \\sum_i (x_i-\\mu)^2 = \\frac{n}{2\\sigma^2} \\Longrightarrow \\frac{1}{\\sigma^2} \\sum_i (x_i-\\mu)^2 = n \\\\ & \\Longrightarrow \\hat{\\sigma}^2_\\textit{MLE} = \\frac{1}{n} \\sum_i (x_i-\\mu)^2 \\end{align}\\]\nYou may recognize this quantity as the biased (uncorrected) sample variance. Although this calculation seems very sensible, we will later show that it systematically underestimates the true variance \\(\\sigma^2\\), which provides our first hint that maximum likelihood estimation is not the final answer for every problem we will encounter.\nWith these results in hand, we can produce the MLEs for our normal parameters given our height data. We would say that the best guess for the true mean height of adult women in the United States is 163.5 cm and the best guess for their variance would be 50.4 cm\\({}^2\\) (implying a standard deviation of 7.1 cm).3\n\n\nCode\n#generate height data\nheights &lt;- c(170.1,161.6,175.2,166.3,165.6,165.8,152.0,155.8,168.6,154.3)\n\n#generate height parameter ll contour plot\nheight.ll &lt;- function(parms) {-1*length(heights)*log(2*pi*parms[2])/2-sum((heights-parms[1])^2)/(2*parms[2])}\nxgrid &lt;- seq(140,180,0.1)\nygrid &lt;- seq(25,80,0.1)\nzgrid &lt;- matrix(apply(cbind(rep(xgrid,times=length(ygrid)),rep(ygrid,each=length(xgrid))),\n                      1,height.ll),ncol=length(ygrid))\nfilled.contour(xgrid,ygrid,zgrid,levels=c(-120,-100,-80,-70,-60,-50,-40,-35,-34,-33.8,-33.7),\n               col=paste0('#000000',c('00','20','40','60','80','9f','af','cf','ef','ff')),\n               main='Log-Lik of Parameters for Height Data',\n               xlab='Mu (mean height, in cm)',ylab='Sigma^2 (variance)')\n\n\n\n\n\n\n\n\nFigure 1.3: Contour plot of height data log-likelihoods\n\n\n\n\n\nWe can confirm that these solutions are reasonable by plotting the log-likelihood of various combinations of mean and variance, seen above. Notice that a broad range of possible means and variances have log-likelihoods close to the maximum value of -33.8. Any of these combinations could easily have generated our data. But if we have to make one guess, then the MLE values of (163.5, 50.4) would be our best choice.",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate likelihood</span>"
    ]
  },
  {
    "objectID": "likelihood.html#visualizer-exponential-likelihoods",
    "href": "likelihood.html#visualizer-exponential-likelihoods",
    "title": "Univariate likelihood",
    "section": "Visualizer: Exponential likelihoods",
    "text": "Visualizer: Exponential likelihoods\nThis visualizer shows an exponential distribution, which is often used to model the waiting times between events. You can create a sample by adjusting the rate parameter \\(\\lambda\\) (e.g. \\(\\lambda=5\\) might mean an average of five events per hour), and the total sample size. Then the visualizer will plot the raw data (each waiting time) as well as the likelihood, log-likelihood, and derivative of the log-likelihood function for the parameter \\(\\lambda\\).\nNotice how the parameter value made most likely by your data will never quite “right” (i.e. equal to the true parameter.) But as sample size increases, the estimates usually get closer to the true value, and the likelihood function develops a very narrow “peak” around our estimate, meaning that the other values are not made very likely by our data.\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 960\n\nlibrary(shiny)\nlibrary(bslib)\n\nll &lt;- function(lambda,x) length(x)*log(lambda) - lambda*sum(x)\nl &lt;- function(lambda,x) exp(ll(lambda,x))\ndll &lt;-function(lambda,x) length(x)/lambda - sum(x)\nx.axis &lt;- seq(0.05,6.0,0.05)\n\nui &lt;- page_fluid(\n  tags$head(tags$style(HTML(\"body {overflow-x: hidden;}\"))),\n  title = \"Likelihood for an Exponential sample\",\n  fluidRow(column(width=6,sliderInput(\"lambda\", \"Lambda (rate)\", min=1, max=5, value=3)),\n           column(width=6,sliderInput(\"nsamp\", \"N (sample size)\", min=10, max=1000, value=100))),\n  fluidRow(column(width=6,plotOutput(\"distPlot1\")),\n           column(width=6,plotOutput(\"distPlot2\"))),\n  fluidRow(column(width=6,plotOutput(\"distPlot3\")),\n           column(width=6,plotOutput(\"distPlot4\"))))\n\nserver &lt;- function(input, output) {\n  x &lt;- reactive({rexp(n=input$nsamp,rate=input$lambda)})\n  output$distPlot1 &lt;- renderPlot(hist(x(),main='Histogram of Data',xlab='Waiting time',ylab='Frequency'))\n  output$distPlot2 &lt;- renderPlot({plot(x.axis,l(x.axis,x()),main='Likelihoods for Lambda',xlab='Lambda',ylab='Likelihood',type='l',xlim=c(0,6)); abline(v=1/mean(x()),col='#0000ff')})\n  output$distPlot3 &lt;- renderPlot({plot(x.axis,ll(x.axis,x()),main='Log-likelihoods for Lambda',xlab='Lambda',ylab='Log-likelihood',type='l',xlim=c(0,6)); abline(v=1/mean(x()),col='#0000ff')})\n  output$distPlot4 &lt;- renderPlot({plot(x.axis,dll(x.axis,x()),main='First Derivative of LL for Lambda',xlab='Lambda',ylab='dLL/dLambda',type='l',xlim=c(0,6),ylim=c(-100,500)); abline(h=0,lty=2); abline(v=1/mean(x()),col='#0000ff')})\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate likelihood</span>"
    ]
  },
  {
    "objectID": "hypothesistest.html#visualizer-poisson-estimation",
    "href": "hypothesistest.html#visualizer-poisson-estimation",
    "title": "Hypothesis tests",
    "section": "Visualizer: Poisson estimation",
    "text": "Visualizer: Poisson estimation\nThis visualizer shows data generated from a Poisson distribution, which is often used to model the number of events observed in a fixed period. You can set the true rate (lambda) wherever you like, and also set a sample size. For the purpose of this visualization, assume that you are asked if the true rate could be 5, i.e. \\(H_0: \\lambda = 5\\). On the left you can see a plot of your sample, and on the right you can see how often samples that extreme are generated from a true Poisson(\\(\\lambda\\)=5) process. The results of the two-tailed hypothesis test (which may draw the wrong conclusion!) are at the bottom.\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n\nlibrary(shiny)\nlibrary(bslib)\n\nui &lt;- page_fluid(\n  tags$head(tags$style(HTML(\"body {overflow-x: hidden;}\"))),\n  title = \"Hypothesis test for a Poisson sample\",\n  fluidRow(column(width=4,sliderInput(\"lambda\", \"True lambda (rate)\", min=3, max=7, value=5, step=0.05)),\n           column(width=4,sliderInput(\"nsamp\", \"N (sample size)\", min=10, max=500, value=50)),\n           column(width=4,sliderInput(\"alpha\", \"Alpha\", min=0.01, max=0.2, value=0.05))),\n  fluidRow(column(width=6,plotOutput(\"distPlot1\")),\n           column(width=6,plotOutput(\"distPlot2\"))),\n  fluidRow(column(width=12,textOutput(\"textString1\"))))\n\nserver &lt;- function(input, output) {\n  x &lt;- reactive({rpois(n=input$nsamp,lambda=input$lambda)})\n  y &lt;- reactive({input$nsamp*dpois(0:max(x()),5)})\n  z &lt;- reactive({(0:2714)[dpois(0:2714,5*input$nsamp)&gt;1e-6]})\n  w &lt;- reactive({(0:2714)[dpois(0:2714,5*input$nsamp)&lt;=dpois(sum(x()),5*input$nsamp)]})\n  text1 &lt;- reactive({if (sum(dpois(0:2714,5*input$nsamp)[dpois(0:2714,5*input$nsamp)&lt;=dpois(sum(x()),5*input$nsamp)])&lt;=input$alpha) 'we *reject*' else 'we *cannot* reject'})\n  output$distPlot1 &lt;- renderPlot({plot(table(x()),main='Histogram of Data',xlab='Number of events',ylab='Frequency'); points(0:max(x()),y(),col='#0000ff'); legend(x='topright',legend=expression(paste('Expected if ', lambda == 5)),col='#0000ff',pch=1)})\n  output$distPlot2 &lt;- renderPlot({plot(z(),dpois(z(),5*length(x())),type='h',main='Distribution Under H0',xlab='Sum of sample',ylab='Probability',lwd=3/log(length(x()),10)); points(w(),dpois(w(),5*length(x())),type='h',col='#0000ff',lwd=3/log(length(x()),10))})\n  output$textString1 &lt;- renderText({paste('Under H0, data as extreme as our sample are observed ', round(100*sum(dpois(w(),5*length(x()))),1), '% of the time. Since alpha=', input$alpha, text1(), ' the null hypothesis that lambda=5.')})\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesis tests</span>"
    ]
  },
  {
    "objectID": "biasvariance.html#visualizer-normal-estimation",
    "href": "biasvariance.html#visualizer-normal-estimation",
    "title": "Estimator bias and variance",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 900\n\nlibrary(shiny)\nlibrary(bslib)\n\nui &lt;- page_fluid(\n  tags$head(tags$style(HTML(\"body {overflow-x: hidden;}\"))),\n  title = \"Variance and bias of Normal estimators\",\n  fluidRow(column(width=3,\"\"),column(width=6,sliderInput(\"nsamp\", \"N (sample size)\", min=5, max=200, value=25)),column(width=3,\"\")),\n  fluidRow(column(width=12,plotOutput(\"distPlot1\"))),\n  fluidRow(column(width=12,plotOutput(\"distPlot2\"))))\n\nserver &lt;- function(input, output) {\n  x &lt;- reactive({matrix(rnorm(10000*input$nsamp,100,20),nrow=10000)})\n  xbar &lt;- reactive({apply(x(),1,mean)})\n  xmed &lt;- reactive({apply(x(),1,median)})\n  xsd &lt;- reactive({apply(x(),1,sd)})\n  xrmse &lt;- reactive({sqrt(xsd()^2*(input$nsamp-1)/input$nsamp)})\n  output$distPlot1 &lt;- renderPlot({hist(xbar(), breaks=seq(min(xbar(),xmed()),max(xbar(),xmed()),length.out=31), main='10,000 estimates for the mean', xlab='Mu-hat', ylab='Frequency', col='#ff000080'); hist(xmed(), breaks=seq(min(xbar(),xmed()),max(xbar(),xmed()),length.out=31), col='#0000ff80', add=TRUE); legend(x='topright', legend=c('Sample mean','Sample median'), fill=c('#ff000080','#0000ff80'), bty='n')})\n  output$distPlot2 &lt;- renderPlot({hist(xrmse(), breaks=seq(min(xrmse(),xsd()),max(xrmse(),xsd()),length.out=31), main='10,000 estimates for the std dev', xlab='Sigma-hat', ylab='Frequency', col='#ff000080'); hist(xsd(), breaks=seq(min(xrmse(),xsd()),max(xrmse(),xsd()),length.out=31), col='#0000ff80', add=TRUE); legend(x='topright', legend=c('Uncorrected: /(n)','Corrected: /(n-1)'), fill=c('#ff000080','#0000ff80'), bty='n')})\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "1. Univariate Techniques",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimator bias and variance</span>"
    ]
  }
]