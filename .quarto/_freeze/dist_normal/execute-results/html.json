{
  "hash": "02c873ba3ac31cbdd61e97b3930e220c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Normal Distribution\"\nformat: html\nfilters:\n  - shinylive\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Assumptions\n\nAlthough a few generating processes are provably normal, we mostly use the normal distribution in contexts where it is “close enough”, and do not require any particular assumptions.\n\nHowever, keep in mind that the normal distribution, at least in theory, is:\n\n * Unbounded\n * Continuous\n * Symmetrical\n \nIf the process you are modeling is bounded, discrete, or asymmetrical, then the normal distribution may be a poor fit. Two common exceptions would be:\n\n * When the distribution is naturally bounded, but most values are observed very far from the bounds (such as the weights of passenger jets, bounded below by 0, or the returns on a stock index, bounded below at -100%)\n * When the distribution is discrete, but most values are very large or very finely subdivided (such as stadium attendance, or the current value of your bank account)\n \n## Definition\n\n$$\\begin{array}{ll}\n  \\text{Support:} & \\mathbb{R} \\\\\n  \\text{Parameter(s):} & \\mu,\\text{ the mean }(\\mu \\in \\mathbb{R}) \\\\\n  & \\sigma,\\text{ the standard deviation }(\\sigma \\gt 0) \\\\\n  \\text{PDF:} & f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2} \\\\\n  \\text{CDF:} & F_X(x) = \\Phi(\\frac{x-\\mu}{\\sigma})\\quad (\\text{No closed form expression}) \\\\\n  \\text{Mean:} & \\mathbb{E}[X]=\\mu \\\\\n  \\text{Variance:} & \\mathbb{V}[X]=\\sigma^2 \\\\\n\\end{array}$$\n\n\n## Visualizer\n```{shinylive-r}\n#| standalone: true\n#| viewerHeight: 650\n\nlibrary(shiny)\nlibrary(bslib)\n\nui <- page_sidebar(title = \"Normal distribution PDF\",\n  sidebar = sidebar(list(sliderInput(\"mu\", \"Mean (mu)\", min=-10, max=10, value=0),\n                         sliderInput(\"sigma\", \"Std Dev (sigma)\", min=0.01, max=10, value=1))),\n  plotOutput(\"distPlot\"))\n\nserver <- function(input, output) {\n  output$distPlot <- renderPlot({\n    x <- seq(input$mu-3*input$sigma,input$mu+3*input$sigma,input$sigma/100)\n    y <- dnorm(x,input$mu,input$sigma)\n    xlims <- c(mean(c(-3,x[1])),mean(c(3,x[601])))\n    ylims <- c(0,mean(c(dnorm(0),y[301])))\n    plot(x=x,y=y,main=NULL,xlab='x',ylab='Density',type='l',lwd=2,\n         xlim=xlims,ylim=ylims)\n  })\n}\n\nshinyApp(ui = ui, server = server)\n```\n\n## Properties\n\n * The normal distribution with mean $\\mu=0$ and variance $\\sigma^2=1$ is said to be the **standard normal distribution** and often written as $Z \\sim \\mathrm{Norm}(0,1)$. The CDF of the standard normal distribution and its inverse are often abbreviated as $F_X(x)=\\Phi(x)$ and $F_X^{-1}(x)=\\Phi^{-1}(x)$, respectively.\n * If $X$ is a normal random variable with mean $\\mu$ and variance $\\sigma^2$, then for any constants $a,b \\in \\mathbb{R}$ the transformation $aX + b$ is also a normal random variable with mean $a\\mu + b$ and variance $a^2\\sigma^2$.\n * If $X$ and $Y$ are two independent normal random variables with means $\\mu_X, \\mu_Y$ and variances $\\sigma^2_X, \\sigma^2_Y$, then their sum $X+Y$ is also a normal random variable with mean $\\mu_X+\\mu_Y$ and variance $\\sigma^2_X+\\sigma^2_Y$.\n * More generally, any linear combination of any number of independent normal random variables is itself a normal random variable!\n \n## Relations to other distributions\n\n * The sum of the squares of $n$ independent standard normal variates is chi-squared distributed with $df=n$:\n $$\\sum_{i=1}^n Z_i^2 \\sim \\chi_{(n)}^2$$\n * The ratio of two standard normal variates has the standard Cauchy distribution, *i.e.*\n $$\\mathrm{For\\ }Z_1,Z_2 \\sim \\mathrm{Norm}(0,1),\\quad \\frac{Z_1}{Z_2} \\sim \\mathrm{Cauchy}(0,1)$$\n * The standard normal distribution is the limit case for the Student's *t*-distribution (as $df \\rightarrow \\infty$). The standard normal can be used in place of the *t*-distribution with little loss of accuracy for large $df$.\n * The normal distribution with mean $df$ and standard deviation $\\sqrt{2df}$ closely approximates the chi-squared distribution for large $df$.\n * The Poisson distribution and binomial distribution both form discrete approximations to the normal distribution when either $\\lambda$ is very large (Poisson) or $np$ is very large and $p$ is not near 0 or 1. \n \n \n \n gfds",
    "supporting": [
      "dist_normal_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}