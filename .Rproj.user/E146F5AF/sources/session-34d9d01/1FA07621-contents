# Probability theory {#sec-prob}

It might surprise you to learn that mathematicians did not complete a formal system for defining probability until Andrey Kolmogorov’s work in the 1930s. Many important insights and results had been noticed by earlier mathematicians, but our “classical” understanding of probability is still less than 100 years old. More recently, mathematicians have explored other systems of probability by relaxing or modifying Kolmogorov’s axioms. The most famous alternative system of probability is the “Bayesian” school, which I will not discuss here.

## Experiments

Kolmogorov’s definition of probability relies on the idea of an experiment. The “experiment” can be very broad or abstract, including actual experiments performed by scientists in laboratories but also natural phenomenon such as tomorrow’s weather and human activities such as a hedge fund’s annual performance.

Imagine an experiment made up of many different trials of the same experimental process. Each trial ends in a single outcome, and there are multiple possible outcomes (possibly an infinite number of outcomes). For example, let us consider an experiment where each trial involves flipping two coins, each marked H for heads and T for tails. Then the four ordered outcomes would be:

::: {#fig-outcomes}
$$\qquad \, \Large{\{\mathrm{HH},\mathrm{TH},\mathrm{TH},\mathrm{TT}\}}$$ $${}_\mathrm{First\ flip}{}^\nearrow \quad {}^\nwarrow{}_\mathrm{Second\ flip}$$

Outcomes of an experiment which flips two coins
:::

Each trial ends in one outcome, but we will want to consider combinations of outcomes, which will be called events. For example, the event {HH, HT, TH} includes three outcomes, and we could think of this event as “a trial resulting in at least one head”. One special event is the empty set (seen earlier in @sec-sets), sometimes written $\emptyset$, which is an event containing no outcomes. This event never happens(!) but we still find it mathematically useful, just like we find zero helpful even if we don’t “see” zeroes around us. Set theory teaches us that for $n$ different elements, there are $2^n$ ways to choose combinations of those elements, which means that with four outcomes there are sixteen events:

::: {#fig-events}
$$\begin{array}{ll} \scriptsize{\textit{1 event with no outcomes}} & \emptyset \\
\scriptsize{\textit{4 events with one outcome}} & \{\mathrm{HH}\},\{\mathrm{HT}\},\{\mathrm{TH}\},\{\mathrm{TT}\} \\
\scriptsize{\textit{6 events with two outcomes}} & \{\mathrm{HH},\mathrm{HT}\},\{\mathrm{HH},\mathrm{TH}\},\{\mathrm{HH},\mathrm{TT}\},\{\mathrm{HT},\mathrm{TH}\},\{\mathrm{HT},\mathrm{TT}\},\{\mathrm{TH},\mathrm{TT}\} \\
\scriptsize{\textit{4 events with three outcomes}} & \{\mathrm{HH},\mathrm{HT},\mathrm{TH}\},\{\mathrm{HH},\mathrm{HT},\mathrm{TT}\},\{\mathrm{HH},\mathrm{TH},\mathrm{TT}\},\{\mathrm{HT},\mathrm{TH},\mathrm{TT}\} \\
\scriptsize{\textit{1 event with four outcomes}} & \{\mathrm{HH},\mathrm{HT},\mathrm{TH},\mathrm{TT}\} \end{array}$$

Events of an experiment which flips two coins
:::

Notice that these combinations are *unordered* subsets of the outcomes. For example, I did not separately list both {HT, TT} and {TT, HT} as two different events, since they both contain the same two outcomes. On the other hand, the nature of our experiment requires that the order of the *flips* does matter: the event {HT, TT} is meaningfully different from the event {TH, TT}.

Let’s review:

::: callout-note
The **outcomes** of an experiment are the set of all possible results from a single trial.

The **event space** of an experiment is the set of all unordered combinations of the outcomes including the empty set ($\emptyset$), each individual outcome, and all pairs, triplets, etc. of the outcomes.
:::

## The axioms of probability

Having set up this idea of an experiment, we now define probability as a way of assigning a numeric score to each event in an experiment.

There are of course many ways we could make numeric scores for each event, and most of them are unhelpful. So we will need rules to help separate “probability” from all the other, unhelpful ways we could assign scores to events. Andrey Kolmogorov proposed the following three rules, often called the axioms of probability. If we assume these rules, all of probability and (classical) parametric statistics will follow:

::: callout-note
Let the triplet $\Omega,\mathcal{F},P$ define an experiment, where:

-   $\Omega$ is the set of outcomes of the experiment (possible results of a single trial)

-   $\mathcal{F}$ is the set of events of the experiment (combinations of outcomes)

-   $P(E)$ is a function which assigns a real number to each event $E$ in $\mathcal{F}$

If we choose $P$ using the following three conditions,

1.  $P(E) \geq 0 \quad \forall E \in F$ (All events have non-negative probability)

2.  $P(\Omega)=1$ (The probability of observing any of the outcomes is 1)

3.  If a group of events $E_1,E_1,\ldots,E_n$ are disjoint then $P(\bigcup_{i=1}^n E_i)=\sum_{i=1}^n P(E_i)$ (The combined probability of a union of mutually exclusive events is equal to the sum of the probabilities of each individual event)

Then we say that $P$ measures **probability**.
:::

Now that we have defined probability, let’s review some basic properties of how probability works. You have probably seen these before, or at least they should make a certain amount of sense. I will not prove them here, but they can all be proven from the axioms and other simple mathematical theorems.

::: callout-note
Let the triplet $\Omega,\mathcal{F},P$ define an experiment, and let $A$ and $B$ be events within $\mathcal{F}$:

-   $P(A^c ) = 1 - P(A)$

-   $P(A \cup B) = P(A) + P(B) - (A \cap B)$

-   If A and B are disjoint (mutually exclusive), then $P(A \cap B) = P(A) + P(B)$
:::

The first result above simply confirms that the probability of an event happening is equivalent to one minus the probability of the event not happening. The second result helps us to find the probability that $A$ or $B$ will happen (you can think of union as ‘or’ operator and intersection as ‘and’). If we simply add all the probability of $A$ to all the probability of $B$, we will double-count their intersection, which is in both sets. So we must subtract one intersection... unless the two sets are disjoint, in which case there is no problem!

### Joint, marginal, and conditional probability

Often we wish to study the relationships between two or more experiments. For example, consider someone who takes a diagnostic test for a particular disease:

-   One experiment is whether the person actually has the disease

-   A different experiment is whether the person tests positive for the disease, *regardless of whether they actually have it*

Most people who test for a disease have some valid concern, and so among the test-takers let us assume that $P(\mathrm{Disease})=0.60$. Let us further assume that the test is imperfect, with few fase positives but lots of false negatives, and so $P(\mathrm{Positive})=0.45$.

These two pieces of information are not enough for us to understand the full implications of a positive test. A clearer sense of how these two experiments relate to each other could be expressed in a table as follows:

::: {#fig-contingency}
$$ \begin{array}{rrccc} & & & \textbf{Test Result} & \\ & & \mathrm{Positive} & \mathrm{Negative} & \textit{Total} \\ & \mathrm{Has\ Disease} & 0.44 & 0.16 & \textit{0.60} \\ \textbf{Health} & \mathrm{Does\ Not} & 0.01 & 0.39 & \textit{0.40} \\ & \textit{Total} & \textit{0.45} & \textit{0.55} & \end{array}$$

Contingency table of joint and marginal probabilities
:::

The four cells at the top right are **joint probabilities**, which tell you the chance of simultaneously observing two pieces of information. For example, among people who test for this disease, 39% do not have the disease and yet test negative.

The four italicized cells along the bottom and right sides are **marginal probabilities**, which tell you the overall chance of one experiment’s outcome averaged over all possible results from the second experiment. Notice that we can compute these marginal probabilities by totaling the rows and columns of the joint probabilities in the literal *margins* of the table.

From the combination of the joint and marginal probabilities, we can compute the **conditional probabilities**, which show us how the outcomes of one experiment become more or less likely once we know the result of the other. When we learn about the other experiment, we change the event space of the first experiment, since some joint outcomes are no longer possible. Events containing those outcomes are removed from $\mathcal{F}$. Probabilities shift such that the total of all remaining events sum to 1.

If we test positive, what is the probability we have the disease? We can disregard the second column above: we now “live” in the first column, totaling 45% (those who test positive). For every 45 people who test positive, 44 test positive and have the disease, while 1 tests positive and does not have the disease. Therefore, the probability of having the disease given a positive test is $0.44/0.45 \approx 0.978.$ We can formalize this result:

::: callout-note
Let the triplet $\Omega,\mathcal{F},P$ define an experiment, and let $A$ and $B$ be events within $\mathcal{F}$. The conditional probability of $A$ given $B$ is written $P(A|B)$ and defined, $$P(A|B) = \frac{P(A \cap B)}{P(B)}$$
:::

We can derive three useful rules from this definition of conditional probability. The first flows simply from the above formula if we multiply both sides by $P(B)$:

::: callout-note
Let the triplet $\Omega,\mathcal{F},P$ define an experiment, and let $A$ and $B$ be events within $\mathcal{F}$. Then, $$P(A \cap B) = P(A|B) \cdot P(B)$$
:::

This result allows us to compute the probability of a series of events by multiplying the branching probabilities of each conditional link. Consider an unfair coin which lands heads (“H”) 40% of the time and tails (“T”) 60% of the time. What is the probability of the sequence THH?

::: {#fig-chain}
```{mermaid}
---
config:
  look: handDrawn
  theme: neutral
---
flowchart LR
  A((Begin)) -- 0.4 --> B[H _ _]
  A -- 0.6 --> C[T _ _]
  C -- 0.4 --> D[T H _]
  C -- 0.6 --> E[T T _]
  D -- 0.4 --> F[T H H]
  D -- 0.6 --> G[T H T]
  classDef stop stroke:red,color:red
  class B,E,G stop
```

Chain of coin flip probabilities
:::

Using the rule above, we can see that the probability of the full sequence could be expressed as P(THH)=P(T)∙P(TH\|T)∙P(THT\|TH)=0.6∙0.4∙0.6=0.144. The second useful result is known as The Law of Complete Probability, and allows us to compute the probability of an event by aggregating its conditional probability among a group of exhaustive and mutually exclusive conditions, meaning that exactly one of the conditions is always true. Let the triplet Ω,F,P define an experiment, and let A be an event within F. Let B_1,B_2,…,B_n also be events within F such that all events B_i are mutually exclusive and ∑\_i▒P(B_i ) =1 Then, P(A)=∑\_i▒〖P(A\|B_i )∙P(B_i ) 〗 As an example, consider the proportion of time that my heart rate is elevated above 80 beats per minute. Elevated heart rates are rare in my sleep, perhaps occurring only during stressful dreams (perhaps 2% of my sleep?). When I’m awake, 80bpm is near my resting heart rate, and so I might spend 25% of my waking hours at rates above that. If I sleep on average 7 hours a day, then we can calculate P(elevated)=P(elevated\|asleep)∙P(asleep)+P(elevated\|awake)∙P(awake) =0.02∙(7/24)+0.25∙(17/24) ≈18.3% The last useful result I will mention here is a way to calculate P(B\|A) from P(A\|B). This formula is known as Bayes Theorem, after the English clergyman Reverend Thomas Bayes. Bayes was not a trained mathematician, but his natural curiosity and diligent amateur study led him to this significant result, published posthumously: Let the triplet Ω,F,P define an experiment, and let A and B be events within F. Then, P(B\|A)=(P(A\|B)∙P(B))/P(A) If we further assume that instead of one event B we have many events B_1,B_2,…,B_n such that all events B_i are mutually exclusive and ∑\_i▒P(B_i ) =1, then further, P(B_j \|A)=(P(A\|B_j )∙P(B_j ))/(∑\_i▒〖P(A\|B_i )∙P(B_i ) 〗) The second equation above flows from the first equation when we apply our prior result of the Law of Complete Probability. For an example of the first equation at work, consider the heart rate hypothetical above: P(awake\|elevated)=(P(elevated\|awake)∙P(awake))/P(elevated) =(0.25∙(17/24))/(0.1829…)≈0.968 Notice the distinction: The probability that my heart rate is elevated given that I’m awake is pretty low: only 25% (I don’t exercise as often as I should). But the probability that I’m awake given that my heart rate is elevated is very high: almost 97%. This is both because my heart rarely races in my sleep, and because I’m more often awake than asleep. Bayes Theorem has lent its name to an alternative system of probability known as Bayesian probability, because they both allow the user to update their prior beliefs as more and more data are observed. This broader Bayesian system relaxes some of Kolmogorov’s axioms and creates entirely new models and computations which some “classical” or “frequentist” statisticians find controversial. However, using Bayes Theorem itself is uncontroversial and perfectly valid under Kolmogorov’s axioms.
