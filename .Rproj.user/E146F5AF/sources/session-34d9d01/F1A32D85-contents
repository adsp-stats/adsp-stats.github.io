```{r}
#| label: setup
#| echo: false
library(thematic)
```

# Set theory {#sec-sets}

These notes largely focus on parametric inference. Parameteric inference relies on distribution theory. Distribution theory relies on probability theory. Probability theory relies on set theory.

But we cannot cover all of set theory, probability theory, distributional theory, and inference in a single document or course. So in these first few chapters I am presenting small corners of each field to you for reference, no more than you need to build a solid understanding of the predictive models in the later chapters.

## Sets, unions and intersections

Sets are collections of objects, and set theory helps us talk about these collections of objects: how many there are, which objects can be found in two different sets, etc. Set theory seems quite basic, but it’s very relevant to probability because one way to think about probability is to divide “the number of desired outcomes” of an experiment by “the number of total outcomes” of that experiment, which requires us to know how to arrange and count outcomes.

Let $\mathcal{S}$ be a **set**, that is, a collection of objects. The objects could be numbers, or words, or cars, or anything at all. We call each object that belongs to a set an **element**, and if an element named $x$ belongs to the set $\mathcal{S}$, we write:

$$x \in \mathcal{S}$$

While if another element called $y$ does not belong to the set $\mathcal{S}$, we write:

$$y \notin \mathcal{S}$$

If a set $\mathcal{A}$ contains all of the elements that belong to another set $\mathcal{B}$, we say that $\mathcal{B}$ is a **subset** of $\mathcal{A}$, which can be written:

$$\mathcal{B} \subseteq \mathcal{A}$$

Notice that this leaves the possibility that $\mathcal{A}$ and $\mathcal{B}$ are in fact equal, the same set. If we know that $\mathcal{B}$ is actually smaller than $\mathcal{A}$, that is, $\mathcal{A}$ contains all the elements in $\mathcal{B}$ and also other elements not in $\mathcal{B}$, then we say that $\mathcal{B}$ is a **proper subset** of $\mathcal{A}$ and we write:

$$\mathcal{B} \subset \mathcal{A}$$

Sometimes two sets share certain elements, and we want to identify only those elements which appear in both sets. We call this new set the **intersection**, and we could write:

$$\mathcal{A} \cap \mathcal{B} = \{x: x \in \mathcal{A} \textrm{ and } x \in \mathcal{B}\}$$ Other times we want to identify all of those elements which appear in either set. We call this new set the **union**, and we could write:

$$\mathcal{A} \cup \mathcal{B} = \{x: x \in \mathcal{A} \textrm{ or } x \in \mathcal{B}\}$$

```{r}
#| label: fig-setbasics
#| layout-ncol: 2
#| layout-nrow: 2
#| fig-cap: "Visualization of set theory basics"
#| fig-subcap:
#|   - $x \in \mathcal{A}, y \notin \mathcal{A}$
#|   - $\mathcal{B} \subseteq \mathcal{A}, \mathcal{A} \subseteq \mathcal{B}$
#|   - $\mathcal{B} \subset \mathcal{A}, \mathcal{A} \not\subset \mathcal{B}$
#|   - $\mathcal{A} \cap \mathcal{B} = \{x,z\}, \mathcal{A} \cup \mathcal{B} = \{w,x,y,z\}$

par(mar=(rep(0.1,4)))
symbols(x=1,y=1,circles=0.8,inches=FALSE,fg='white',bg='grey80',
        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',
        xlab=NA,ylab=NA,add=FALSE)
text(x=0.25,y=1.75,label='A',adj=c(0.5,0.5),cex=3.5)
text(x=c(1.4,2.2),y=c(1,1),labels=c('x','y'),adj=c(0.5,0.5),cex=2.5)

symbols(x=c(1,1.1),y=c(1,0.9),circles=c(0.8,0.75),inches=FALSE,
        fg=c('white','black'),bg=c('grey80',NA),
        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',
        xlab=NA,ylab=NA,add=FALSE)
text(x=c(0.25,1.8),y=c(1.7,0.3),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)
text(x=c(0.8,1.1,1.4),y=c(0.7,1.1,0.9),labels=c('x','y','z'),adj=c(0.5,0.5),cex=2.5)

symbols(x=c(1,1.25),y=c(1,1.25),circles=c(0.8,0.5),inches=FALSE,
        fg=c('white','black'),bg=c('grey80',NA),
        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',
        xlab=NA,ylab=NA,add=FALSE)
text(x=c(0.25,1.7),y=c(1.7,1.7),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)
text(x=c(0.8,1.1,1.4),y=c(0.7,1.1,0.9),labels=c('x','y','z'),adj=c(0.5,0.5),cex=2.5)

symbols(x=c(1,1.6),y=c(1,0.9),circles=c(0.8,0.7),inches=FALSE,
        fg=c('white','black'),bg=c('grey80',NA),
        xlim=c(0,3),ylim=c(0,2),xaxt='n',yaxt='n',
        xlab=NA,ylab=NA,add=FALSE)
text(x=c(0.25,2.1),y=c(1.7,1.7),label=c('A','B'),adj=c(0.5,0.5),cex=3.5)
text(x=c(0.8,1.1,1.4,1.9),y=c(0.7,1.1,0.9,1.0),labels=c('x','y','z','w'),adj=c(0.5,0.5),cex=2.5)
```

We occasionally find it useful, after defining a set, to also consider every known object not in the set. If an element $x$ does not belong to a set $\mathcal{S}$ then it belongs to “$\mathcal{S}$-**complement**”, often written $\mathcal{S}^c$.

Just above, I wrote “every known object”, and that is also a set worth naming. Let us say that we have some way of knowing all the elements which could or could not belong to any given set. This universe of elements is given lots of names, including the **universal set** and also $\Omega$, Omega, the last letter of the Greek alphabet and therefore literally the ultimate set.

What about a set with no elements at all? Such a thing exists and is often quite useful, just as the number 0 is useful to us despite not doing much. We call it $\emptyset$, the **empty set** (sometimes just called "null").

Consider some basic results which flow from these definitions:

::: callout-note
Let $\emptyset$ be the empty set, $\mathcal{A}$ be any set, and $\Omega$ be the universal set. Then,

$$\begin{array}{lcllcl}
  \mathcal{A} \cup \mathcal{A}^c &=& \Omega\qquad & \mathcal{A} \cap \mathcal{A}^c &=& \emptyset \\
  \mathcal{A} \cup \emptyset &=& \mathcal{A} & \mathcal{A} \cap \emptyset &=& \emptyset \\
  \mathcal{A} \cup \Omega &=& \Omega & \mathcal{A} \cap \Omega &=& \mathcal{A}
\end{array}$$
:::

If, for any two sets $\mathcal{A}$ and $\mathcal{B}$, we know that $\mathcal{A} \cap \mathcal{B} = \emptyset$ then they have no elements in common and we say that the sets are **disjoint**.

## Combinatorics

Another part of set theory studies how to arrange and count the elements in a set. We call this topic “combinatorics”.

You may remember a mathematical operation called **factorial**, written with an exclamation mark (!). Its definition for non-negative integers is:

$$x! = x \cdot (x-1) \cdot (x-2) \cdot \ldots \cdot 2 \cdot 1$$

So, for example, $3! = 3 \cdot 2 \cdot 1 = 6$, and $10! = 3\,628\,800$.[^sets-1] This operation will be very handy for counting arrangements of objects. Let’s now consider several different situations in which wish to count arrangements. In all of these examples, we will suppose that we have a set $\mathcal{S}$ containing $n$ elements. Sometimes we will be studying arrangements of all $n$ objects, but if we are arranging a different number of objects, I will generally call that other number $k$.

[^sets-1]: Notice how quickly these grow: even modern distributed computing has a hard time with large factorials.

### Ordered arrangements without repetition

First, let us consider how many ways we can arrange the $n$ elements of $\mathcal{S}$ in a particular order. For example, let’s say that I am on vacation for five days starting Monday, I have brought five different t-shirts, and I intend to wear a fresh shirt every day. I can select any of the five shirts Monday night. On Tuesday, I can choose from the four remaining shirts. On Wednesday, no matter what I picked Monday and Tuesday, I will have three choices left. On Thursday, two choices. On Friday, only one shirt is left, and I must wear it. Thus I count $5 \cdot 4 \cdot 3 \cdot 2 \cdot 1 = 5! = 120$ shirt arrangements.

### Ordered arrangements with repetition

Second, let us consider how many ways we could arrange the elements of $\mathcal{S}$ in a particular order if we now allow repetition. Reconsidering the previous example, what if I were comfortable wearing the same shirt on multiple days, perhaps even every day (yikes)? On Monday, I would have five choices of what to wear. On Tuesday I would also have five choices: I could repeat Monday’s shirt, or choose any of the others --- and so on throughout the week. Thus I count $5 \cdot 5 \cdot 5 \cdot 5 \cdot 5 = 5^5 = 3125$ different shirt arrangements.

Furthermore, we can generalize this method to cases where we arrange $k \neq n$ elements of $\mathcal{S}$: if I were only vacationing for three days but brought five shirts, there would be $5^3=125$ arrangements, or for seven days, $5^7=78\,125$ arrangements.

### Ordered subsets without repetition (permutations)

Third, let us consider how to order only a subset of elements, without repetition. Say that I brought five shirts, I wear a fresh shirt every day, but the vacation lasts only three days (perhaps I wanted backups for spills or rain). The calculations proceed as in the first case above: I have five choices on Monday, four choices on Tuesday, and three choices on Wednesday --- and then I'm done, and thus I count $5 \cdot 4 \cdot 3 = 60$ shirt arrangements.

Note that $5 \cdot 4 \cdot 3 = (5 \cdot 4 \cdot 3 \cdot 2 \cdot 1)/(2 \cdot 1) = 5!/2!$ or equivalently $5!/(5-3)!$. We will use this result to show a general form below.

### Unordered arrangements without repetition (combinations)

Fourth, suppose we no longer care about the order of elements, and only care about which elements are picked or not picked. Perhaps I am packing five shirts for my vacation, and choosing them from my closet which has a total of nine shirts. How many different bags could I create? The bag doesn't know or care which shirts will be worn on which days... a vacation where I wear the red shirt on Monday will create the same bag as a week where I wear the red shirt on Friday. Using the third case above, we know there are $9!⁄4! = 15\,120$ ways to create an *ordered* subset of five shirts from a set of nine. But using the first case above, we also know that for any five shirts, there are $5!=120$ ways to order them. Combining this information, we see that each of the $15\,120$ ordered shirt arrangements belongs to a group of $120$ duplicate bags which only differ by their order, so we need to shrink our total by a factor of $120$, leaving $15\,120⁄120 = (9!/4!)/5! = 9!/((9-5)!5!) = 126$ possible ways to pack my bag.

### All possible unordered subsets (the power set)

Fifth and finally, let us consider how many possible subsets we could construct, without specifiying size or order. Let us repeat the bag packing question (how many possible bags can I create?), but allowing me to pack any number of the nine shirts (not just five). To answer this question, I will show that it is equivalent to another, simpler question. Consider that each of my nine shirts can either be in or out of the bag. So each possible bag can be thought of as choosing from a set of two elements (“in” and “out”) nine times (once for each shirt), with repetition allowed. Following the logic of our second case we know there will be $2 \cdot 2 \cdot 2 \cdot 2 \cdot 2 \cdot 2 \cdot 2 \cdot 2 \cdot 2 = 2^9 = 512$ possible bags Notice that these bags will include one with all nine shirts, as well as a bag with no shirts at all (double yikes, but mathematically valid).

Let’s review:

::: callout-note
Let $\mathcal{S}$ be a set of $n$ elements. Then,

-   There are $n!$ ways to arrange the elements of $\mathcal{S}$ in order.

-   There are $n^k$ ways to pick $k$ elements of $\mathcal{S}$, if we allow repetition.

-   There are ${}_{n}P_k = \frac{n!}{(n-k)!} = n \cdot (n-1) \cdot \ldots \cdot (n-k+1)$ *ordered* subsets of $\mathcal{S}$ having exactly $k$ elements. These ordered subsets are called **permutations**.

-   There are ${}_{n}C_k = \frac{n!}{(n-k)!k!}$ *unordered* subsets of $\mathcal{S}$ having exactly $k$ elements. These unordered subsets are called **combinations**, and in this text we will use $\left(\begin{array}{c} n \\ k \end{array} \right)$ synomously with ${}_{n}C_k$. Statisticians often read this aloud as "n choose k".

-   There are $2^n$ distinct (unordered) subsets of $\mathcal{S}$, including $\mathcal{S}$ itself and the empty set $\emptyset$. This set of all possible subsets is called the **power set**.
:::

## Probability as counting cases

We will soon explore a more formal definition of probability, but learning the combinatorics shown above leads to an immediate payoff: we can use them to calculate probabilities for a specific (yet common) scenario.

We often face a situation in which a finite number of outcomes are all equally likely. For example,

-   If we roll two six-sided dice, we have an equal chance of each of 36 ordered results (*e.g.* Roll #1 is 2 and Roll #2 is 5)

-   If we draw five cards from a 52-card deck, we have an equal chance of each of $311\,875\,200$ possible ordered hands, or an equal chance of each of $2\,598\,960$ unordered hands.

-   If we split 24 students into six groups of four, there are roughly 4.5 trillion groupings which are each equally likely, if we order neither the groups themselves nor the students within the groups.

In each of these cases, we can evaluate the probability of certain outcomes by counting the number of cases with the desired attributes and dividing by the number of total cases.

::: callout-note
For any finite set $\mathcal{A}$, let $n(\mathcal{A})$ be a function which counts the number of elements in $\mathcal{A}$.

Now consider an experiment with a set of outcomes, $\Omega$. Exactly one outcome from $\Omega$ must happen, and all outcomes are equally likely to happen. For any subset $\mathcal{A} \subseteq \Omega$, the **probability** of an outcome belonging to $\mathcal{A}$ can be calculated as: $$P(\mathcal{A})=\frac{n(\mathcal{A})}{n(\Omega)}$$
:::

::: callout-warning
The above result is *only* true for situations with a finite number of equally likely outomes. At the moment, we haven't learned enough to prove which situations meet that requirement, nor to prove the result is even true: we are proceeding on assumption.
:::

From here, we can start to calculate some actual probabilities. Suppose we are dealt five cards from a standard 52-card deck: what is the probability of being dealt exactly one pair (two matched cards and three unmatched cards)?

-   This question is complicated, because many pairs are actually part of a more valuable hand: three-of-a-kind, four-of-a-kind, a full house, or two pairs. We don't wish to count those hands, even though they contain pairs.

-   Although order doesn't matter, suppose that the first and second cards are paired, while the third, fourth, and fifth cards are unmatched. The first card can be anything (52 choices). The second card must be one of the three remaining cards of the same rank (3 choices). The third card can be anything *except* the rank of the pair (48 choices). The fourth card can be anything except the rank of the pair *or* the rank of the third card, since that would form a second pair (44 choices). And likewise for the fifth (40 choices).

-   $52 \cdot 3 \cdot 48 \cdot 44 \cdot 40 = 13\,178\,880$ would describe the number of hands where the first two cards form a pair. But there are other hands with one pair, such as when the first and third cards are paired. In fact there are ${}_5C_2 = 5!/(2!3!) = 10$ different ways the pair could be arranged in our hand. So there are in fact $n(\mathcal{A})=131\,788\,800$ ordered hands with exactly one pair.

-   That would be among $n(\Omega) = 52 \cdot 51 \cdot 50 \cdot 49 \cdot 48 = 52!/(52 - 5)! = 311\,875\,200$ total ordered hands.

-   In which case the probability of exactly one pair is $n(\mathcal{A})/n(\Omega) = 134\,534\,400/311\,875\,200 \approx 42.3\%$

Let's try one more example, this time somewhat more relevant to a real-world data science issue. Consider an allegation of discriminatory hiring practices. 15 pilots interviewed for five open positions at an airline. 10 of the 15 candidates were men, but only 2 of the 5 selected pilots are men. One of the rejected male pilots claims that the hiring process was unfair. What do you think?

-   There are ${}_{10}C_2 = 10!/(2!8!) = 45$ unordered ways to choose 2 men from among 10 male applicants and ${}_3C_5 = 5!/(3!2!) = 10$ ways to choose 3 women[^sets-2] from among the remaining 5 applicants, so we have $n(\mathcal{A}) = 45 \cdot 10 = 450$.

-   There are $n(\Omega) = {}_15C_5 = 15!/(10!5!) = 3003$ unordered ways to choose 5 pilots from the 15 total applicants.

-   In which case, if we assume that the successful pilots were selected at random (or at any rate not on the basis of their sex), the probability of selecting exactly 2 men and 3 women from 10 men and 5 women would be $n(\mathcal{A})/n(\Omega) = 450/3003 \approx 15.0\%$.

-   It might be useful to also contemplate the case of picking only one male candidate, or zero male candidates. Using similar calculations, the cumulative probability of picking "so few or fewer" male candidates under an assumption of equal probability would be $501/3003 \approx 16.7\%$

[^sets-2]: Or non-binary pilots!

At the end of the day we cannot tell whether the hiring process was fair or unfair. But we can say that an impartial hiring process which was blind to pilot sex would reach a similar outcome (or a more extreme outcome!) roughly $16.7\%$ of the time.

::: {.callout="tip"}
Notice how in the first example, I found it easier to count ordered cases, while in the second example I found it easier to count unordered cases. As long as both my numerator and denominator are consistent, the answer will come out the same.
:::

## Putting it into practice {.unnumbered}

At the end of each chapter I will provide some R code snippets to help put the concepts into practice, as well as sample problems (and their solutions!) to help you test your own comprehension of the material.

### Code examples {.unnumbered}

#### Set theory {.unnumbered}

Set theory is so basic that it's all around us. For example, when we filter a dataset, or when we merge two different datasets, we are choosing intersections and unions from sets where each element is a row of data. The following functions are rarely used in R, but do directly implement the concepts learned above.

```{r}
#| code-fold: false
letters[1:10]
is.element('j',letters)
is.element(c('a','B','c'),letters)

union(1:8,3:10)
intersect(1:8,3:10)
setdiff(1:8,3:10)
setequal(c(1,4,9),c(1,9,4))
```

#### Combinatorics {.unnumbered}

Sometimes our combinatorics problems cannot be solved with easy helper functions, because of special constraints to the problem. However, the following functions will often come in handy. Note the addition of a custom function for permutations.

```{r}
#| code-fold: false
factorial(4)
factorial(1:5)

choose(n=10,k=3)

permute <- function(n,k) factorial(n)/factorial(n-k)
permute(n=10,k=3)
```

### Exercises and solutions {.unnumbered}

1.  Earlier, I calculated the probability that a five-card hand from a standard deck contains exactly one pair. I counted ordered hands to find the answer, though order doesn't matter. Try to find an unordered solution, which should arrive at the same answer.

::: {.callout-tip collapse="true"}
## Solution (theoretical)

There are 13 ways to choose the rank of the pair, ${}_4{C}_2$ ways to choose the two suits of that rank which will form the pair, ${}_{12}{C}_3$ ways to choose the three different ranks of the remaining cards, and four choices of suit for each of them. $$\frac{13 \cdot {}_4{C}_2 \cdot {}_{12}{C}_3 \cdot 4^3}{{}_{52}{C}_5} \approx 42.3\%$$
:::

```{r}
#| code-summary: R implementation
#| output: false
13*choose(4,2)*choose(12,3)*4^3/choose(52,5)
```

2.  Assume that birthdays are evenly distributed across a 365-day (non-leap) year. In a classroom of 23 students, what is the probability that at least two of them share a birthday?

::: {.callout-tip collapse="true"}
## Solution (theoretical)

There are so many ways in which two or more students *could* share birthdays that it will be easier for us to consider the complement: how many ways students could *not* share any birthdays. Clearly, the first student can have any birthday, but the second will only have 364 qualifying options, etc. $$P(A) = 1 - P(A^c) = 1 - \frac{{}_{365}P_{23}}{365^{23}} = 1 - \frac{365 \cdot 364 \cdot \ldots \cdot 343}{365^{23}} \approx 50.7\%$$ This is sometimes known as the birthday "paradox", as it may surprise you that such a small classroom would most likely contain a shared birthday.
:::

```{r}
#| code-summary: R implementation
#| output: false
1-prod(365:343)/365^23
```

3.  In 1919, the statistician Ronald Fisher heard his colleague, the phycologist Muriel Bristol, claim that she could tell whether milk was added to hot tea, or whether the tea was poured directly onto milk. Fisher tested her by pouring eight cups of tea, four one way and four the other, and serving them to her in a random order which she was able to identify with complete accuracy. If Bristol knew that there were four cups of each type, what would be the probability that she identified them all correctly by chance alone?

::: {.callout-tip collapse="true"}
## Solution (theoretical)

This one's quite simple! There are ${}_8C_4 = 70$ ways to arrange the four milk-first cups among the eight total cups, and if Dr. Bristol had been guessing at random she would have selected each arrangement with equal probability, and so would have chosen the right arrangement with only $1/70 \approx 1.4\%$ probability.
:::

```{r}
#| code-summary: R implementation
#| output: false
1/choose(8,4)
```

4.  How would the problem above change if Muriel Bristol had not known there were four cups of each type?

::: {.callout-tip collapse="true"}
## Solution (theoretical)

Without knowing in advance how many cups had milk poured first, Bristol would have been guessing blindly on each new cup, with her guesses for the first few cups providing no information on the latter cups. The experiment now allows $2^8=256$ possible cup sequences, with only one being correct, so if she were guessing at random then a perfect score would only occur with probability $1/256 \approx 0.4\%$.
:::

```{r}
#| code-summary: R implementation
#| output: false
1/2^8
```
